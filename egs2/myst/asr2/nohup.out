2024-10-12T23:26:52 (asr2.sh:288:main) ./asr2.sh --stage 13 --stop_stage 13 --kmeans_opts --batch_bins 600000 --nj 4 --kmeans_feature wavlm_large/21 --nclusters 2000 --ngpu 1 --src_lang wavlm_large_21_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --speed_perturb_factors 0.9 1.0 1.1 --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_noctc_1gpu.yaml --inference_config conf/decode_ctc0.3.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other dev_clean dev_other --src_bpe_train_text dump/raw/train_clean_100_sp/text.rm.wavlm_large_21_km2000 --tgt_bpe_train_text dump/raw/train_clean_100_sp/text.ts.en --lm_train_text dump/raw/train_clean_100_sp/text.ts.en
2024-10-12T23:26:52 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-10-12T23:26:52 (asr2.sh:1420:main) Stage 13: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2024-10-12T23:26:52 (asr2.sh:1463:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_noctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000_sp/run.sh'. You can resume the process from stage 13 using this script
2024-10-12T23:26:52 (asr2.sh:1467:main) ASR training started... log: 'exp/asr_train_discrete_asr_e_branchformer1_noctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000_sp/train.log'
2024-10-12 23:26:52,590 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_e_branchformer1_noctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000_sp/train.log' --log exp/asr_train_discrete_asr_e_branchformer1_noctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_e_branchformer1_noctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000_sp/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_bpemodel data/token_list/src_bpe_unigram6000_rm_wavlm_large_21_km2000/bpe.model --src_token_type bpe --src_token_list data/token_list/src_bpe_unigram6000_rm_wavlm_large_21_km2000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type dump/raw/dev/text.rm.wavlm_large_21_km2000,src_text,text --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000_sp/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000_sp/valid/src_text_shape.bpe --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_e_branchformer1_noctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000_sp --config conf/train_discrete_asr_e_branchformer1_noctc_1gpu.yaml --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text.rm.wavlm_large_21_km2000,src_text,text --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000_sp/train/src_text_shape.bpe --train_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000_sp/train/text_shape.bpe
2024-10-12 23:26:52,606 (launch:348) INFO: log file: exp/asr_train_discrete_asr_e_branchformer1_noctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000_sp/train.log
Traceback (most recent call last):
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/data/mohan/workdir/espnet/espnet2/bin/launch.py", line 384, in <module>
    main()
  File "/data/mohan/workdir/espnet/espnet2/bin/launch.py", line 358, in main
    process.wait(0.5)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/subprocess.py", line 1209, in wait
    return self._wait(timeout=timeout)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/subprocess.py", line 1953, in _wait
    time.sleep(delay)
KeyboardInterrupt
2024-10-12T23:27:08 (asr2.sh:288:main) ./asr2.sh --stage 13 --stop_stage 13 --kmeans_opts --batch_bins 600000 --nj 4 --kmeans_feature wavlm_large/21 --nclusters 2000 --ngpu 1 --src_lang wavlm_large_21_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --speed_perturb_factors 0.9 1.0 1.1 --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_noctc_1gpu.yaml --inference_config conf/decode_ctc0.3.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other dev_clean dev_other --src_bpe_train_text dump/raw/train_clean_100_sp/text.rm.wavlm_large_21_km2000 --tgt_bpe_train_text dump/raw/train_clean_100_sp/text.ts.en --lm_train_text dump/raw/train_clean_100_sp/text.ts.en
2024-10-12T23:27:08 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-10-12T23:27:08 (asr2.sh:1420:main) Stage 13: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2024-10-12T23:27:08 (asr2.sh:1463:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_noctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000_sp/run.sh'. You can resume the process from stage 13 using this script
2024-10-12T23:27:08 (asr2.sh:1467:main) ASR training started... log: 'exp/asr_train_discrete_asr_e_branchformer1_noctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000_sp/train.log'
2024-10-12 23:27:08,888 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_e_branchformer1_noctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000_sp/train.log' --log exp/asr_train_discrete_asr_e_branchformer1_noctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_e_branchformer1_noctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000_sp/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_bpemodel data/token_list/src_bpe_unigram6000_rm_wavlm_large_21_km2000/bpe.model --src_token_type bpe --src_token_list data/token_list/src_bpe_unigram6000_rm_wavlm_large_21_km2000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type dump/raw/dev/text.rm.wavlm_large_21_km2000,src_text,text --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000_sp/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000_sp/valid/src_text_shape.bpe --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_e_branchformer1_noctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000_sp --config conf/train_discrete_asr_e_branchformer1_noctc_1gpu.yaml --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text.rm.wavlm_large_21_km2000,src_text,text --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000_sp/train/src_text_shape.bpe --train_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000_sp/train/text_shape.bpe
2024-10-12 23:27:08,902 (launch:348) INFO: log file: exp/asr_train_discrete_asr_e_branchformer1_noctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000_sp/train.log
2024-10-13T07:04:40 (asr2.sh:1782:main) Successfully finished. [elapsed=27452s]
2024-10-13T13:31:47 (asr2.sh:288:main) ./asr2.sh --stage 14 --stop_stage 14 --kmeans_opts --batch_bins 600000 --nj 4 --kmeans_feature wavlm_large/21 --nclusters 2000 --ngpu 1 --src_lang wavlm_large_21_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --speed_perturb_factors 0.9 1.0 1.1 --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_noctc_1gpu.yaml --inference_config conf/decode_ctc0.0.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other dev_clean dev_other --src_bpe_train_text dump/raw/train_clean_100_sp/text.rm.wavlm_large_21_km2000 --tgt_bpe_train_text dump/raw/train_clean_100_sp/text.ts.en --lm_train_text dump/raw/train_clean_100_sp/text.ts.en
2024-10-13T13:31:47 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-10-13T13:31:47 (asr2.sh:1542:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_e_branchformer1_noctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000_sp
2024-10-13T13:31:47 (asr2.sh:1570:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_noctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000_sp/decode_ctc0.0_asr_model_valid.acc.ave/run.sh'. You can resume the process from stage 14 using this script
2024-10-13T13:31:47 (asr2.sh:1599:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_noctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000_sp/decode_ctc0.0_asr_model_valid.acc.ave/test_clean/logdir/asr_inference.*.log'
2024-10-13T14:04:26 (asr2.sh:1599:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_noctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000_sp/decode_ctc0.0_asr_model_valid.acc.ave/test_other/logdir/asr_inference.*.log'
2024-10-13T14:35:57 (asr2.sh:1599:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_noctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000_sp/decode_ctc0.0_asr_model_valid.acc.ave/dev_clean/logdir/asr_inference.*.log'
2024-10-13T15:16:15 (asr2.sh:1599:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_noctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000_sp/decode_ctc0.0_asr_model_valid.acc.ave/dev_other/logdir/asr_inference.*.log'
2024-10-13T16:09:44 (asr2.sh:1782:main) Successfully finished. [elapsed=9477s]
2024-10-17T04:39:59 (asr2.sh:288:main) ./asr2.sh --stage 13 --stop_stage 13 --gpu_kmeans true --kmeans_opts --batch_bins 400000 --nj 4 --kmeans_feature wavlm_large/21 --nclusters 2000 --ngpu 1 --src_lang wavlm_large_21_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_1gpu.yaml --inference_config conf/decode_ctc0.3.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_21_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-10-17T04:40:00 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-10-17T04:40:00 (asr2.sh:1420:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2024-10-17T04:40:00 (asr2.sh:1463:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2024-10-17T04:40:00 (asr2.sh:1467:main) ASR training started... log: 'exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/train.log'
2024-10-17 04:40:00,171 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_bpemodel data/token_list/src_bpe_unigram6000_rm_wavlm_large_21_km2000/bpe.model --src_token_type bpe --src_token_list data/token_list/src_bpe_unigram6000_rm_wavlm_large_21_km2000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type dump/raw/dev/text.rm.wavlm_large_21_km2000,src_text,text --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/valid/src_text_shape.bpe --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000 --config conf/train_discrete_asr_e_branchformer1_1gpu.yaml --train_data_path_and_name_and_type dump/raw/train/text.rm.wavlm_large_21_km2000,src_text,text --train_data_path_and_name_and_type dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/train/src_text_shape.bpe --train_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/train/text_shape.bpe
2024-10-17 04:40:00,188 (launch:348) INFO: log file: exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/train.log
2024-10-17T09:38:06 (asr2.sh:1782:main) Successfully finished. [elapsed=17887s]
2024-10-17T12:20:34 (asr2.sh:288:main) ./asr2.sh --stage 14 --stop_stage 14 --gpu_kmeans true --kmeans_opts --batch_bins 400000 --nj 4 --kmeans_feature wavlm_large/21 --nclusters 2000 --ngpu 1 --src_lang wavlm_large_21_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_1gpu.yaml --inference_config conf/decode_ctc0.3.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_21_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-10-17T12:20:34 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-10-17T12:20:34 (asr2.sh:1542:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000
2024-10-17T12:20:34 (asr2.sh:1570:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/run.sh'. You can resume the process from stage 14 using this script
2024-10-17T12:20:34 (asr2.sh:1599:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.*.log'
2024-10-17T12:23:11 (asr2.sh:288:main) ./asr2.sh --stage 14 --stop_stage 14 --gpu_kmeans true --kmeans_opts --batch_bins 400000 --nj 4 --kmeans_feature wavlm_large/21 --nclusters 2000 --ngpu 1 --src_lang wavlm_large_21_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_1gpu.yaml --inference_config conf/decode_ctc0.3.yaml --train_set train --valid_set dev --test_sets dev --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_21_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-10-17T12:23:11 (asr2.sh:326:main) Info: The valid_set 'dev' is included in the test_sets. '--eval_valid_set true' is set and 'dev' is removed from the test_sets
2024-10-17T12:23:11 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-10-17T12:23:11 (asr2.sh:1542:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000
2024-10-17T12:23:11 (asr2.sh:1570:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/run.sh'. You can resume the process from stage 14 using this script
./asr2.sh: line 1589: dump/raw/org/dev/text.rm.wavlm_large_21_km2000: No such file or directory
./asr2.sh: line 17: [: : integer expression expected
utils/split_scp.pl: Error opening input scp file dump/raw/org/dev/text.rm.wavlm_large_21_km2000: No such file or directory
2024-10-17T12:26:10 (asr2.sh:288:main) ./asr2.sh --stage 14 --stop_stage 14 --gpu_kmeans true --kmeans_opts --batch_bins 400000 --nj 4 --kmeans_feature wavlm_large/21 --nclusters 2000 --ngpu 1 --src_lang wavlm_large_21_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_1gpu.yaml --inference_config conf/decode_ctc0.3.yaml --train_set train --valid_set dev --test_sets dev --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_21_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-10-17T12:26:11 (asr2.sh:326:main) Info: The valid_set 'dev' is included in the test_sets. '--eval_valid_set true' is set and 'dev' is removed from the test_sets
2024-10-17T12:26:11 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-10-17T12:26:11 (asr2.sh:1542:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000
2024-10-17T12:26:11 (asr2.sh:1570:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/run.sh'. You can resume the process from stage 14 using this script
./asr2.sh: line 1578: _dsets: unbound variable
2024-10-17T12:27:13 (asr2.sh:288:main) ./asr2.sh --stage 14 --stop_stage 14 --gpu_kmeans true --kmeans_opts --batch_bins 400000 --nj 4 --kmeans_feature wavlm_large/21 --nclusters 2000 --ngpu 1 --src_lang wavlm_large_21_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_1gpu.yaml --inference_config conf/decode_ctc0.3.yaml --train_set train --valid_set dev --test_sets dev --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_21_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-10-17T12:27:13 (asr2.sh:326:main) Info: The valid_set 'dev' is included in the test_sets. '--eval_valid_set true' is set and 'dev' is removed from the test_sets
2024-10-17T12:27:14 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-10-17T12:27:14 (asr2.sh:1542:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000
2024-10-17T12:27:14 (asr2.sh:1570:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/run.sh'. You can resume the process from stage 14 using this script
2024-10-17T12:27:14 (asr2.sh:1786:main) Successfully finished. [elapsed=1s]
2024-10-17T12:32:47 (asr2.sh:288:main) ./asr2.sh --stage 14 --stop_stage 14 --gpu_kmeans true --kmeans_opts --batch_bins 400000 --nj 4 --kmeans_feature wavlm_large/21 --nclusters 2000 --ngpu 1 --src_lang wavlm_large_21_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_1gpu.yaml --inference_config conf/decode_ctc0.3.yaml --train_set train --valid_set dev --test_sets dev --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_21_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-10-17T12:32:47 (asr2.sh:326:main) Info: The valid_set 'dev' is included in the test_sets. '--eval_valid_set true' is set and 'dev' is removed from the test_sets
2024-10-17T12:32:47 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-10-17T12:32:47 (asr2.sh:1542:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000
2024-10-17T12:32:47 (asr2.sh:1570:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/run.sh'. You can resume the process from stage 14 using this script
2024-10-17T12:32:47 (asr2.sh:1786:main) Successfully finished. [elapsed=0s]
2024-10-17T12:36:27 (asr2.sh:288:main) ./asr2.sh --stage 14 --stop_stage 14 --gpu_kmeans true --kmeans_opts --batch_bins 400000 --nj 4 --kmeans_feature wavlm_large/21 --nclusters 2000 --ngpu 1 --src_lang wavlm_large_21_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_1gpu.yaml --inference_config conf/decode_ctc0.3.yaml --train_set train --valid_set dev --test_sets dev --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_21_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-10-17T12:36:27 (asr2.sh:326:main) Info: The valid_set 'dev' is included in the test_sets. '--eval_valid_set true' is set and 'dev' is removed from the test_sets
2024-10-17T12:36:27 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-10-17T12:36:27 (asr2.sh:1542:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000
2024-10-17T12:36:27 (asr2.sh:1570:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/run.sh'. You can resume the process from stage 14 using this script
2024-10-17T12:36:27 (asr2.sh:1786:main) Successfully finished. [elapsed=0s]
2024-10-17T17:33:30 (asr2.sh:288:main) ./asr2.sh --stage 14 --stop_stage 14 --gpu_kmeans true --kmeans_opts --batch_bins 400000 --nj 4 --kmeans_feature wavlm_large/21 --nclusters 2000 --ngpu 1 --src_lang wavlm_large_21_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_1gpu.yaml --inference_config conf/decode_ctc0.3.yaml --train_set train --valid_set dev --test_sets dev test --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_21_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-10-17T17:33:30 (asr2.sh:326:main) Info: The valid_set 'dev' is included in the test_sets. '--eval_valid_set true' is set and 'dev' is removed from the test_sets
2024-10-17T17:33:30 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-10-17T17:33:30 (asr2.sh:1542:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000
2024-10-17T17:33:30 (asr2.sh:1570:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/run.sh'. You can resume the process from stage 14 using this script
2024-10-17T17:33:30 (asr2.sh:1601:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.*.log'
2024-10-17T18:19:10 (asr2.sh:288:main) ./asr2.sh --stage 14 --stop_stage 14 --gpu_kmeans true --kmeans_opts --batch_bins 400000 --nj 4 --kmeans_feature wavlm_large/21 --nclusters 2000 --ngpu 1 --src_lang wavlm_large_21_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_1gpu.yaml --inference_config conf/decode_ctc0.3.yaml --train_set train --valid_set dev --test_sets dev test --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_21_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-10-17T18:19:10 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-10-17T18:19:10 (asr2.sh:1542:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000
2024-10-17T18:19:10 (asr2.sh:1570:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/run.sh'. You can resume the process from stage 14 using this script
2024-10-17T18:19:10 (asr2.sh:1601:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/dev/logdir/asr_inference.*.log'
2024-10-17T21:21:11 (asr2.sh:1601:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.*.log'
bash: line 1: 667598 Killed                  ( python3 -m espnet2.bin.mt_inference --batch_size 1 --ngpu 0 --data_path_and_name_and_type dump/raw/test/text.rm.wavlm_large_21_km2000,src_text,text --key_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/keys.6.scp --mt_train_config exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/config.yaml --mt_model_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/valid.acc.ave.pth --output_dir exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/output.6 --config conf/decode_ctc0.3.yaml ) 2>> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.6.log >> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.6.log
bash: line 1: 667593 Killed                  ( python3 -m espnet2.bin.mt_inference --batch_size 1 --ngpu 0 --data_path_and_name_and_type dump/raw/test/text.rm.wavlm_large_21_km2000,src_text,text --key_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/keys.2.scp --mt_train_config exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/config.yaml --mt_model_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/valid.acc.ave.pth --output_dir exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/output.2 --config conf/decode_ctc0.3.yaml ) 2>> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.2.log >> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.2.log
bash: line 1: 667595 Killed                  ( python3 -m espnet2.bin.mt_inference --batch_size 1 --ngpu 0 --data_path_and_name_and_type dump/raw/test/text.rm.wavlm_large_21_km2000,src_text,text --key_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/keys.1.scp --mt_train_config exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/config.yaml --mt_model_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/valid.acc.ave.pth --output_dir exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/output.1 --config conf/decode_ctc0.3.yaml ) 2>> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.1.log >> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.1.log
bash: line 1: 667600 Killed                  ( python3 -m espnet2.bin.mt_inference --batch_size 1 --ngpu 0 --data_path_and_name_and_type dump/raw/test/text.rm.wavlm_large_21_km2000,src_text,text --key_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/keys.8.scp --mt_train_config exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/config.yaml --mt_model_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/valid.acc.ave.pth --output_dir exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/output.8 --config conf/decode_ctc0.3.yaml ) 2>> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.8.log >> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.8.log
2024-10-18T01:04:50 (asr2.sh:288:main) ./asr2.sh --stage 14 --stop_stage 14 --gpu_kmeans true --kmeans_opts --batch_bins 400000 --nj 4 --kmeans_feature wavlm_large/21 --nclusters 2000 --ngpu 1 --src_lang wavlm_large_21_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_1gpu.yaml --inference_config conf/decode_ctc0.3.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_21_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-10-18T01:04:50 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-10-18T01:04:50 (asr2.sh:1542:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000
2024-10-18T01:04:50 (asr2.sh:1570:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/run.sh'. You can resume the process from stage 14 using this script
2024-10-18T01:04:50 (asr2.sh:1601:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.*.log'
bash: line 1: 742603 Killed                  ( python3 -m espnet2.bin.mt_inference --batch_size 1 --ngpu 0 --data_path_and_name_and_type dump/raw/test/text.rm.wavlm_large_21_km2000,src_text,text --key_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/keys.1.scp --mt_train_config exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/config.yaml --mt_model_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/valid.acc.ave.pth --output_dir exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/output.1 --config conf/decode_ctc0.3.yaml ) 2>> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.1.log >> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.1.log
bash: line 1: 742601 Killed                  ( python3 -m espnet2.bin.mt_inference --batch_size 1 --ngpu 0 --data_path_and_name_and_type dump/raw/test/text.rm.wavlm_large_21_km2000,src_text,text --key_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/keys.2.scp --mt_train_config exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/config.yaml --mt_model_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/valid.acc.ave.pth --output_dir exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/output.2 --config conf/decode_ctc0.3.yaml ) 2>> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.2.log >> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.2.log
bash: line 1: 742600 Killed                  ( python3 -m espnet2.bin.mt_inference --batch_size 1 --ngpu 0 --data_path_and_name_and_type dump/raw/test/text.rm.wavlm_large_21_km2000,src_text,text --key_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/keys.3.scp --mt_train_config exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/config.yaml --mt_model_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/valid.acc.ave.pth --output_dir exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/output.3 --config conf/decode_ctc0.3.yaml ) 2>> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.3.log >> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.3.log
bash: line 1: 742607 Killed                  ( python3 -m espnet2.bin.mt_inference --batch_size 1 --ngpu 0 --data_path_and_name_and_type dump/raw/test/text.rm.wavlm_large_21_km2000,src_text,text --key_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/keys.6.scp --mt_train_config exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/config.yaml --mt_model_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/valid.acc.ave.pth --output_dir exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/output.6 --config conf/decode_ctc0.3.yaml ) 2>> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.6.log >> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.6.log
<<<<<<< HEAD
2024-10-22T10:26:30 (asr2.sh:288:main) ./asr2.sh --stage 14 --stop_stage 14 --gpu_kmeans true --kmeans_opts --batch_bins 400000 --nj 4 --kmeans_feature wavlm_large/21 --nclusters 2000 --ngpu 1 --inference_asr_model valid.cer_ctc.ave.pth --src_lang wavlm_large_21_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu.yaml --inference_config conf/decode_ctc1.0.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_21_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-10-22T10:26:30 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-10-22T10:26:30 (asr2.sh:1542:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000
2024-10-22T10:26:30 (asr2.sh:1570:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_asr_model_valid.cer_ctc.ave/run.sh'. You can resume the process from stage 14 using this script
2024-10-22T10:26:30 (asr2.sh:1601:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_asr_model_valid.cer_ctc.ave/test/logdir/asr_inference.*.log'
bash: line 1: 4186045 Killed                  ( python3 -m espnet2.bin.mt_inference --batch_size 1 --ngpu 0 --data_path_and_name_and_type dump/raw/test/text.rm.wavlm_large_21_km2000,src_text,text --key_file exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_asr_model_valid.cer_ctc.ave/test/logdir/keys.2.scp --mt_train_config exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/config.yaml --mt_model_file exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/valid.cer_ctc.ave.pth --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_asr_model_valid.cer_ctc.ave/test/logdir/output.2 --config conf/decode_ctc1.0.yaml ) 2>> exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_asr_model_valid.cer_ctc.ave/test/logdir/asr_inference.2.log >> exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_asr_model_valid.cer_ctc.ave/test/logdir/asr_inference.2.log
bash: line 1: 4186048 Killed                  ( python3 -m espnet2.bin.mt_inference --batch_size 1 --ngpu 0 --data_path_and_name_and_type dump/raw/test/text.rm.wavlm_large_21_km2000,src_text,text --key_file exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_asr_model_valid.cer_ctc.ave/test/logdir/keys.6.scp --mt_train_config exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/config.yaml --mt_model_file exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/valid.cer_ctc.ave.pth --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_asr_model_valid.cer_ctc.ave/test/logdir/output.6 --config conf/decode_ctc1.0.yaml ) 2>> exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_asr_model_valid.cer_ctc.ave/test/logdir/asr_inference.6.log >> exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_asr_model_valid.cer_ctc.ave/test/logdir/asr_inference.6.log
bash: line 1: 4186049 Killed                  ( python3 -m espnet2.bin.mt_inference --batch_size 1 --ngpu 0 --data_path_and_name_and_type dump/raw/test/text.rm.wavlm_large_21_km2000,src_text,text --key_file exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_asr_model_valid.cer_ctc.ave/test/logdir/keys.7.scp --mt_train_config exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/config.yaml --mt_model_file exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/valid.cer_ctc.ave.pth --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_asr_model_valid.cer_ctc.ave/test/logdir/output.7 --config conf/decode_ctc1.0.yaml ) 2>> exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_asr_model_valid.cer_ctc.ave/test/logdir/asr_inference.7.log >> exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_asr_model_valid.cer_ctc.ave/test/logdir/asr_inference.7.log
bash: line 1: 4186044 Killed                  ( python3 -m espnet2.bin.mt_inference --batch_size 1 --ngpu 0 --data_path_and_name_and_type dump/raw/test/text.rm.wavlm_large_21_km2000,src_text,text --key_file exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_asr_model_valid.cer_ctc.ave/test/logdir/keys.1.scp --mt_train_config exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/config.yaml --mt_model_file exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/valid.cer_ctc.ave.pth --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_asr_model_valid.cer_ctc.ave/test/logdir/output.1 --config conf/decode_ctc1.0.yaml ) 2>> exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_asr_model_valid.cer_ctc.ave/test/logdir/asr_inference.1.log >> exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_asr_model_valid.cer_ctc.ave/test/logdir/asr_inference.1.log
run.pl: 4 / 8 failed, log is in exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_asr_model_valid.cer_ctc.ave/test/logdir/asr_inference.*.log
cat: -: Bad file descriptor
=======
<<<<<<< HEAD
2024-10-18T04:54:03 (asr2.sh:288:main) ./asr2.sh --stage 14 --stop_stage 14 --gpu_kmeans true --kmeans_opts --batch_bins 400000 --nj 4 --kmeans_feature wavlm_large/21 --nclusters 2000 --ngpu 1 --src_lang wavlm_large_21_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_1gpu.yaml --inference_config conf/decode_ctc0.3.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_21_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-10-18T04:54:03 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-10-18T04:54:03 (asr2.sh:1542:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000
2024-10-18T04:54:03 (asr2.sh:1570:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/run.sh'. You can resume the process from stage 14 using this script
2024-10-18T04:54:03 (asr2.sh:1601:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.*.log'
bash: line 1: 742604 Killed                  ( python3 -m espnet2.bin.mt_inference --batch_size 1 --ngpu 0 --data_path_and_name_and_type dump/raw/test/text.rm.wavlm_large_21_km2000,src_text,text --key_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/keys.8.scp --mt_train_config exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/config.yaml --mt_model_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/valid.acc.ave.pth --output_dir exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/output.8 --config conf/decode_ctc0.3.yaml ) 2>> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.8.log >> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.8.log
bash: line 1: 742602 Killed                  ( python3 -m espnet2.bin.mt_inference --batch_size 1 --ngpu 0 --data_path_and_name_and_type dump/raw/test/text.rm.wavlm_large_21_km2000,src_text,text --key_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/keys.7.scp --mt_train_config exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/config.yaml --mt_model_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/valid.acc.ave.pth --output_dir exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/output.7 --config conf/decode_ctc0.3.yaml ) 2>> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.7.log >> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.7.log
bash: line 1: 799817 Killed                  ( python3 -m espnet2.bin.mt_inference --batch_size 1 --ngpu 0 --data_path_and_name_and_type dump/raw/test/text.rm.wavlm_large_21_km2000,src_text,text --key_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/keys.1.scp --mt_train_config exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/config.yaml --mt_model_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/valid.acc.ave.pth --output_dir exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/output.1 --config conf/decode_ctc0.3.yaml ) 2>> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.1.log >> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.1.log
bash: line 1: 799821 Killed                  ( python3 -m espnet2.bin.mt_inference --batch_size 1 --ngpu 0 --data_path_and_name_and_type dump/raw/test/text.rm.wavlm_large_21_km2000,src_text,text --key_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/keys.2.scp --mt_train_config exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/config.yaml --mt_model_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/valid.acc.ave.pth --output_dir exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/output.2 --config conf/decode_ctc0.3.yaml ) 2>> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.2.log >> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.2.log
bash: line 1: 799816 Killed                  ( python3 -m espnet2.bin.mt_inference --batch_size 1 --ngpu 0 --data_path_and_name_and_type dump/raw/test/text.rm.wavlm_large_21_km2000,src_text,text --key_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/keys.3.scp --mt_train_config exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/config.yaml --mt_model_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/valid.acc.ave.pth --output_dir exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/output.3 --config conf/decode_ctc0.3.yaml ) 2>> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.3.log >> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.3.log
bash: line 1: 799822 Killed                  ( python3 -m espnet2.bin.mt_inference --batch_size 1 --ngpu 0 --data_path_and_name_and_type dump/raw/test/text.rm.wavlm_large_21_km2000,src_text,text --key_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/keys.6.scp --mt_train_config exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/config.yaml --mt_model_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/valid.acc.ave.pth --output_dir exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/output.6 --config conf/decode_ctc0.3.yaml ) 2>> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.6.log >> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.6.log
run.pl: 6 / 8 failed, log is in exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.*.log
cat: -: Bad file descriptor
run.pl: 4 / 8 failed, log is in exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.*.log
cat: -: Bad file descriptor
2024-10-18T16:48:32 (asr2.sh:288:main) ./asr2.sh --stage 14 --stop_stage 14 --gpu_kmeans true --kmeans_opts --batch_bins 400000 --nj 4 --kmeans_feature wavlm_large/21 --nclusters 2000 --ngpu 1 --src_lang wavlm_large_21_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_1gpu.yaml --inference_config conf/decode_ctc0.3.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_21_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-10-18T16:48:33 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-10-18T16:48:33 (asr2.sh:1542:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000
2024-10-18T16:48:33 (asr2.sh:1570:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/run.sh'. You can resume the process from stage 14 using this script
2024-10-18T16:48:33 (asr2.sh:1601:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.*.log'
bash: line 1: 1403798 Killed                  ( python3 -m espnet2.bin.mt_inference --batch_size 1 --ngpu 0 --data_path_and_name_and_type dump/raw/test/text.rm.wavlm_large_21_km2000,src_text,text --key_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/keys.1.scp --mt_train_config exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/config.yaml --mt_model_file exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/valid.acc.ave.pth --output_dir exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/output.1 --config conf/decode_ctc0.3.yaml ) 2>> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.1.log >> exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.1.log
run.pl: 1 / 4 failed, log is in exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_asr_model_valid.acc.ave/test/logdir/asr_inference.*.log
cat: -: Bad file descriptor
=======
2024-10-25T22:21:45 (asr2.sh:288:main) ./asr2.sh --stage 13 --stop_stage 13 --gpu_kmeans true --kmeans_opts --batch_bins 400000 --nj 4 --kmeans_feature wavlm_large/21 --nclusters 2000 --ngpu 1 --inference_asr_model valid.cer_ctc.ave.pth --src_lang wavlm_large_21_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu.yaml --inference_config conf/decode_ctc1.0.yaml --train_set train --valid_set dev --test_sets dev --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_21_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-10-25T22:21:45 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-10-25T22:21:45 (asr2.sh:1420:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2024-10-25T22:21:45 (asr2.sh:1463:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2024-10-25T22:21:45 (asr2.sh:1467:main) ASR training started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/train.log'
2024-10-25 22:21:48,128 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_bpemodel data/token_list/src_bpe_unigram6000_rm_wavlm_large_21_km2000/bpe.model --src_token_type bpe --src_token_list data/token_list/src_bpe_unigram6000_rm_wavlm_large_21_km2000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type dump/raw/dev/text.rm.wavlm_large_21_km2000,src_text,text --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/valid/src_text_shape.bpe --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000 --config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu.yaml --train_data_path_and_name_and_type dump/raw/train/text.rm.wavlm_large_21_km2000,src_text,text --train_data_path_and_name_and_type dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/train/src_text_shape.bpe --train_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/train/text_shape.bpe
2024-10-25 22:21:48,161 (launch:348) INFO: log file: exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/train.log
2024-10-25T22:25:35 (asr2.sh:288:main) ./asr2.sh --stage 13 --stop_stage 13 --gpu_kmeans true --kmeans_opts --batch_bins 400000 --nj 4 --kmeans_feature wavlm_large/21 --nclusters 2000 --ngpu 1 --inference_asr_model valid.cer_ctc.ave.pth --src_lang wavlm_large_21_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu.yaml --inference_config conf/decode_ctc1.0.yaml --train_set train --valid_set dev --test_sets dev --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_21_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-10-25T22:25:35 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-10-25T22:25:35 (asr2.sh:1420:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2024-10-25T22:25:35 (asr2.sh:1463:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2024-10-25T22:25:35 (asr2.sh:1467:main) ASR training started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/train.log'
2024-10-25 22:25:35,505 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_bpemodel data/token_list/src_bpe_unigram6000_rm_wavlm_large_21_km2000/bpe.model --src_token_type bpe --src_token_list data/token_list/src_bpe_unigram6000_rm_wavlm_large_21_km2000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type dump/raw/dev/text.rm.wavlm_large_21_km2000,src_text,text --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/valid/src_text_shape.bpe --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000 --config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu.yaml --train_data_path_and_name_and_type dump/raw/train/text.rm.wavlm_large_21_km2000,src_text,text --train_data_path_and_name_and_type dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/train/src_text_shape.bpe --train_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/train/text_shape.bpe
2024-10-25 22:25:35,522 (launch:348) INFO: log file: exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/train.log
2024-10-25T22:41:46 (asr2.sh:288:main) ./asr2.sh --stage 13 --stop_stage 13 --gpu_kmeans true --kmeans_opts --batch_bins 400000 --nj 4 --kmeans_feature wavlm_large/21 --nclusters 2000 --ngpu 1 --inference_asr_model valid.cer_ctc.ave.pth --src_lang wavlm_large_21_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu.yaml --inference_config conf/decode_ctc1.0.yaml --train_set train --valid_set dev --test_sets dev --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_21_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-10-25T22:41:46 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-10-25T22:41:46 (asr2.sh:1420:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2024-10-25T22:41:46 (asr2.sh:1463:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2024-10-25T22:41:46 (asr2.sh:1467:main) ASR training started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/train.log'
2024-10-25 22:41:47,037 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_bpemodel data/token_list/src_bpe_unigram6000_rm_wavlm_large_21_km2000/bpe.model --src_token_type bpe --src_token_list data/token_list/src_bpe_unigram6000_rm_wavlm_large_21_km2000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type dump/raw/dev/text.rm.wavlm_large_21_km2000,src_text,text --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/valid/src_text_shape.bpe --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000 --config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu.yaml --train_data_path_and_name_and_type dump/raw/train/text.rm.wavlm_large_21_km2000,src_text,text --train_data_path_and_name_and_type dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/train/src_text_shape.bpe --train_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/train/text_shape.bpe
2024-10-25 22:41:47,054 (launch:348) INFO: log file: exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/train.log
run.pl: job failed, log is in exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/train.log
Command '['run.pl', '--name', 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/train.log', '--gpu', '1', 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/train.log', 'python3', '-m', 'espnet2.bin.mt_train', '--use_preprocessor', 'true', '--bpemodel', 'data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model', '--token_type', 'bpe', '--token_list', 'data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt', '--src_bpemodel', 'data/token_list/src_bpe_unigram6000_rm_wavlm_large_21_km2000/bpe.model', '--src_token_type', 'bpe', '--src_token_list', 'data/token_list/src_bpe_unigram6000_rm_wavlm_large_21_km2000/tokens.txt', '--non_linguistic_symbols', 'none', '--cleaner', 'none', '--g2p', 'none', '--valid_data_path_and_name_and_type', 'dump/raw/dev/text.ts.en,text,text', '--valid_data_path_and_name_and_type', 'dump/raw/dev/text.rm.wavlm_large_21_km2000,src_text,text', '--valid_shape_file', 'exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/valid/text_shape.bpe', '--valid_shape_file', 'exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/valid/src_text_shape.bpe', '--resume', 'true', '--ignore_init_mismatch', 'false', '--fold_length', '150', '--fold_length', '150', '--output_dir', 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000', '--config', 'conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu.yaml', '--train_data_path_and_name_and_type', 'dump/raw/train/text.rm.wavlm_large_21_km2000,src_text,text', '--train_data_path_and_name_and_type', 'dump/raw/train/text.ts.en,text,text', '--train_shape_file', 'exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/train/src_text_shape.bpe', '--train_shape_file', 'exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/train/text_shape.bpe', '--ngpu', '1', '--multiprocessing_distributed', 'True']' returned non-zero exit status 1.
Traceback (most recent call last):
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/data/mohan/workdir/espnet/espnet2/bin/launch.py", line 384, in <module>
    main()
  File "/data/mohan/workdir/espnet/espnet2/bin/launch.py", line 375, in main
    raise RuntimeError(
RuntimeError: 
################### The last 1000 lines of exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/train.log ###################
# python3 -m espnet2.bin.mt_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_bpemodel data/token_list/src_bpe_unigram6000_rm_wavlm_large_21_km2000/bpe.model --src_token_type bpe --src_token_list data/token_list/src_bpe_unigram6000_rm_wavlm_large_21_km2000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type dump/raw/dev/text.rm.wavlm_large_21_km2000,src_text,text --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/valid/src_text_shape.bpe --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000 --config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu.yaml --train_data_path_and_name_and_type dump/raw/train/text.rm.wavlm_large_21_km2000,src_text,text --train_data_path_and_name_and_type dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/train/src_text_shape.bpe --train_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/train/text_shape.bpe --ngpu 1 --multiprocessing_distributed True 
# Started at Fri Oct 25 22:41:47 PDT 2024
#
/data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/mt_train.py --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_bpemodel data/token_list/src_bpe_unigram6000_rm_wavlm_large_21_km2000/bpe.model --src_token_type bpe --src_token_list data/token_list/src_bpe_unigram6000_rm_wavlm_large_21_km2000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type dump/raw/dev/text.rm.wavlm_large_21_km2000,src_text,text --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/valid/src_text_shape.bpe --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000 --config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu.yaml --train_data_path_and_name_and_type dump/raw/train/text.rm.wavlm_large_21_km2000,src_text,text --train_data_path_and_name_and_type dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/train/src_text_shape.bpe --train_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/train/text_shape.bpe --ngpu 1 --multiprocessing_distributed True
[SPAPL-Psychic] 2024-10-25 22:41:53,906 (mt:347) INFO: Vocabulary size: 5000
[SPAPL-Psychic] 2024-10-25 22:41:53,907 (mt:361) INFO: Source vocabulary size: 6000
[SPAPL-Psychic] 2024-10-25 22:41:54,827 (abs_task:1387) INFO: pytorch.version=2.3.0+cu121, cuda.available=True, cudnn.version=8902, cudnn.benchmark=False, cudnn.deterministic=True
[SPAPL-Psychic] 2024-10-25 22:41:54,834 (abs_task:1388) INFO: Model structure:
ESPnetDiscreteASRModel(
  (frontend): Embedding(
    (embed): Sequential(
      (0): Embedding(6000, 512)
      (1): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (encoder): EBranchformerEncoder(
    (embed): Conv1dSubsampling2(
      (conv): Sequential(
        (0): Conv1d(512, 256, kernel_size=(3,), stride=(1,))
        (1): ReLU()
        (2): Conv1d(256, 256, kernel_size=(3,), stride=(2,))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): RelPositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (encoders): MultiSequential(
      (0): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (1): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (2): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (3): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (4): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (5): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (6): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (7): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (8): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (9): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (10): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (11): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embed): Sequential(
      (0): Embedding(5000, 256)
      (1): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
    (output_layer): Linear(in_features=256, out_features=5000, bias=True)
    (decoders): MultiSequential(
      (0): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (criterion_mt): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
  (specaug): SpecAug(
    (time_mask): MaskAlongAxisVariableMaxWidth(mask_width_ratio_range=[0.0, 0.05], num_mask=10, axis=time)
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5000, bias=True)
    (ctc_loss): CTCLoss()
  )
)

Model summary:
    Class Name: ESPnetDiscreteASRModel
    Total Number of model parameters: 40.36 M
    Number of trainable parameters: 40.36 M (100.0%)
    Size: 161.45 MB
    Type: torch.float32
[SPAPL-Psychic] 2024-10-25 22:41:54,834 (abs_task:1391) INFO: Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.002
    lr: 1.3333333333333336e-07
    maximize: False
    weight_decay: 1e-06
)
[SPAPL-Psychic] 2024-10-25 22:41:54,834 (abs_task:1392) INFO: Scheduler: WarmupLR(warmup_steps=15000)
[SPAPL-Psychic] 2024-10-25 22:41:54,834 (abs_task:1401) INFO: Saving the configuration in exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/config.yaml
[SPAPL-Psychic] 2024-10-25 22:41:55,589 (abs_task:1810) INFO: [train] dataset:
ESPnetDataset(
  src_text: {"path": "dump/raw/train/text.rm.wavlm_large_21_km2000", "type": "text"}
  text: {"path": "dump/raw/train/text.ts.en", "type": "text"}
  preprocess: <espnet2.train.preprocessor.MutliTokenizerCommonPreprocessor object at 0x7f7868024d90>)
[SPAPL-Psychic] 2024-10-25 22:41:55,589 (abs_task:1811) INFO: [train] Batch sampler: NumElementsBatchSampler(N-batch=1101, batch_bins=64000000, sort_in_batch=descending, sort_batch=descending)
[SPAPL-Psychic] 2024-10-25 22:41:55,590 (abs_task:1812) INFO: [train] mini-batch sizes summary: N-batch=1101, mean=50.6, min=6, max=378
[SPAPL-Psychic] 2024-10-25 22:41:55,661 (abs_task:1810) INFO: [valid] dataset:
ESPnetDataset(
  text: {"path": "dump/raw/dev/text.ts.en", "type": "text"}
  src_text: {"path": "dump/raw/dev/text.rm.wavlm_large_21_km2000", "type": "text"}
  preprocess: <espnet2.train.preprocessor.MutliTokenizerCommonPreprocessor object at 0x7f7862d1f760>)
[SPAPL-Psychic] 2024-10-25 22:41:55,661 (abs_task:1811) INFO: [valid] Batch sampler: NumElementsBatchSampler(N-batch=237, batch_bins=64000000, sort_in_batch=descending, sort_batch=descending)
[SPAPL-Psychic] 2024-10-25 22:41:55,661 (abs_task:1812) INFO: [valid] mini-batch sizes summary: N-batch=237, mean=38.1, min=8, max=159
[SPAPL-Psychic] 2024-10-25 22:41:55,664 (trainer:311) INFO: 1/70epoch started
Traceback (most recent call last):
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_train.py", line 23, in <module>
    main()
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_train.py", line 19, in main
    MTTask.main(cmd=cmd)
  File "/data/mohan/workdir/espnet/espnet2/tasks/abs_task.py", line 1210, in main
    cls.main_worker(args)
  File "/data/mohan/workdir/espnet/espnet2/tasks/abs_task.py", line 1571, in main_worker
    cls.trainer.run(
  File "/data/mohan/workdir/espnet/espnet2/train/trainer.py", line 317, in run
    all_steps_are_invalid = cls.train_one_epoch(
  File "/data/mohan/workdir/espnet/espnet2/train/trainer.py", line 614, in train_one_epoch
    retval = model(**batch)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/mohan/workdir/espnet/espnet2/asr/discrete_asr_espnet_model.py", line 139, in forward
    encoder_out, encoder_out_lens = self.encode(src_text, src_text_lengths)
  File "/data/mohan/workdir/espnet/espnet2/asr/discrete_asr_espnet_model.py", line 240, in encode
    encoder_out, encoder_out_lens, _ = self.encoder(feats, feats_lengths)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/mohan/workdir/espnet/espnet2/asr/encoder/e_branchformer_encoder.py", line 495, in forward
    xs_pad, masks = self.encoders(xs_pad, masks)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/mohan/workdir/espnet/espnet/nets/pytorch_backend/transformer/repeat.py", line 30, in forward
    args = m(*args)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/mohan/workdir/espnet/espnet2/asr/encoder/e_branchformer_encoder.py", line 146, in forward
    x_att = self.attn(x1, x1, x1, pos_emb, mask)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/mohan/workdir/espnet/espnet/nets/pytorch_backend/transformer/attention.py", line 433, in forward
    return self.forward_attention(v, scores, mask)
  File "/data/mohan/workdir/espnet/espnet/nets/pytorch_backend/transformer/attention.py", line 140, in forward_attention
    p_attn = self.dropout(self.attn)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/dropout.py", line 59, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/functional.py", line 1295, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 
# Accounting: time=12 threads=1
# Ended (code 1) at Fri Oct 25 22:41:59 PDT 2024, elapsed time 12 seconds

>>>>>>> 03a9f0ca90290a3f0224bfc973394f3baef8bb64
>>>>>>> 0c3485d9898a9adda8d2aefb5489b5566b74ab42
2024-10-25T23:10:18 (asr2.sh:288:main) ./asr2.sh --stage 13 --stop_stage 13 --gpu_kmeans true --kmeans_opts --batch_bins 400000 --nj 4 --kmeans_feature wavlm_large/21 --nclusters 2000 --ngpu 1 --inference_asr_model valid.cer_ctc.ave.pth --src_lang wavlm_large_21_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu.yaml --inference_config conf/decode_ctc1.0.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_21_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-10-25T23:10:18 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-10-25T23:10:18 (asr2.sh:1420:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2024-10-25T23:10:18 (asr2.sh:1463:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2024-10-25T23:10:18 (asr2.sh:1467:main) ASR training started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/train.log'
2024-10-25 23:10:19,033 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_bpemodel data/token_list/src_bpe_unigram6000_rm_wavlm_large_21_km2000/bpe.model --src_token_type bpe --src_token_list data/token_list/src_bpe_unigram6000_rm_wavlm_large_21_km2000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type dump/raw/dev/text.rm.wavlm_large_21_km2000,src_text,text --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/valid/src_text_shape.bpe --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000 --config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu.yaml --train_data_path_and_name_and_type dump/raw/train/text.rm.wavlm_large_21_km2000,src_text,text --train_data_path_and_name_and_type dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/train/src_text_shape.bpe --train_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/train/text_shape.bpe
2024-10-25 23:10:19,046 (launch:348) INFO: log file: exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/train.log
2024-10-26T06:25:59 (asr2.sh:1786:main) Successfully finished. [elapsed=26141s]
2024-10-26T14:13:56 (asr2.sh:288:main) ./asr2.sh --stage 14 --stop_stage 14 --gpu_kmeans true --kmeans_opts --batch_bins 400000 --nj 4 --kmeans_feature wavlm_large/21 --nclusters 2000 --ngpu 1 --inference_nj 4 --inference_asr_model valid.cer_ctc.ave.pth --src_lang wavlm_large_21_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets dev test --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_21_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-10-26T14:13:56 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-10-26T14:13:56 (asr2.sh:1542:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000
2024-10-26T14:13:56 (asr2.sh:1570:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.ave/run.sh'. You can resume the process from stage 14 using this script
2024-10-26T14:13:56 (asr2.sh:1601:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.ave/dev/logdir/asr_inference.*.log'
2024-10-26T14:35:55 (asr2.sh:1601:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.ave/test/logdir/asr_inference.*.log'
2024-10-26T15:04:51 (asr2.sh:1786:main) Successfully finished. [elapsed=3055s]
2024-10-26T16:23:13 (asr2.sh:288:main) ./asr2.sh --stage 13 --stop_stage 13 --gpu_kmeans true --kmeans_opts --batch_bins 400000 --nj 4 --kmeans_feature wavlm_large/21 --nclusters 2000 --ngpu 1 --src_lang wavlm_large_21_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_1gpu.yaml --inference_config conf/decode_ctc0.3.yaml --train_set train --valid_set dev --test_sets dev test --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_21_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-10-26T16:23:13 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-10-26T16:23:13 (asr2.sh:1420:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2024-10-26T16:23:13 (asr2.sh:1463:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2024-10-26T16:23:13 (asr2.sh:1467:main) ASR training started... log: 'exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/train.log'
2024-10-26 16:23:13,468 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_bpemodel data/token_list/src_bpe_unigram6000_rm_wavlm_large_21_km2000/bpe.model --src_token_type bpe --src_token_list data/token_list/src_bpe_unigram6000_rm_wavlm_large_21_km2000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type dump/raw/dev/text.rm.wavlm_large_21_km2000,src_text,text --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/valid/src_text_shape.bpe --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000 --config conf/train_discrete_asr_e_branchformer1_1gpu.yaml --train_data_path_and_name_and_type dump/raw/train/text.rm.wavlm_large_21_km2000,src_text,text --train_data_path_and_name_and_type dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/train/src_text_shape.bpe --train_shape_file exp/asr_stats_raw_rm_wavlm_large_21_km2000_bpe6000_bpe5000/train/text_shape.bpe
2024-10-26 16:23:13,481 (launch:348) INFO: log file: exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/train.log
2024-10-27T02:51:13 (asr2.sh:1786:main) Successfully finished. [elapsed=37680s]
2024-10-27T12:30:39 (asr2.sh:288:main) ./asr2.sh --stage 14 --stop_stage 14 --gpu_kmeans true --kmeans_opts --batch_bins 400000 --nj 4 --kmeans_feature wavlm_large/21 --nclusters 2000 --ngpu 1 --src_lang wavlm_large_21_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_1gpu.yaml --inference_config conf/decode_ctc0.3_greedy.yaml --train_set train --valid_set dev --test_sets dev test --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_21_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-10-27T12:30:39 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-10-27T12:30:39 (asr2.sh:1542:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000
2024-10-27T12:30:39 (asr2.sh:1570:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_greedy_asr_model_valid.acc.ave/run.sh'. You can resume the process from stage 14 using this script
2024-10-27T12:30:39 (asr2.sh:1601:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_greedy_asr_model_valid.acc.ave/dev/logdir/asr_inference.*.log'
2024-10-27T18:00:21 (asr2.sh:1601:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_greedy_asr_model_valid.acc.ave/test/logdir/asr_inference.*.log'
2024-10-28T01:08:09 (asr2.sh:1786:main) Successfully finished. [elapsed=45450s]
2024-10-28T13:39:34 (asr2.sh:288:main) ./asr2.sh --stage 14 --stop_stage 14 --gpu_kmeans true --kmeans_opts --batch_bins 400000 --nj 4 --kmeans_feature wavlm_large/21 --nclusters 2000 --ngpu 1 --src_lang wavlm_large_21_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_1gpu.yaml --inference_config conf/decode_ctc0.3_greedy.yaml --train_set train --valid_set dev --test_sets dev test --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_21_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-10-28T13:39:35 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-10-28T13:39:35 (asr2.sh:1542:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000
2024-10-28T13:39:35 (asr2.sh:1570:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_greedy_asr_model_valid.acc.ave/run.sh'. You can resume the process from stage 14 using this script
2024-10-28T13:39:35 (asr2.sh:1601:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_greedy_asr_model_valid.acc.ave/dev/logdir/asr_inference.*.log'
2024-10-28T14:00:50 (asr2.sh:1601:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc0.3_greedy_asr_model_valid.acc.ave/test/logdir/asr_inference.*.log'
2024-10-28T14:24:42 (asr2.sh:1786:main) Successfully finished. [elapsed=2708s]
2024-10-28T18:03:03 (asr2.sh:288:main) ./asr2.sh --stage 14 --stop_stage 14 --gpu_kmeans true --kmeans_opts --batch_bins 400000 --nj 4 --kmeans_feature wavlm_large/21 --nclusters 2000 --ngpu 1 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --src_lang wavlm_large_21_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets dev test --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_21_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-10-28T18:03:03 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-10-28T18:03:03 (asr2.sh:1542:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000
2024-10-28T18:03:03 (asr2.sh:1570:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/run.sh'. You can resume the process from stage 14 using this script
2024-10-28T18:03:03 (asr2.sh:1601:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/asr_inference.*.log'
2024-10-28T18:32:02 (asr2.sh:1601:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/test/logdir/asr_inference.*.log'
2024-10-28T19:11:14 (asr2.sh:1786:main) Successfully finished. [elapsed=4091s]
2024-11-06T19:47:50 (asr2_hf.sh:288:main) ./asr2_hf.sh --stage 13 --stop_stage 13 --gpu_kmeans true --kmeans_opts --batch_bins 1 --nj 8 --kmeans_feature wavlm_large_fintune/24 --nclusters 2000 --ngpu 1 --nj 4 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --src_lang wavlm_large_fintune_24_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_fintune_24_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-11-06T19:47:50 (asr2_hf.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-11-06T19:47:50 (asr2_hf.sh:1423:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2024-11-06T19:47:50 (asr2_hf.sh:1466:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_fintune_24_km2000_bpe_rm6000_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2024-11-06T19:47:50 (asr2_hf.sh:1470:main) ASR training started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_fintune_24_km2000_bpe_rm6000_bpe_ts5000/train.log'
2024-11-06 19:47:50,299 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_fintune_24_km2000_bpe_rm6000_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_fintune_24_km2000_bpe_rm6000_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_fintune_24_km2000_bpe_rm6000_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_bpemodel data/token_list/src_bpe_unigram6000_rm_wavlm_large_fintune_24_km2000/bpe.model --src_token_type bpe --src_token_list data/token_list/src_bpe_unigram6000_rm_wavlm_large_fintune_24_km2000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type dump/raw/dev/text.rm.wavlm_large_fintune_24_km2000,src_text,text --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_fintune_24_km2000_bpe6000_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_fintune_24_km2000_bpe6000_bpe5000/valid/src_text_shape.bpe --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_fintune_24_km2000_bpe_rm6000_bpe_ts5000 --config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu.yaml --train_data_path_and_name_and_type dump/raw/train/text.rm.wavlm_large_fintune_24_km2000,src_text,text --train_data_path_and_name_and_type dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_rm_wavlm_large_fintune_24_km2000_bpe6000_bpe5000/train/src_text_shape.bpe --train_shape_file exp/asr_stats_raw_rm_wavlm_large_fintune_24_km2000_bpe6000_bpe5000/train/text_shape.bpe
2024-11-06 19:47:50,317 (launch:348) INFO: log file: exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_fintune_24_km2000_bpe_rm6000_bpe_ts5000/train.log
./asr2_hf.sh: line 1674: syntax error near unexpected token `('
2024-11-07T10:22:30 (asr2_hf.sh:288:main) ./asr2_hf.sh --stage 14 --stop_stage 14 --gpu_kmeans true --kmeans_opts --batch_bins 1 --nj 8 --kmeans_feature wavlm_large_fintune/24 --nclusters 2000 --ngpu 1 --nj 4 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --src_lang wavlm_large_fintune_24_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_fintune_24_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-11-07T10:22:30 (asr2_hf.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-11-07T10:22:30 (asr2_hf.sh:1545:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_fintune_24_km2000_bpe_rm6000_bpe_ts5000
2024-11-07T10:22:30 (asr2_hf.sh:1573:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_fintune_24_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/run.sh'. You can resume the process from stage 14 using this script
2024-11-07T10:22:30 (asr2_hf.sh:1604:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_fintune_24_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/test/logdir/asr_inference.*.log'
2024-11-07T10:22:56 (asr2_hf.sh:288:main) ./asr2_hf.sh --stage 14 --stop_stage 14 --gpu_kmeans true --kmeans_opts --batch_bins 1 --nj 8 --kmeans_feature wavlm_large_fintune/24 --nclusters 2000 --ngpu 1 --nj 4 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --src_lang wavlm_large_fintune_24_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets dev test --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_fintune_24_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-11-07T10:22:56 (asr2_hf.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-11-07T10:22:56 (asr2_hf.sh:1545:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_fintune_24_km2000_bpe_rm6000_bpe_ts5000
2024-11-07T10:22:56 (asr2_hf.sh:1573:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_fintune_24_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/run.sh'. You can resume the process from stage 14 using this script
2024-11-07T10:22:56 (asr2_hf.sh:1604:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_fintune_24_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/asr_inference.*.log'
2024-11-07T10:31:48 (asr2_hf.sh:288:main) ./asr2_hf.sh --stage 13 --stop_stage 13 --gpu_kmeans true --kmeans_opts --batch_bins 1 --nj 8 --kmeans_feature wavlm_large_fintune/21 --nclusters 2000 --ngpu 1 --nj 4 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --src_lang wavlm_large_fintune_21_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_fintune_21_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-11-07T10:31:48 (asr2_hf.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-11-07T10:31:48 (asr2_hf.sh:1423:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2024-11-07T10:31:48 (asr2_hf.sh:1466:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_fintune_21_km2000_bpe_rm6000_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2024-11-07T10:31:48 (asr2_hf.sh:1470:main) ASR training started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_fintune_21_km2000_bpe_rm6000_bpe_ts5000/train.log'
2024-11-07 10:31:48,978 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_fintune_21_km2000_bpe_rm6000_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_fintune_21_km2000_bpe_rm6000_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_fintune_21_km2000_bpe_rm6000_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_bpemodel data/token_list/src_bpe_unigram6000_rm_wavlm_large_fintune_21_km2000/bpe.model --src_token_type bpe --src_token_list data/token_list/src_bpe_unigram6000_rm_wavlm_large_fintune_21_km2000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type dump/raw/dev/text.rm.wavlm_large_fintune_21_km2000,src_text,text --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_fintune_21_km2000_bpe6000_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_fintune_21_km2000_bpe6000_bpe5000/valid/src_text_shape.bpe --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_fintune_21_km2000_bpe_rm6000_bpe_ts5000 --config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu.yaml --train_data_path_and_name_and_type dump/raw/train/text.rm.wavlm_large_fintune_21_km2000,src_text,text --train_data_path_and_name_and_type dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_rm_wavlm_large_fintune_21_km2000_bpe6000_bpe5000/train/src_text_shape.bpe --train_shape_file exp/asr_stats_raw_rm_wavlm_large_fintune_21_km2000_bpe6000_bpe5000/train/text_shape.bpe
2024-11-07 10:31:48,992 (launch:348) INFO: log file: exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_fintune_21_km2000_bpe_rm6000_bpe_ts5000/train.log
2024-11-07T10:44:58 (asr2_hf.sh:1604:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_fintune_24_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/test/logdir/asr_inference.*.log'
./asr2_hf.sh: line 1625: syntax error near unexpected token `done'
2024-11-07T16:35:34 (asr2_hf.sh:1789:main) Successfully finished. [elapsed=21826s]
2024-11-07T17:27:03 (asr2.sh:288:main) ./asr2.sh --stage 6 --stop_stage 7 --gpu_kmeans true --kmeans_opts --batch_bins 1 --nj 4 --kmeans_feature wavlm_large/24 --nclusters 2000 --ngpu 1 --nj 4 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --src_lang wavlm_large_24_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_24_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-11-07T17:27:03 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-11-07T17:27:03 (asr2.sh:953:main) Stage 6: dump/extracted -> dump/raw
2024-11-07T17:27:03 (asr2.sh:1074:main) Stage 7b: Generate token_list from dump/raw/train/text.rm.wavlm_large_24_km2000 using BPE for src_lang
sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=data/token_list/src_bpe_unigram6000_rm_wavlm_large_24_km2000/train.txt --vocab_size=6000 --model_type=unigram --model_prefix=data/token_list/src_bpe_unigram6000_rm_wavlm_large_24_km2000/bpe --character_coverage=1.0 --input_sentence_size=100000000
sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : 
trainer_spec {
  input: data/token_list/src_bpe_unigram6000_rm_wavlm_large_24_km2000/train.txt
  input_format: 
  model_prefix: data/token_list/src_bpe_unigram6000_rm_wavlm_large_24_km2000/bpe
  model_type: UNIGRAM
  vocab_size: 6000
  self_test_sample_size: 0
  character_coverage: 1
  input_sentence_size: 100000000
  shuffle_input_sentence: 1
  seed_sentencepiece_size: 1000000
  shrinking_factor: 0.75
  max_sentence_length: 4192
  num_threads: 16
  num_sub_iterations: 2
  max_sentencepiece_length: 16
  split_by_unicode_script: 1
  split_by_number: 1
  split_by_whitespace: 1
  split_digits: 0
  treat_whitespace_as_suffix: 0
  allow_whitespace_only_pieces: 0
  required_chars: 
  byte_fallback: 0
  vocabulary_output_piece_score: 1
  train_extremely_large_corpus: 0
  hard_vocab_limit: 1
  use_all_vocab: 0
  unk_id: 0
  bos_id: 1
  eos_id: 2
  pad_id: -1
  unk_piece: <unk>
  bos_piece: <s>
  eos_piece: </s>
  pad_piece: <pad>
  unk_surface:   
  enable_differential_privacy: 0
  differential_privacy_noise_level: 0
  differential_privacy_clipping_threshold: 0
}
normalizer_spec {
  name: nmt_nfkc
  add_dummy_prefix: 1
  remove_extra_whitespaces: 1
  escape_whitespaces: 1
  normalization_rule_tsv: 
}
denormalizer_spec {}
trainer_interface.cc(350) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.
trainer_interface.cc(181) LOG(INFO) Loading corpus: data/token_list/src_bpe_unigram6000_rm_wavlm_large_24_km2000/train.txt
trainer_interface.cc(406) LOG(INFO) Loaded all 55702 sentences
trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <unk>
trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <s>
trainer_interface.cc(422) LOG(INFO) Adding meta_piece: </s>
trainer_interface.cc(427) LOG(INFO) Normalizing sentences...
trainer_interface.cc(536) LOG(INFO) all chars count=15553435
trainer_interface.cc(557) LOG(INFO) Alphabet size=2001
trainer_interface.cc(558) LOG(INFO) Final character coverage=1
trainer_interface.cc(590) LOG(INFO) Done! preprocessed 55702 sentences.
unigram_model_trainer.cc(146) LOG(INFO) Making suffix array...
unigram_model_trainer.cc(150) LOG(INFO) Extracting frequent sub strings...
unigram_model_trainer.cc(201) LOG(INFO) Initialized 1000000 seed sentencepieces
trainer_interface.cc(596) LOG(INFO) Tokenizing input sentences with whitespace: 55702
trainer_interface.cc(607) LOG(INFO) Done! 55690
unigram_model_trainer.cc(491) LOG(INFO) Using 55690 sentences for EM training
unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=0 size=758576 obj=955.876 num_tokens=4111860 num_tokens/piece=5.4205
unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=1 size=663033 obj=906.055 num_tokens=4114586 num_tokens/piece=6.2057
unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=0 size=495062 obj=912.798 num_tokens=4197353 num_tokens/piece=8.47844
unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=1 size=492172 obj=907.509 num_tokens=4198118 num_tokens/piece=8.52978
unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=0 size=368937 obj=925.1 num_tokens=4339384 num_tokens/piece=11.7619
unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=1 size=368543 obj=919.32 num_tokens=4339726 num_tokens/piece=11.7754
2024-11-07T17:27:45 (asr2_hf.sh:288:main) ./asr2_hf.sh --stage 14 --stop_stage 14 --gpu_kmeans true --kmeans_opts --batch_bins 1 --nj 8 --kmeans_feature wavlm_large_fintune/21 --nclusters 2000 --ngpu 1 --nj 4 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --src_lang wavlm_large_fintune_21_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets dev test --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_fintune_21_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-11-07T17:27:46 (asr2_hf.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-11-07T17:27:46 (asr2_hf.sh:1545:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_fintune_21_km2000_bpe_rm6000_bpe_ts5000
2024-11-07T17:27:46 (asr2_hf.sh:1573:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_fintune_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/run.sh'. You can resume the process from stage 14 using this script
2024-11-07T17:27:46 (asr2_hf.sh:1604:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_fintune_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/asr_inference.*.log'
2024-11-07T17:43:29 (asr2_hf.sh:1604:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_fintune_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/test/logdir/asr_inference.*.log'
2024-11-07T18:04:24 (asr2_hf.sh:1789:main) Successfully finished. [elapsed=2199s]
2024-11-07T18:35:07 (asr2.sh:288:main) ./asr2.sh --stage 13 --stop_stage 13 --gpu_kmeans true --kmeans_opts --batch_bins 1 --nj 4 --kmeans_feature wavlm_large/24 --nclusters 2000 --ngpu 1 --nj 4 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --src_lang wavlm_large_24_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_24_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-11-07T18:35:07 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-11-07T18:35:07 (asr2.sh:1423:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2024-11-07T18:35:07 (asr2.sh:1466:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_24_km2000_bpe_rm6000_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2024-11-07T18:35:07 (asr2.sh:1470:main) ASR training started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_24_km2000_bpe_rm6000_bpe_ts5000/train.log'
2024-11-07 18:35:07,381 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_24_km2000_bpe_rm6000_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_24_km2000_bpe_rm6000_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_24_km2000_bpe_rm6000_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_bpemodel data/token_list/src_bpe_unigram6000_rm_wavlm_large_24_km2000/bpe.model --src_token_type bpe --src_token_list data/token_list/src_bpe_unigram6000_rm_wavlm_large_24_km2000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type dump/raw/dev/text.rm.wavlm_large_24_km2000,src_text,text --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_24_km2000_bpe6000_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_24_km2000_bpe6000_bpe5000/valid/src_text_shape.bpe --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_24_km2000_bpe_rm6000_bpe_ts5000 --config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu.yaml --train_data_path_and_name_and_type dump/raw/train/text.rm.wavlm_large_24_km2000,src_text,text --train_data_path_and_name_and_type dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_rm_wavlm_large_24_km2000_bpe6000_bpe5000/train/src_text_shape.bpe --train_shape_file exp/asr_stats_raw_rm_wavlm_large_24_km2000_bpe6000_bpe5000/train/text_shape.bpe
2024-11-07 18:35:07,394 (launch:348) INFO: log file: exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_24_km2000_bpe_rm6000_bpe_ts5000/train.log
2024-11-08T01:46:18 (asr2.sh:1789:main) Successfully finished. [elapsed=25871s]
2024-11-08T11:06:39 (asr2.sh:288:main) ./asr2.sh --stage 14 --stop_stage 14 --gpu_kmeans true --kmeans_opts --batch_bins 1 --nj 4 --kmeans_feature wavlm_large/24 --nclusters 2000 --ngpu 1 --nj 4 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --src_lang wavlm_large_24_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets dev test --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_24_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-11-08T11:06:39 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-11-08T11:06:39 (asr2.sh:1545:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_24_km2000_bpe_rm6000_bpe_ts5000
2024-11-08T11:06:39 (asr2.sh:1573:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_24_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/run.sh'. You can resume the process from stage 14 using this script
2024-11-08T11:06:39 (asr2.sh:1604:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_24_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/asr_inference.*.log'
2024-11-08T11:25:05 (asr2.sh:1604:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_24_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/test/logdir/asr_inference.*.log'
2024-11-08T11:49:56 (asr2.sh:1789:main) Successfully finished. [elapsed=2597s]
2024-11-17T02:23:09 (asr2.sh:288:main) ./asr2.sh --stage 13 --stop_stage 13 --gpu_kmeans true --kmeans_opts --batch_bins 1 --nj 4 --kmeans_feature wavlm_large_libri100/21 --nclusters 2000 --ngpu 1 --nj 4 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --src_lang wavlm_large_libri100_21_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_libri100_21_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-11-17T02:23:09 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-11-17T02:23:09 (asr2.sh:1424:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2024-11-17T02:23:09 (asr2.sh:1467:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_libri100_21_km2000_bpe_rm6000_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2024-11-17T02:23:09 (asr2.sh:1471:main) ASR training started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_libri100_21_km2000_bpe_rm6000_bpe_ts5000/train.log'
2024-11-17 02:23:09,232 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_libri100_21_km2000_bpe_rm6000_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_libri100_21_km2000_bpe_rm6000_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_libri100_21_km2000_bpe_rm6000_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_bpemodel data/token_list/src_bpe_unigram6000_rm_wavlm_large_libri100_21_km2000/bpe.model --src_token_type bpe --src_token_list data/token_list/src_bpe_unigram6000_rm_wavlm_large_libri100_21_km2000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type dump/raw/dev/text.rm.wavlm_large_libri100_21_km2000,src_text,text --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_libri100_21_km2000_bpe6000_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_libri100_21_km2000_bpe6000_bpe5000/valid/src_text_shape.bpe --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_libri100_21_km2000_bpe_rm6000_bpe_ts5000 --config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu.yaml --train_data_path_and_name_and_type dump/raw/train/text.rm.wavlm_large_libri100_21_km2000,src_text,text --train_data_path_and_name_and_type dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_rm_wavlm_large_libri100_21_km2000_bpe6000_bpe5000/train/src_text_shape.bpe --train_shape_file exp/asr_stats_raw_rm_wavlm_large_libri100_21_km2000_bpe6000_bpe5000/train/text_shape.bpe
2024-11-17 02:23:09,245 (launch:348) INFO: log file: exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_libri100_21_km2000_bpe_rm6000_bpe_ts5000/train.log
2024-11-17T04:34:18 (asr2.sh:1790:main) Successfully finished. [elapsed=7869s]
2024-11-17T11:35:09 (asr2.sh:288:main) ./asr2.sh --stage 14 --stop_stage 14 --gpu_kmeans true --kmeans_opts --batch_bins 1 --nj 4 --kmeans_feature wavlm_large_libri100/21 --nclusters 2000 --ngpu 1 --nj 4 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --src_lang wavlm_large_libri100_21_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets dev test --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_libri100_21_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2024-11-17T11:35:09 (asr2.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2024-11-17T11:35:09 (asr2.sh:1546:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_libri100_21_km2000_bpe_rm6000_bpe_ts5000
2024-11-17T11:35:09 (asr2.sh:1574:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_libri100_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/run.sh'. You can resume the process from stage 14 using this script
2024-11-17T11:35:09 (asr2.sh:1605:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_libri100_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/asr_inference.*.log'
2024-11-17T11:52:55 (asr2.sh:1605:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_raw_wavlm_large_libri100_21_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/test/logdir/asr_inference.*.log'
2024-11-17T12:16:25 (asr2.sh:1790:main) Successfully finished. [elapsed=2476s]
2025-01-10T03:06:15 (asr2_hf.sh:288:main) ./asr2_hf.sh --stage 13 --stop_stage 13 --gpu_kmeans true --portion 1.0 --kmeans_opts --batch_bins 1 --nj 8 --kmeans_feature wavlm_large_finetune/24 --nclusters 2000 --ngpu 1 --nj 4 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang wavlm_large_finetune_24_km2000 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets dev test --src_bpe_train_text dump/raw/train/text.ts.wavlm_large_finetune_24_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-01-10T03:06:15 (asr2_hf.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2025-01-10T03:06:15 (asr2_hf.sh:1423:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-01-10T03:06:15 (asr2_hf.sh:1466:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_ts_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-01-10T03:06:15 (asr2_hf.sh:1470:main) ASR training started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_ts_bpe_ts5000/train.log'
2025-01-10 03:06:15,976 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_ts_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_ts_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_ts_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_bpemodel none --src_token_type char --src_token_list data/token_list/char_wavlm_large_finetune_24_km2000/src_tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type dump/raw/dev/text.ts.wavlm_large_finetune_24_km2000,src_text,text --valid_shape_file exp/asr_stats_raw_ts_wavlm_large_finetune_24_km2000_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_wavlm_large_finetune_24_km2000_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_ts_bpe_ts5000 --config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type dump/raw/train/text.ts.wavlm_large_finetune_24_km2000,src_text,text --train_data_path_and_name_and_type dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_wavlm_large_finetune_24_km2000_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_wavlm_large_finetune_24_km2000_char_bpe5000/train/text_shape.bpe
2025-01-10 03:06:15,992 (launch:348) INFO: log file: exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_ts_bpe_ts5000/train.log
run.pl: job failed, log is in exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_ts_bpe_ts5000/train.log
Command '['run.pl', '--name', 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_ts_bpe_ts5000/train.log', '--gpu', '1', 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_ts_bpe_ts5000/train.log', 'python3', '-m', 'espnet2.bin.mt_train', '--use_preprocessor', 'true', '--bpemodel', 'data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model', '--token_type', 'bpe', '--token_list', 'data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt', '--src_bpemodel', 'none', '--src_token_type', 'char', '--src_token_list', 'data/token_list/char_wavlm_large_finetune_24_km2000/src_tokens.txt', '--non_linguistic_symbols', 'none', '--cleaner', 'none', '--g2p', 'none', '--valid_data_path_and_name_and_type', 'dump/raw/dev/text.ts.en,text,text', '--valid_data_path_and_name_and_type', 'dump/raw/dev/text.ts.wavlm_large_finetune_24_km2000,src_text,text', '--valid_shape_file', 'exp/asr_stats_raw_ts_wavlm_large_finetune_24_km2000_char_bpe5000/valid/text_shape.bpe', '--valid_shape_file', 'exp/asr_stats_raw_ts_wavlm_large_finetune_24_km2000_char_bpe5000/valid/src_text_shape.char', '--resume', 'true', '--ignore_init_mismatch', 'false', '--fold_length', '150', '--fold_length', '150', '--output_dir', 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_ts_bpe_ts5000', '--config', 'conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml', '--train_data_path_and_name_and_type', 'dump/raw/train/text.ts.wavlm_large_finetune_24_km2000,src_text,text', '--train_data_path_and_name_and_type', 'dump/raw/train/text.ts.en,text,text', '--train_shape_file', 'exp/asr_stats_raw_ts_wavlm_large_finetune_24_km2000_char_bpe5000/train/src_text_shape.char', '--train_shape_file', 'exp/asr_stats_raw_ts_wavlm_large_finetune_24_km2000_char_bpe5000/train/text_shape.bpe', '--ngpu', '1', '--multiprocessing_distributed', 'True']' returned non-zero exit status 1.
Traceback (most recent call last):
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/data/mohan/workdir/espnet/espnet2/bin/launch.py", line 384, in <module>
    main()
  File "/data/mohan/workdir/espnet/espnet2/bin/launch.py", line 375, in main
    raise RuntimeError(
RuntimeError: 
################### The last 1000 lines of exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_ts_bpe_ts5000/train.log ###################
# python3 -m espnet2.bin.mt_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_bpemodel none --src_token_type char --src_token_list data/token_list/char_wavlm_large_finetune_24_km2000/src_tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type dump/raw/dev/text.ts.wavlm_large_finetune_24_km2000,src_text,text --valid_shape_file exp/asr_stats_raw_ts_wavlm_large_finetune_24_km2000_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_wavlm_large_finetune_24_km2000_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_ts_bpe_ts5000 --config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type dump/raw/train/text.ts.wavlm_large_finetune_24_km2000,src_text,text --train_data_path_and_name_and_type dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_wavlm_large_finetune_24_km2000_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_wavlm_large_finetune_24_km2000_char_bpe5000/train/text_shape.bpe --ngpu 1 --multiprocessing_distributed True 
# Started at Fri Jan 10 03:06:16 EST 2025
#
/data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/mt_train.py --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_bpemodel none --src_token_type char --src_token_list data/token_list/char_wavlm_large_finetune_24_km2000/src_tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type dump/raw/dev/text.ts.wavlm_large_finetune_24_km2000,src_text,text --valid_shape_file exp/asr_stats_raw_ts_wavlm_large_finetune_24_km2000_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_wavlm_large_finetune_24_km2000_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_ts_bpe_ts5000 --config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type dump/raw/train/text.ts.wavlm_large_finetune_24_km2000,src_text,text --train_data_path_and_name_and_type dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_wavlm_large_finetune_24_km2000_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_wavlm_large_finetune_24_km2000_char_bpe5000/train/text_shape.bpe --ngpu 1 --multiprocessing_distributed True
[dl] 2025-01-10 03:06:22,810 (mt:347) INFO: Vocabulary size: 5000
[dl] 2025-01-10 03:06:22,811 (mt:361) INFO: Source vocabulary size: 2003
[dl] 2025-01-10 03:06:23,004 (discrete_asr_espnet_model:96) WARNING: Set decoder to none as ctc_weight==1.0
[dl] 2025-01-10 03:06:24,016 (abs_task:1387) INFO: pytorch.version=2.3.0+cu121, cuda.available=True, cudnn.version=8902, cudnn.benchmark=False, cudnn.deterministic=True
[dl] 2025-01-10 03:06:24,021 (abs_task:1388) INFO: Model structure:
ESPnetDiscreteASRModel(
  (frontend): Embedding(
    (embed): Sequential(
      (0): Embedding(2003, 512)
      (1): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (encoder): EBranchformerEncoder(
    (embed): Conv1dSubsampling2(
      (conv): Sequential(
        (0): Conv1d(512, 256, kernel_size=(3,), stride=(1,))
        (1): ReLU()
        (2): Conv1d(256, 256, kernel_size=(3,), stride=(2,))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): RelPositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (encoders): MultiSequential(
      (0): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (1): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (2): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (3): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (4): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (5): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (6): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (7): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (8): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (9): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (10): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (11): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
  )
  (criterion_mt): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
  (specaug): SpecAug(
    (time_mask): MaskAlongAxisVariableMaxWidth(mask_width_ratio_range=[0.0, 0.05], num_mask=10, axis=time)
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5000, bias=True)
    (ctc_loss): CTCLoss()
  )
)

Model summary:
    Class Name: ESPnetDiscreteASRModel
    Total Number of model parameters: 26.28 M
    Number of trainable parameters: 26.28 M (100.0%)
    Size: 105.11 MB
    Type: torch.float32
[dl] 2025-01-10 03:06:24,022 (abs_task:1391) INFO: Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 3.333333333333334e-08
    maximize: False
    weight_decay: 1e-06
)
[dl] 2025-01-10 03:06:24,022 (abs_task:1392) INFO: Scheduler: WarmupLR(warmup_steps=15000)
[dl] 2025-01-10 03:06:24,022 (abs_task:1401) INFO: Saving the configuration in exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_ts_bpe_ts5000/config.yaml
[dl] 2025-01-10 03:06:24,764 (abs_task:1810) INFO: [train] dataset:
ESPnetDataset(
  src_text: {"path": "dump/raw/train/text.ts.wavlm_large_finetune_24_km2000", "type": "text"}
  text: {"path": "dump/raw/train/text.ts.en", "type": "text"}
  preprocess: <espnet2.train.preprocessor.MutliTokenizerCommonPreprocessor object at 0x7552dd384790>)
[dl] 2025-01-10 03:06:24,765 (abs_task:1811) INFO: [train] Batch sampler: NumElementsBatchSampler(N-batch=839, batch_bins=64000000, sort_in_batch=descending, sort_batch=descending)
[dl] 2025-01-10 03:06:24,765 (abs_task:1812) INFO: [train] mini-batch sizes summary: N-batch=839, mean=66.4, min=8, max=486
[dl] 2025-01-10 03:06:24,828 (abs_task:1810) INFO: [valid] dataset:
ESPnetDataset(
  text: {"path": "dump/raw/dev/text.ts.en", "type": "text"}
  src_text: {"path": "dump/raw/dev/text.ts.wavlm_large_finetune_24_km2000", "type": "text"}
  preprocess: <espnet2.train.preprocessor.MutliTokenizerCommonPreprocessor object at 0x7552dd3858d0>)
[dl] 2025-01-10 03:06:24,829 (abs_task:1811) INFO: [valid] Batch sampler: NumElementsBatchSampler(N-batch=185, batch_bins=64000000, sort_in_batch=descending, sort_batch=descending)
[dl] 2025-01-10 03:06:24,829 (abs_task:1812) INFO: [valid] mini-batch sizes summary: N-batch=185, mean=48.8, min=11, max=133
[dl] 2025-01-10 03:06:24,831 (trainer:311) INFO: 1/70epoch started
/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
Traceback (most recent call last):
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_train.py", line 23, in <module>
    main()
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_train.py", line 19, in main
    MTTask.main(cmd=cmd)
  File "/data/mohan/workdir/espnet/espnet2/tasks/abs_task.py", line 1210, in main
    cls.main_worker(args)
  File "/data/mohan/workdir/espnet/espnet2/tasks/abs_task.py", line 1571, in main_worker
    cls.trainer.run(
  File "/data/mohan/workdir/espnet/espnet2/train/trainer.py", line 317, in run
    all_steps_are_invalid = cls.train_one_epoch(
  File "/data/mohan/workdir/espnet/espnet2/train/trainer.py", line 614, in train_one_epoch
    retval = model(**batch)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/mohan/workdir/espnet/espnet2/asr/discrete_asr_espnet_model.py", line 162, in forward
    loss_ctc, cer_ctc = self._calc_ctc_loss(
  File "/data/mohan/workdir/espnet/espnet2/asr/discrete_asr_espnet_model.py", line 316, in _calc_ctc_loss
    loss_ctc = self.ctc(encoder_out, encoder_out_lens, ys_pad, ys_pad_lens)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/mohan/workdir/espnet/espnet2/asr/ctc.py", line 180, in forward
    loss = self.loss_fn(ys_hat, ys_true, hlens, ys_lens).to(
  File "/data/mohan/workdir/espnet/espnet2/asr/ctc.py", line 77, in loss_fn
    th_pred = th_pred.log_softmax(2).float()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 278.00 MiB. GPU 
# Accounting: time=12 threads=1
# Ended (code 1) at Fri Jan 10 03:06:28 EST 2025, elapsed time 12 seconds

2025-01-10T03:09:23 (asr2_hf.sh:288:main) ./asr2_hf.sh --stage 14 --stop_stage 14 --gpu_kmeans true --portion 1.0 --kmeans_opts --batch_bins 1 --nj 8 --kmeans_feature wavlm_large_finetune/24 --nclusters 2000 --ngpu 1 --nj 4 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang wavlm_large_finetune_24_km2000 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets dev test --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_finetune_24_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-01-10T03:09:24 (asr2_hf.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2025-01-10T03:09:24 (asr2_hf.sh:1545:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000
2025-01-10T03:09:24 (asr2_hf.sh:1573:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/run.sh'. You can resume the process from stage 14 using this script
2025-01-10T03:09:24 (asr2_hf.sh:1604:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/asr_inference.*.log'
run.pl: 4 / 4 failed, log is in exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/asr_inference.*.log
# python3 -m espnet2.bin.mt_inference --batch_size 1 --ngpu 1 --data_path_and_name_and_type dump/raw/dev/text.rm.wavlm_large_finetune_24_km2000,src_text,text --key_file exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/keys.1.scp --mt_train_config exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/config.yaml --mt_model_file exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/valid.cer_ctc.best.pth --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/output.1 --config conf/decode_ctc1.0_greedy.yaml 
# Started at Fri Jan 10 03:09:24 EST 2025
#
/data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/mt_inference.py --batch_size 1 --ngpu 1 --data_path_and_name_and_type dump/raw/dev/text.rm.wavlm_large_finetune_24_km2000,src_text,text --key_file exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/keys.1.scp --mt_train_config exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/config.yaml --mt_model_file exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/valid.cer_ctc.best.pth --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/output.1 --config conf/decode_ctc1.0_greedy.yaml
2025-01-10 03:09:31,402 (abs_task:2300) INFO: config file: exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/config.yaml
Traceback (most recent call last):
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_inference.py", line 561, in <module>
    main()
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_inference.py", line 557, in main
    inference(**kwargs)
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_inference.py", line 348, in inference
    text2text = Text2Text.from_pretrained(
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_inference.py", line 269, in from_pretrained
    return Text2Text(**kwargs)
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_inference.py", line 67, in __init__
    mt_model, mt_train_args = MTTask.build_model_from_file(
  File "/data/mohan/workdir/espnet/espnet2/tasks/abs_task.py", line 2301, in build_model_from_file
    with config_file.open("r", encoding="utf-8") as f:
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/pathlib.py", line 1119, in open
    return self._accessor.open(self, mode, buffering, encoding, errors,
FileNotFoundError: [Errno 2] No such file or directory: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/config.yaml'
# Accounting: time=8 threads=1
# Ended (code 1) at Fri Jan 10 03:09:32 EST 2025, elapsed time 8 seconds
# python3 -m espnet2.bin.mt_inference --batch_size 1 --ngpu 1 --data_path_and_name_and_type dump/raw/dev/text.rm.wavlm_large_finetune_24_km2000,src_text,text --key_file exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/keys.2.scp --mt_train_config exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/config.yaml --mt_model_file exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/valid.cer_ctc.best.pth --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/output.2 --config conf/decode_ctc1.0_greedy.yaml 
# Started at Fri Jan 10 03:09:24 EST 2025
#
/data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/mt_inference.py --batch_size 1 --ngpu 1 --data_path_and_name_and_type dump/raw/dev/text.rm.wavlm_large_finetune_24_km2000,src_text,text --key_file exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/keys.2.scp --mt_train_config exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/config.yaml --mt_model_file exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/valid.cer_ctc.best.pth --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/output.2 --config conf/decode_ctc1.0_greedy.yaml
2025-01-10 03:09:31,562 (abs_task:2300) INFO: config file: exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/config.yaml
Traceback (most recent call last):
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_inference.py", line 561, in <module>
    main()
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_inference.py", line 557, in main
    inference(**kwargs)
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_inference.py", line 348, in inference
    text2text = Text2Text.from_pretrained(
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_inference.py", line 269, in from_pretrained
    return Text2Text(**kwargs)
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_inference.py", line 67, in __init__
    mt_model, mt_train_args = MTTask.build_model_from_file(
  File "/data/mohan/workdir/espnet/espnet2/tasks/abs_task.py", line 2301, in build_model_from_file
    with config_file.open("r", encoding="utf-8") as f:
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/pathlib.py", line 1119, in open
    return self._accessor.open(self, mode, buffering, encoding, errors,
FileNotFoundError: [Errno 2] No such file or directory: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/config.yaml'
# Accounting: time=8 threads=1
# Ended (code 1) at Fri Jan 10 03:09:32 EST 2025, elapsed time 8 seconds
# python3 -m espnet2.bin.mt_inference --batch_size 1 --ngpu 1 --data_path_and_name_and_type dump/raw/dev/text.rm.wavlm_large_finetune_24_km2000,src_text,text --key_file exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/keys.3.scp --mt_train_config exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/config.yaml --mt_model_file exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/valid.cer_ctc.best.pth --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/output.3 --config conf/decode_ctc1.0_greedy.yaml 
# Started at Fri Jan 10 03:09:24 EST 2025
#
/data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/mt_inference.py --batch_size 1 --ngpu 1 --data_path_and_name_and_type dump/raw/dev/text.rm.wavlm_large_finetune_24_km2000,src_text,text --key_file exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/keys.3.scp --mt_train_config exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/config.yaml --mt_model_file exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/valid.cer_ctc.best.pth --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/output.3 --config conf/decode_ctc1.0_greedy.yaml
2025-01-10 03:09:31,544 (abs_task:2300) INFO: config file: exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/config.yaml
Traceback (most recent call last):
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_inference.py", line 561, in <module>
    main()
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_inference.py", line 557, in main
    inference(**kwargs)
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_inference.py", line 348, in inference
    text2text = Text2Text.from_pretrained(
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_inference.py", line 269, in from_pretrained
    return Text2Text(**kwargs)
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_inference.py", line 67, in __init__
    mt_model, mt_train_args = MTTask.build_model_from_file(
  File "/data/mohan/workdir/espnet/espnet2/tasks/abs_task.py", line 2301, in build_model_from_file
    with config_file.open("r", encoding="utf-8") as f:
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/pathlib.py", line 1119, in open
    return self._accessor.open(self, mode, buffering, encoding, errors,
FileNotFoundError: [Errno 2] No such file or directory: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/config.yaml'
# Accounting: time=8 threads=1
# Ended (code 1) at Fri Jan 10 03:09:32 EST 2025, elapsed time 8 seconds
# python3 -m espnet2.bin.mt_inference --batch_size 1 --ngpu 1 --data_path_and_name_and_type dump/raw/dev/text.rm.wavlm_large_finetune_24_km2000,src_text,text --key_file exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/keys.4.scp --mt_train_config exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/config.yaml --mt_model_file exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/valid.cer_ctc.best.pth --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/output.4 --config conf/decode_ctc1.0_greedy.yaml 
# Started at Fri Jan 10 03:09:24 EST 2025
#
/data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/mt_inference.py --batch_size 1 --ngpu 1 --data_path_and_name_and_type dump/raw/dev/text.rm.wavlm_large_finetune_24_km2000,src_text,text --key_file exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/keys.4.scp --mt_train_config exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/config.yaml --mt_model_file exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/valid.cer_ctc.best.pth --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/output.4 --config conf/decode_ctc1.0_greedy.yaml
2025-01-10 03:09:30,861 (abs_task:2300) INFO: config file: exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/config.yaml
Traceback (most recent call last):
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_inference.py", line 561, in <module>
    main()
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_inference.py", line 557, in main
    inference(**kwargs)
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_inference.py", line 348, in inference
    text2text = Text2Text.from_pretrained(
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_inference.py", line 269, in from_pretrained
    return Text2Text(**kwargs)
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_inference.py", line 67, in __init__
    mt_model, mt_train_args = MTTask.build_model_from_file(
  File "/data/mohan/workdir/espnet/espnet2/tasks/abs_task.py", line 2301, in build_model_from_file
    with config_file.open("r", encoding="utf-8") as f:
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/pathlib.py", line 1119, in open
    return self._accessor.open(self, mode, buffering, encoding, errors,
FileNotFoundError: [Errno 2] No such file or directory: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/config.yaml'
# Accounting: time=7 threads=1
# Ended (code 1) at Fri Jan 10 03:09:31 EST 2025, elapsed time 7 seconds
2025-01-10T03:09:59 (asr2_hf.sh:288:main) ./asr2_hf.sh --stage 13 --stop_stage 13 --gpu_kmeans true --portion 1.0 --kmeans_opts --batch_bins 1 --nj 8 --kmeans_feature wavlm_large_finetune/24 --nclusters 2000 --ngpu 1 --nj 4 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang wavlm_large_finetune_24_km2000 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets dev test --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_finetune_24_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-01-10T03:09:59 (asr2_hf.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2025-01-10T03:09:59 (asr2_hf.sh:1423:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-01-10T03:09:59 (asr2_hf.sh:1466:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-01-10T03:09:59 (asr2_hf.sh:1470:main) ASR training started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/train.log'
2025-01-10 03:09:59,657 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_bpemodel none --src_token_type char --src_token_list data/token_list/char_wavlm_large_finetune_24_km2000/src_tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type dump/raw/dev/text.rm.wavlm_large_finetune_24_km2000,src_text,text --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_finetune_24_km2000_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_finetune_24_km2000_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000 --config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type dump/raw/train/text.rm.wavlm_large_finetune_24_km2000,src_text,text --train_data_path_and_name_and_type dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_rm_wavlm_large_finetune_24_km2000_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_rm_wavlm_large_finetune_24_km2000_char_bpe5000/train/text_shape.bpe
2025-01-10 03:09:59,674 (launch:348) INFO: log file: exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/train.log
2025-01-10T03:14:30 (asr2_hf.sh:288:main) ./asr2_hf.sh --stage 13 --stop_stage 13 --gpu_kmeans true --portion 1.0 --kmeans_opts --batch_bins 1 --nj 8 --kmeans_feature wavlm_large_finetune/24 --nclusters 2000 --ngpu 1 --nj 4 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang wavlm_large_finetune_24_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets dev test --src_bpe_train_text dump/raw/train/text.ts.wavlm_large_finetune_24_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-01-10T03:14:30 (asr2_hf.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2025-01-10T03:14:30 (asr2_hf.sh:1423:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-01-10T03:14:30 (asr2_hf.sh:1466:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_bpe_ts6000_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-01-10T03:14:30 (asr2_hf.sh:1470:main) ASR training started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_bpe_ts6000_bpe_ts5000/train.log'
2025-01-10 03:14:30,563 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_bpe_ts6000_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_bpe_ts6000_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_bpe_ts6000_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_bpemodel data/token_list/src_bpe_unigram6000_ts_wavlm_large_finetune_24_km2000/bpe.model --src_token_type bpe --src_token_list data/token_list/src_bpe_unigram6000_ts_wavlm_large_finetune_24_km2000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type dump/raw/dev/text.ts.wavlm_large_finetune_24_km2000,src_text,text --valid_shape_file exp/asr_stats_raw_ts_wavlm_large_finetune_24_km2000_bpe6000_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_wavlm_large_finetune_24_km2000_bpe6000_bpe5000/valid/src_text_shape.bpe --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_bpe_ts6000_bpe_ts5000 --config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type dump/raw/train/text.ts.wavlm_large_finetune_24_km2000,src_text,text --train_data_path_and_name_and_type dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_wavlm_large_finetune_24_km2000_bpe6000_bpe5000/train/src_text_shape.bpe --train_shape_file exp/asr_stats_raw_ts_wavlm_large_finetune_24_km2000_bpe6000_bpe5000/train/text_shape.bpe
2025-01-10 03:14:30,580 (launch:348) INFO: log file: exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_bpe_ts6000_bpe_ts5000/train.log
2025-01-10T03:16:27 (asr2_hf.sh:288:main) ./asr2_hf.sh --stage 13 --stop_stage 13 --gpu_kmeans true --portion 1.0 --kmeans_opts --batch_bins 1 --nj 8 --kmeans_feature wavlm_large_finetune/24 --nclusters 2000 --ngpu 1 --nj 4 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang wavlm_large_finetune_24_km2000 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets dev test --src_bpe_train_text dump/raw/train/text.ts.wavlm_large_finetune_24_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-01-10T03:16:27 (asr2_hf.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2025-01-10T03:16:27 (asr2_hf.sh:1423:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-01-10T03:16:27 (asr2_hf.sh:1466:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_ts_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-01-10T03:16:27 (asr2_hf.sh:1470:main) ASR training started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_ts_bpe_ts5000/train.log'
2025-01-10 03:16:27,580 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_ts_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_ts_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_ts_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_bpemodel none --src_token_type char --src_token_list data/token_list/char_wavlm_large_finetune_24_km2000/src_tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type dump/raw/dev/text.ts.wavlm_large_finetune_24_km2000,src_text,text --valid_shape_file exp/asr_stats_raw_ts_wavlm_large_finetune_24_km2000_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_wavlm_large_finetune_24_km2000_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_ts_bpe_ts5000 --config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type dump/raw/train/text.ts.wavlm_large_finetune_24_km2000,src_text,text --train_data_path_and_name_and_type dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_wavlm_large_finetune_24_km2000_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_wavlm_large_finetune_24_km2000_char_bpe5000/train/text_shape.bpe
2025-01-10 03:16:27,596 (launch:348) INFO: log file: exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_ts_bpe_ts5000/train.log
2025-01-10T04:30:59 (asr2_hf.sh:288:main) ./asr2_hf.sh --stage 13 --stop_stage 13 --gpu_kmeans true --portion 1.0 --kmeans_opts --batch_bins 1 --nj 8 --kmeans_feature wavlm_large_finetune/24 --nclusters 2000 --ngpu 1 --nj 4 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang wavlm_large_finetune_24_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets dev test --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_finetune_24_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-01-10T04:30:59 (asr2_hf.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2025-01-10T04:30:59 (asr2_hf.sh:1423:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-01-10T04:30:59 (asr2_hf.sh:1466:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_bpe_rm6000_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-01-10T04:30:59 (asr2_hf.sh:1470:main) ASR training started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_bpe_rm6000_bpe_ts5000/train.log'
2025-01-10 04:30:59,415 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_bpe_rm6000_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_bpe_rm6000_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_bpe_rm6000_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_bpemodel data/token_list/src_bpe_unigram6000_rm_wavlm_large_finetune_24_km2000/bpe.model --src_token_type bpe --src_token_list data/token_list/src_bpe_unigram6000_rm_wavlm_large_finetune_24_km2000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type dump/raw/dev/text.rm.wavlm_large_finetune_24_km2000,src_text,text --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_finetune_24_km2000_bpe6000_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_rm_wavlm_large_finetune_24_km2000_bpe6000_bpe5000/valid/src_text_shape.bpe --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_bpe_rm6000_bpe_ts5000 --config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type dump/raw/train/text.rm.wavlm_large_finetune_24_km2000,src_text,text --train_data_path_and_name_and_type dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_rm_wavlm_large_finetune_24_km2000_bpe6000_bpe5000/train/src_text_shape.bpe --train_shape_file exp/asr_stats_raw_rm_wavlm_large_finetune_24_km2000_bpe6000_bpe5000/train/text_shape.bpe
2025-01-10 04:30:59,432 (launch:348) INFO: log file: exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_bpe_rm6000_bpe_ts5000/train.log
2025-01-10T04:33:46 (asr2_hf.sh:288:main) ./asr2_hf.sh --stage 13 --stop_stage 13 --gpu_kmeans true --portion 1.0 --kmeans_opts --batch_bins 1 --nj 8 --kmeans_feature wavlm_large_finetune/24 --nclusters 2000 --ngpu 2 --nj 4 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang wavlm_large_finetune_24_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets dev test --src_bpe_train_text dump/raw/train/text.ts.wavlm_large_finetune_24_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-01-10T04:33:46 (asr2_hf.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2025-01-10T04:33:46 (asr2_hf.sh:1423:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-01-10T04:33:46 (asr2_hf.sh:1466:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_bpe_ts6000_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-01-10T04:33:47 (asr2_hf.sh:1470:main) ASR training started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_bpe_ts6000_bpe_ts5000/train.log'
2025-01-10 04:33:47,128 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_bpe_ts6000_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_bpe_ts6000_bpe_ts5000/train.log --ngpu 2 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_bpe_ts6000_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_bpemodel data/token_list/src_bpe_unigram6000_ts_wavlm_large_finetune_24_km2000/bpe.model --src_token_type bpe --src_token_list data/token_list/src_bpe_unigram6000_ts_wavlm_large_finetune_24_km2000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type dump/raw/dev/text.ts.wavlm_large_finetune_24_km2000,src_text,text --valid_shape_file exp/asr_stats_raw_ts_wavlm_large_finetune_24_km2000_bpe6000_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_wavlm_large_finetune_24_km2000_bpe6000_bpe5000/valid/src_text_shape.bpe --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_bpe_ts6000_bpe_ts5000 --config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type dump/raw/train/text.ts.wavlm_large_finetune_24_km2000,src_text,text --train_data_path_and_name_and_type dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_wavlm_large_finetune_24_km2000_bpe6000_bpe5000/train/src_text_shape.bpe --train_shape_file exp/asr_stats_raw_ts_wavlm_large_finetune_24_km2000_bpe6000_bpe5000/train/text_shape.bpe
2025-01-10 04:33:47,144 (launch:237) INFO: single-node with 2gpu on distributed mode
2025-01-10 04:33:47,144 (launch:348) INFO: log file: exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_bpe_ts6000_bpe_ts5000/train.log
2025-01-10T09:14:05 (asr2_hf.sh:1789:main) Successfully finished. [elapsed=21846s]
2025-01-10T10:46:13 (asr2_hf.sh:1789:main) Successfully finished. [elapsed=22514s]
2025-01-10T11:55:25 (asr2_hf.sh:288:main) ./asr2_hf.sh --stage 14 --stop_stage 14 --gpu_kmeans true --portion 1.0 --kmeans_opts --batch_bins 1 --nj 8 --kmeans_feature wavlm_large_finetune/24 --nclusters 2000 --ngpu 1 --nj 4 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang wavlm_large_finetune_24_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets dev test --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_finetune_24_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-01-10T11:55:25 (asr2_hf.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2025-01-10T11:55:25 (asr2_hf.sh:1545:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_bpe_rm6000_bpe_ts5000
2025-01-10T11:55:25 (asr2_hf.sh:1573:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/run.sh'. You can resume the process from stage 14 using this script
2025-01-10T11:55:25 (asr2_hf.sh:1604:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/asr_inference.*.log'
2025-01-10T11:56:12 (asr2_hf.sh:288:main) ./asr2_hf.sh --stage 14 --stop_stage 14 --gpu_kmeans true --portion 1.0 --kmeans_opts --batch_bins 1 --nj 8 --kmeans_feature wavlm_large_finetune/24 --nclusters 2000 --ngpu 1 --nj 4 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang wavlm_large_finetune_24_km2000 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case rm --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets dev test --src_bpe_train_text dump/raw/train/text.rm.wavlm_large_finetune_24_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-01-10T11:56:12 (asr2_hf.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2025-01-10T11:56:12 (asr2_hf.sh:1545:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000
2025-01-10T11:56:12 (asr2_hf.sh:1573:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/run.sh'. You can resume the process from stage 14 using this script
2025-01-10T11:56:12 (asr2_hf.sh:1604:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/asr_inference.*.log'
2025-01-10T12:24:46 (asr2_hf.sh:1604:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_bpe_rm6000_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/test/logdir/asr_inference.*.log'
2025-01-10T12:27:16 (asr2_hf.sh:1604:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_rm_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/test/logdir/asr_inference.*.log'
2025-01-10T12:49:04 (asr2_hf.sh:1789:main) Successfully finished. [elapsed=34357s]
2025-01-10T12:51:13 (asr2_hf.sh:288:main) ./asr2_hf.sh --stage 14 --stop_stage 14 --gpu_kmeans true --portion 1.0 --kmeans_opts --batch_bins 1 --nj 8 --kmeans_feature wavlm_large_finetune/24 --nclusters 2000 --ngpu 1 --nj 4 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang wavlm_large_finetune_24_km2000 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets dev test --src_bpe_train_text dump/raw/train/text.ts.wavlm_large_finetune_24_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-01-10T12:51:14 (asr2_hf.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2025-01-10T12:51:14 (asr2_hf.sh:1545:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_ts_bpe_ts5000
2025-01-10T12:51:14 (asr2_hf.sh:1573:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/run.sh'. You can resume the process from stage 14 using this script
2025-01-10T12:51:14 (asr2_hf.sh:1604:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/asr_inference.*.log'
2025-01-10T13:02:43 (asr2_hf.sh:1789:main) Successfully finished. [elapsed=4038s]
2025-01-10T13:08:05 (asr2_hf.sh:1789:main) Successfully finished. [elapsed=4313s]
2025-01-10T13:08:20 (asr2_hf.sh:1789:main) Successfully finished. [elapsed=30874s]
2025-01-10T13:22:58 (asr2_hf.sh:288:main) ./asr2_hf.sh --stage 14 --stop_stage 14 --gpu_kmeans true --portion 1.0 --kmeans_opts --batch_bins 1 --nj 8 --kmeans_feature wavlm_large_finetune/24 --nclusters 2000 --ngpu 1 --nj 4 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang wavlm_large_finetune_24_km2000 --tgt_lang en --src_token_type bpe --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets dev test --src_bpe_train_text dump/raw/train/text.ts.wavlm_large_finetune_24_km2000 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-01-10T13:22:58 (asr2_hf.sh:625:main) Skipped stages:  8 9 10 11 16 17 
2025-01-10T13:22:58 (asr2_hf.sh:1545:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_bpe_ts6000_bpe_ts5000
2025-01-10T13:22:58 (asr2_hf.sh:1573:main) Generate 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_bpe_ts6000_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/run.sh'. You can resume the process from stage 14 using this script
2025-01-10T13:22:58 (asr2_hf.sh:1604:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_bpe_ts6000_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/asr_inference.*.log'
2025-01-10T13:31:58 (asr2_hf.sh:1604:main) Decoding started... log: 'exp/asr_train_discrete_asr_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_wavlm_large_finetune_24_km2000_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/test/logdir/asr_inference.*.log'
2025-04-01T17:29:33 (asr2_codec.sh:295:main) ./asr2_codec.sh --stage 13 --stop_stage 13 --src_token_size 1024 --src_codebook_size 8 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/dev/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --ngpu 1 --nj 4 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang speechtokenizer --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.speechtokenizer --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-01T17:29:33 (asr2_codec.sh:632:main) Skipped stages:  8 9 10 11 16 17 
2025-04-01T17:29:33 (asr2_codec.sh:1430:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-04-01T17:29:33 (asr2_codec.sh:1473:main) Generate 'exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-04-01T17:29:33 (asr2_codec.sh:1477:main) ASR training started... log: 'exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log'
2025-04-01 17:29:33,862 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_int_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1024 --src_codebook_size 8 --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/dev/speech_token.scp,src_text,text_int --valid_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000 --config conf/train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/train/text_shape.bpe
2025-04-01 17:29:33,875 (launch:348) INFO: log file: exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log
2025-04-01T17:31:02 (asr2_codec.sh:295:main) ./asr2_codec.sh --stage 13 --stop_stage 13 --src_token_size 1024 --src_codebook_size 8 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/dev/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --ngpu 1 --nj 4 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang speechtokenizer --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.speechtokenizer --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-01T17:31:02 (asr2_codec.sh:632:main) Skipped stages:  8 9 10 11 16 17 
2025-04-01T17:31:02 (asr2_codec.sh:1430:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-04-01T17:31:02 (asr2_codec.sh:1473:main) Generate 'exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-04-01T17:31:02 (asr2_codec.sh:1477:main) ASR training started... log: 'exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log'
2025-04-01 17:31:02,278 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_int_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1024 --src_codebook_size 8 --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/dev/speech_token.scp,src_text,text_int --valid_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000 --config conf/train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/train/text_shape.bpe
2025-04-01 17:31:02,289 (launch:348) INFO: log file: exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log
bash: line 1: 693407 Killed                  ( python3 -m espnet2.bin.mt_int_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1024 --src_codebook_size 8 --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/dev/speech_token.scp,src_text,text_int --valid_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000 --config conf/train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/train/text_shape.bpe --ngpu 1 --multiprocessing_distributed True ) 2>> exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log >> exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log
run.pl: job failed, log is in exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log
Command '['run.pl', '--name', 'exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log', '--gpu', '1', 'exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log', 'python3', '-m', 'espnet2.bin.mt_int_train', '--use_preprocessor', 'true', '--bpemodel', 'data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model', '--token_type', 'bpe', '--token_list', 'data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt', '--src_token_size', '1024', '--src_codebook_size', '8', '--non_linguistic_symbols', 'none', '--cleaner', 'none', '--g2p', 'none', '--valid_data_path_and_name_and_type', '/data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text', '--valid_data_path_and_name_and_type', '/data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/dev/speech_token.scp,src_text,text_int', '--valid_shape_file', 'exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/valid/text_shape.bpe', '--valid_shape_file', 'exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/valid/src_text_shape.char', '--resume', 'true', '--ignore_init_mismatch', 'false', '--fold_length', '150', '--fold_length', '150', '--output_dir', 'exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000', '--config', 'conf/train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml', '--train_data_path_and_name_and_type', '/data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/train/speech_token.scp,src_text,text_int', '--train_data_path_and_name_and_type', '/data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text', '--train_shape_file', 'exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/train/src_text_shape.char', '--train_shape_file', 'exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/train/text_shape.bpe', '--ngpu', '1', '--multiprocessing_distributed', 'True']' returned non-zero exit status 1.
Traceback (most recent call last):
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/data/mohan/workdir/espnet/espnet2/bin/launch.py", line 384, in <module>
    main()
  File "/data/mohan/workdir/espnet/espnet2/bin/launch.py", line 375, in main
    raise RuntimeError(
RuntimeError: 
################### The last 1000 lines of exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log ###################
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
  )
  (criterion_mt): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
  (specaug): SpecAug(
    (time_mask): MaskAlongAxisVariableMaxWidth(mask_width_ratio_range=[0.0, 0.05], num_mask=10, axis=time)
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5000, bias=True)
    (ctc_loss): CTCLoss()
  )
)

Model summary:
    Class Name: ESPnetDiscreteASRModel
    Total Number of model parameters: 25.78 M
    Number of trainable parameters: 25.78 M (100.0%)
    Size: 103.11 MB
    Type: torch.float32
[lambda-Lambda-Vector] 2025-04-01 17:31:08,160 (abs_task:1391) INFO: Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 3.333333333333334e-08
    maximize: False
    weight_decay: 1e-06
)
[lambda-Lambda-Vector] 2025-04-01 17:31:08,160 (abs_task:1392) INFO: Scheduler: WarmupLR(warmup_steps=15000)
[lambda-Lambda-Vector] 2025-04-01 17:31:08,160 (abs_task:1401) INFO: Saving the configuration in exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/config.yaml
[lambda-Lambda-Vector] 2025-04-01 17:31:25,889 (abs_task:1810) INFO: [train] dataset:
ESPnetDataset(
  src_text: {"path": "/data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/train/speech_token.scp", "type": "text_int"}
  text: {"path": "/data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en", "type": "text"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7dde72ba1ff0>)
[lambda-Lambda-Vector] 2025-04-01 17:31:25,889 (abs_task:1811) INFO: [train] Batch sampler: NumElementsBatchSampler(N-batch=1549, batch_bins=128000000, sort_in_batch=descending, sort_batch=descending)
[lambda-Lambda-Vector] 2025-04-01 17:31:25,889 (abs_task:1812) INFO: [train] mini-batch sizes summary: N-batch=1549, mean=36.0, min=8, max=316
[lambda-Lambda-Vector] 2025-04-01 17:31:28,396 (abs_task:1810) INFO: [valid] dataset:
ESPnetDataset(
  text: {"path": "/data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en", "type": "text"}
  src_text: {"path": "/data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/dev/speech_token.scp", "type": "text_int"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7dde71423760>)
[lambda-Lambda-Vector] 2025-04-01 17:31:28,396 (abs_task:1811) INFO: [valid] Batch sampler: NumElementsBatchSampler(N-batch=319, batch_bins=128000000, sort_in_batch=descending, sort_batch=descending)
[lambda-Lambda-Vector] 2025-04-01 17:31:28,396 (abs_task:1812) INFO: [valid] mini-batch sizes summary: N-batch=319, mean=28.3, min=8, max=112
[lambda-Lambda-Vector] 2025-04-01 17:31:28,398 (trainer:311) INFO: 1/70epoch started
/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
[lambda-Lambda-Vector] 2025-04-01 17:31:41,900 (trainer:779) INFO: 1epoch:train:1-77batch: iter_time=8.045e-04, forward_time=0.062, loss_ctc=1.817e+03, loss=1.817e+03, backward_time=0.063, grad_norm=3.217e+03, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.005, optim0_lr0=1.333e-06, train_time=0.175
/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[lambda-Lambda-Vector] 2025-04-01 17:31:54,401 (trainer:779) INFO: 1epoch:train:78-154batch: iter_time=6.048e-05, forward_time=0.057, loss_ctc=1.156e+03, loss=1.156e+03, backward_time=0.062, grad_norm=3.831e+03, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.005, optim0_lr0=3.900e-06, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 17:32:06,843 (trainer:779) INFO: 1epoch:train:155-231batch: iter_time=6.029e-05, forward_time=0.058, loss_ctc=776.524, loss=776.524, backward_time=0.061, grad_norm=2.543e+03, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.005, optim0_lr0=6.467e-06, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 17:32:19,955 (trainer:779) INFO: 1epoch:train:232-308batch: iter_time=5.906e-05, forward_time=0.056, loss_ctc=675.399, loss=675.399, backward_time=0.060, grad_norm=2.400e+03, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.005, optim0_lr0=9.033e-06, train_time=0.170
[lambda-Lambda-Vector] 2025-04-01 17:32:32,363 (trainer:779) INFO: 1epoch:train:309-385batch: iter_time=5.991e-05, forward_time=0.058, loss_ctc=602.060, loss=602.060, backward_time=0.061, grad_norm=2.274e+03, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.005, optim0_lr0=1.160e-05, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 17:32:44,993 (trainer:779) INFO: 1epoch:train:386-462batch: iter_time=5.888e-05, forward_time=0.058, loss_ctc=588.820, loss=588.820, backward_time=0.062, grad_norm=2.445e+03, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.005, optim0_lr0=1.417e-05, train_time=0.164
[lambda-Lambda-Vector] 2025-04-01 17:32:57,293 (trainer:779) INFO: 1epoch:train:463-539batch: iter_time=5.782e-05, forward_time=0.057, loss_ctc=479.584, loss=479.584, backward_time=0.060, grad_norm=2.302e+03, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.005, optim0_lr0=1.673e-05, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 17:33:09,825 (trainer:779) INFO: 1epoch:train:540-616batch: iter_time=5.950e-05, forward_time=0.058, loss_ctc=158.823, loss=158.823, backward_time=0.061, grad_norm=599.709, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.005, optim0_lr0=1.930e-05, train_time=0.163
[lambda-Lambda-Vector] 2025-04-01 17:33:22,333 (trainer:779) INFO: 1epoch:train:617-693batch: iter_time=6.024e-05, forward_time=0.058, loss_ctc=131.764, loss=131.764, backward_time=0.061, grad_norm=154.092, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.005, optim0_lr0=2.187e-05, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 17:33:35,179 (trainer:779) INFO: 1epoch:train:694-770batch: iter_time=5.976e-05, forward_time=0.059, loss_ctc=138.750, loss=138.750, backward_time=0.063, grad_norm=87.350, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.005, optim0_lr0=2.443e-05, train_time=0.167
[lambda-Lambda-Vector] 2025-04-01 17:33:47,305 (trainer:779) INFO: 1epoch:train:771-847batch: iter_time=5.947e-05, forward_time=0.056, loss_ctc=100.977, loss=100.977, backward_time=0.059, grad_norm=54.979, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.005, optim0_lr0=2.700e-05, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 17:34:00,271 (trainer:779) INFO: 1epoch:train:848-924batch: iter_time=6.124e-05, forward_time=0.060, loss_ctc=132.417, loss=132.417, backward_time=0.064, grad_norm=54.680, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.005, optim0_lr0=2.957e-05, train_time=0.168
[lambda-Lambda-Vector] 2025-04-01 17:34:12,996 (trainer:779) INFO: 1epoch:train:925-1001batch: iter_time=6.036e-05, forward_time=0.059, loss_ctc=114.570, loss=114.570, backward_time=0.062, grad_norm=64.742, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.005, optim0_lr0=3.213e-05, train_time=0.165
[lambda-Lambda-Vector] 2025-04-01 17:34:25,914 (trainer:779) INFO: 1epoch:train:1002-1078batch: iter_time=5.554e-05, forward_time=0.060, loss_ctc=135.657, loss=135.657, backward_time=0.064, grad_norm=55.143, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.005, optim0_lr0=3.470e-05, train_time=0.168
[lambda-Lambda-Vector] 2025-04-01 17:34:38,357 (trainer:779) INFO: 1epoch:train:1079-1155batch: iter_time=5.118e-05, forward_time=0.057, loss_ctc=121.778, loss=121.778, backward_time=0.061, grad_norm=53.032, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.005, optim0_lr0=3.727e-05, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 17:34:50,726 (trainer:779) INFO: 1epoch:train:1156-1232batch: iter_time=5.187e-05, forward_time=0.058, loss_ctc=94.111, loss=94.111, backward_time=0.061, grad_norm=43.826, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.005, optim0_lr0=3.983e-05, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 17:35:03,167 (trainer:779) INFO: 1epoch:train:1233-1309batch: iter_time=5.187e-05, forward_time=0.058, loss_ctc=99.933, loss=99.933, backward_time=0.061, grad_norm=60.436, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.005, optim0_lr0=4.240e-05, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 17:35:15,615 (trainer:779) INFO: 1epoch:train:1310-1386batch: iter_time=5.410e-05, forward_time=0.058, loss_ctc=99.294, loss=99.294, backward_time=0.061, grad_norm=51.346, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.005, optim0_lr0=4.497e-05, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 17:35:27,998 (trainer:779) INFO: 1epoch:train:1387-1463batch: iter_time=5.626e-05, forward_time=0.057, loss_ctc=107.869, loss=107.869, backward_time=0.061, grad_norm=55.283, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.005, optim0_lr0=4.753e-05, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 17:35:39,989 (trainer:779) INFO: 1epoch:train:1464-1540batch: iter_time=5.546e-05, forward_time=0.055, loss_ctc=98.910, loss=98.910, backward_time=0.058, grad_norm=42.918, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.005, optim0_lr0=5.010e-05, train_time=0.156
/data/mohan/workdir/espnet/espnet2/train/reporter.py:79: UserWarning: No valid stats found
  warnings.warn("No valid stats found")
[lambda-Lambda-Vector] 2025-04-01 17:36:28,704 (trainer:365) INFO: 1epoch results: [train] iter_time=9.458e-05, forward_time=0.058, loss_ctc=361.597, loss=361.597, backward_time=0.061, grad_norm=1.014e+03, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.005, optim0_lr0=2.587e-05, train_time=0.163, time=4 minutes and 13.37 seconds, total_count=1549, gpu_max_cached_mem_GB=10.865, [valid] loss_ctc=109.887, cer_ctc=1.000, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=109.887, time=46.94 seconds, total_count=319, gpu_max_cached_mem_GB=31.432
[lambda-Lambda-Vector] 2025-04-01 17:36:30,328 (trainer:433) INFO: The best model has been updated: valid.cer_ctc
[lambda-Lambda-Vector] 2025-04-01 17:36:30,329 (trainer:299) INFO: 2/70epoch started. Estimated time to finish: 5 hours, 47 minutes and 13.22 seconds
[lambda-Lambda-Vector] 2025-04-01 17:36:43,343 (trainer:779) INFO: 2epoch:train:1-77batch: iter_time=6.922e-04, forward_time=0.055, loss_ctc=96.575, loss=96.575, backward_time=0.059, grad_norm=53.084, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.004, optim0_lr0=5.297e-05, train_time=0.169
[lambda-Lambda-Vector] 2025-04-01 17:36:55,327 (trainer:779) INFO: 2epoch:train:78-154batch: iter_time=5.381e-05, forward_time=0.053, loss_ctc=117.453, loss=117.453, backward_time=0.057, grad_norm=51.467, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.004, optim0_lr0=5.553e-05, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 17:37:07,379 (trainer:779) INFO: 2epoch:train:155-231batch: iter_time=5.163e-05, forward_time=0.053, loss_ctc=113.819, loss=113.819, backward_time=0.058, grad_norm=59.814, clip=98.701, loss_scale=6.554e+04, optim_step_time=0.004, optim0_lr0=5.810e-05, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 17:37:20,444 (trainer:779) INFO: 2epoch:train:232-308batch: iter_time=5.387e-05, forward_time=0.054, loss_ctc=105.709, loss=105.709, backward_time=0.058, grad_norm=59.232, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.005, optim0_lr0=6.067e-05, train_time=0.170
[lambda-Lambda-Vector] 2025-04-01 17:37:32,728 (trainer:779) INFO: 2epoch:train:309-385batch: iter_time=5.487e-05, forward_time=0.054, loss_ctc=122.099, loss=122.099, backward_time=0.059, grad_norm=51.541, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.005, optim0_lr0=6.323e-05, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 17:37:44,981 (trainer:779) INFO: 2epoch:train:386-462batch: iter_time=5.587e-05, forward_time=0.054, loss_ctc=99.751, loss=99.751, backward_time=0.058, grad_norm=52.931, clip=100.000, loss_scale=7.490e+04, optim_step_time=0.005, optim0_lr0=6.580e-05, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 17:37:57,177 (trainer:779) INFO: 2epoch:train:463-539batch: iter_time=5.446e-05, forward_time=0.054, loss_ctc=111.805, loss=111.805, backward_time=0.058, grad_norm=66.764, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.004, optim0_lr0=6.837e-05, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 17:38:09,150 (trainer:779) INFO: 2epoch:train:540-616batch: iter_time=5.401e-05, forward_time=0.053, loss_ctc=114.348, loss=114.348, backward_time=0.057, grad_norm=52.930, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.005, optim0_lr0=7.093e-05, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 17:38:21,441 (trainer:779) INFO: 2epoch:train:617-693batch: iter_time=4.982e-05, forward_time=0.054, loss_ctc=105.787, loss=105.787, backward_time=0.059, grad_norm=55.185, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.004, optim0_lr0=7.350e-05, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 17:38:33,694 (trainer:779) INFO: 2epoch:train:694-770batch: iter_time=5.081e-05, forward_time=0.054, loss_ctc=102.342, loss=102.342, backward_time=0.058, grad_norm=61.929, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.004, optim0_lr0=7.607e-05, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 17:38:45,654 (trainer:779) INFO: 2epoch:train:771-847batch: iter_time=4.911e-05, forward_time=0.053, loss_ctc=90.161, loss=90.161, backward_time=0.057, grad_norm=48.551, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.004, optim0_lr0=7.863e-05, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 17:38:57,980 (trainer:779) INFO: 2epoch:train:848-924batch: iter_time=5.043e-05, forward_time=0.055, loss_ctc=112.369, loss=112.369, backward_time=0.059, grad_norm=64.229, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.004, optim0_lr0=8.120e-05, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 17:39:10,023 (trainer:779) INFO: 2epoch:train:925-1001batch: iter_time=4.976e-05, forward_time=0.053, loss_ctc=106.134, loss=106.134, backward_time=0.057, grad_norm=65.504, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.004, optim0_lr0=8.377e-05, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 17:39:22,265 (trainer:779) INFO: 2epoch:train:1002-1078batch: iter_time=4.755e-05, forward_time=0.054, loss_ctc=121.790, loss=121.790, backward_time=0.059, grad_norm=53.938, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.004, optim0_lr0=8.633e-05, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 17:39:34,735 (trainer:779) INFO: 2epoch:train:1079-1155batch: iter_time=5.022e-05, forward_time=0.055, loss_ctc=117.990, loss=117.990, backward_time=0.060, grad_norm=61.573, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.004, optim0_lr0=8.890e-05, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 17:39:47,041 (trainer:779) INFO: 2epoch:train:1156-1232batch: iter_time=4.817e-05, forward_time=0.054, loss_ctc=108.881, loss=108.881, backward_time=0.059, grad_norm=55.627, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.004, optim0_lr0=9.147e-05, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 17:39:59,201 (trainer:779) INFO: 2epoch:train:1233-1309batch: iter_time=4.739e-05, forward_time=0.054, loss_ctc=112.675, loss=112.675, backward_time=0.058, grad_norm=58.207, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.004, optim0_lr0=9.403e-05, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 17:40:11,566 (trainer:779) INFO: 2epoch:train:1310-1386batch: iter_time=4.959e-05, forward_time=0.055, loss_ctc=116.628, loss=116.628, backward_time=0.059, grad_norm=73.353, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.004, optim0_lr0=9.660e-05, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 17:40:23,400 (trainer:779) INFO: 2epoch:train:1387-1463batch: iter_time=4.773e-05, forward_time=0.053, loss_ctc=90.552, loss=90.552, backward_time=0.056, grad_norm=67.274, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.004, optim0_lr0=9.917e-05, train_time=0.154
[lambda-Lambda-Vector] 2025-04-01 17:40:35,366 (trainer:779) INFO: 2epoch:train:1464-1540batch: iter_time=4.952e-05, forward_time=0.053, loss_ctc=98.929, loss=98.929, backward_time=0.057, grad_norm=53.876, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.004, optim0_lr0=1.017e-04, train_time=0.155
/data/mohan/workdir/espnet/espnet2/train/reporter.py:79: UserWarning: No valid stats found
  warnings.warn("No valid stats found")
[lambda-Lambda-Vector] 2025-04-01 17:41:23,337 (trainer:365) INFO: 2epoch results: [train] iter_time=8.278e-05, forward_time=0.054, loss_ctc=107.581, loss=107.581, backward_time=0.058, grad_norm=58.416, clip=99.935, loss_scale=1.120e+05, optim_step_time=0.004, optim0_lr0=7.750e-05, train_time=0.159, time=4 minutes and 6.73 seconds, total_count=3098, gpu_max_cached_mem_GB=31.432, [valid] loss_ctc=106.812, cer_ctc=0.992, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=106.812, time=46.28 seconds, total_count=638, gpu_max_cached_mem_GB=31.432
[lambda-Lambda-Vector] 2025-04-01 17:41:24,823 (trainer:433) INFO: The best model has been updated: valid.cer_ctc
[lambda-Lambda-Vector] 2025-04-01 17:41:24,823 (trainer:299) INFO: 3/70epoch started. Estimated time to finish: 5 hours, 37 minutes and 58.46 seconds
[lambda-Lambda-Vector] 2025-04-01 17:41:37,864 (trainer:779) INFO: 3epoch:train:1-77batch: iter_time=5.845e-04, forward_time=0.055, loss_ctc=111.993, loss=111.993, backward_time=0.059, grad_norm=63.727, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.004, optim0_lr0=1.046e-04, train_time=0.169
[lambda-Lambda-Vector] 2025-04-01 17:41:49,934 (trainer:779) INFO: 3epoch:train:78-154batch: iter_time=5.158e-05, forward_time=0.053, loss_ctc=120.536, loss=120.536, backward_time=0.058, grad_norm=61.691, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.004, optim0_lr0=1.072e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 17:42:02,058 (trainer:779) INFO: 3epoch:train:155-231batch: iter_time=5.195e-05, forward_time=0.054, loss_ctc=98.038, loss=98.038, backward_time=0.058, grad_norm=69.073, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.004, optim0_lr0=1.097e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 17:42:14,273 (trainer:779) INFO: 3epoch:train:232-308batch: iter_time=5.154e-05, forward_time=0.054, loss_ctc=90.479, loss=90.479, backward_time=0.058, grad_norm=77.963, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.004, optim0_lr0=1.123e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 17:42:26,484 (trainer:779) INFO: 3epoch:train:309-385batch: iter_time=5.095e-05, forward_time=0.054, loss_ctc=105.080, loss=105.080, backward_time=0.059, grad_norm=83.637, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.004, optim0_lr0=1.149e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 17:42:38,852 (trainer:779) INFO: 3epoch:train:386-462batch: iter_time=5.294e-05, forward_time=0.055, loss_ctc=108.984, loss=108.984, backward_time=0.059, grad_norm=83.238, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.004, optim0_lr0=1.174e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 17:42:51,547 (trainer:779) INFO: 3epoch:train:463-539batch: iter_time=4.895e-05, forward_time=0.056, loss_ctc=135.466, loss=135.466, backward_time=0.061, grad_norm=98.542, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.004, optim0_lr0=1.200e-04, train_time=0.165
[lambda-Lambda-Vector] 2025-04-01 17:43:03,256 (trainer:779) INFO: 3epoch:train:540-616batch: iter_time=5.221e-05, forward_time=0.052, loss_ctc=90.997, loss=90.997, backward_time=0.056, grad_norm=81.989, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.004, optim0_lr0=1.226e-04, train_time=0.152
[lambda-Lambda-Vector] 2025-04-01 17:43:15,531 (trainer:779) INFO: 3epoch:train:617-693batch: iter_time=5.534e-05, forward_time=0.055, loss_ctc=91.534, loss=91.534, backward_time=0.059, grad_norm=84.971, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.005, optim0_lr0=1.251e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 17:43:27,863 (trainer:779) INFO: 3epoch:train:694-770batch: iter_time=5.266e-05, forward_time=0.055, loss_ctc=105.107, loss=105.107, backward_time=0.059, grad_norm=94.203, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.004, optim0_lr0=1.277e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 17:43:39,964 (trainer:779) INFO: 3epoch:train:771-847batch: iter_time=5.359e-05, forward_time=0.054, loss_ctc=92.154, loss=92.154, backward_time=0.058, grad_norm=79.955, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.005, optim0_lr0=1.303e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 17:43:51,908 (trainer:779) INFO: 3epoch:train:848-924batch: iter_time=5.226e-05, forward_time=0.053, loss_ctc=97.522, loss=97.522, backward_time=0.057, grad_norm=77.763, clip=100.000, loss_scale=1.685e+05, optim_step_time=0.005, optim0_lr0=1.328e-04, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 17:44:03,659 (trainer:779) INFO: 3epoch:train:925-1001batch: iter_time=5.036e-05, forward_time=0.052, loss_ctc=102.434, loss=102.434, backward_time=0.056, grad_norm=82.063, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.004, optim0_lr0=1.354e-04, train_time=0.153
[lambda-Lambda-Vector] 2025-04-01 17:44:16,769 (trainer:779) INFO: 3epoch:train:1002-1078batch: iter_time=5.293e-05, forward_time=0.054, loss_ctc=97.703, loss=97.703, backward_time=0.058, grad_norm=111.583, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.005, optim0_lr0=1.380e-04, train_time=0.170
[lambda-Lambda-Vector] 2025-04-01 17:44:28,957 (trainer:779) INFO: 3epoch:train:1079-1155batch: iter_time=5.321e-05, forward_time=0.054, loss_ctc=116.989, loss=116.989, backward_time=0.058, grad_norm=131.788, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.005, optim0_lr0=1.405e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 17:44:41,551 (trainer:779) INFO: 3epoch:train:1156-1232batch: iter_time=5.174e-05, forward_time=0.056, loss_ctc=111.448, loss=111.448, backward_time=0.060, grad_norm=159.842, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.005, optim0_lr0=1.431e-04, train_time=0.163
[lambda-Lambda-Vector] 2025-04-01 17:44:53,453 (trainer:779) INFO: 3epoch:train:1233-1309batch: iter_time=5.320e-05, forward_time=0.053, loss_ctc=85.719, loss=85.719, backward_time=0.057, grad_norm=116.165, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.005, optim0_lr0=1.457e-04, train_time=0.154
[lambda-Lambda-Vector] 2025-04-01 17:45:05,766 (trainer:779) INFO: 3epoch:train:1310-1386batch: iter_time=5.078e-05, forward_time=0.054, loss_ctc=112.667, loss=112.667, backward_time=0.059, grad_norm=145.675, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.004, optim0_lr0=1.482e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 17:45:18,023 (trainer:779) INFO: 3epoch:train:1387-1463batch: iter_time=5.021e-05, forward_time=0.054, loss_ctc=106.330, loss=106.330, backward_time=0.059, grad_norm=141.568, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.004, optim0_lr0=1.508e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 17:45:30,161 (trainer:779) INFO: 3epoch:train:1464-1540batch: iter_time=4.790e-05, forward_time=0.054, loss_ctc=95.825, loss=95.825, backward_time=0.058, grad_norm=131.682, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.004, optim0_lr0=1.534e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 17:46:17,279 (trainer:365) INFO: 3epoch results: [train] iter_time=7.820e-05, forward_time=0.054, loss_ctc=102.618, loss=102.618, backward_time=0.058, grad_norm=98.863, clip=100.000, loss_scale=1.858e+05, optim_step_time=0.004, optim0_lr0=1.291e-04, train_time=0.159, time=4 minutes and 7.01 seconds, total_count=4647, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=107.944, cer_ctc=0.899, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=107.944, time=45.44 seconds, total_count=957, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 17:46:18,831 (trainer:433) INFO: The best model has been updated: valid.cer_ctc
[lambda-Lambda-Vector] 2025-04-01 17:46:18,831 (trainer:299) INFO: 4/70epoch started. Estimated time to finish: 5 hours, 31 minutes and 26.34 seconds
[lambda-Lambda-Vector] 2025-04-01 17:46:32,722 (trainer:779) INFO: 4epoch:train:1-77batch: iter_time=7.554e-04, forward_time=0.055, loss_ctc=101.377, loss=101.377, backward_time=0.059, grad_norm=124.761, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.004, optim0_lr0=1.562e-04, train_time=0.180
[lambda-Lambda-Vector] 2025-04-01 17:46:44,778 (trainer:779) INFO: 4epoch:train:78-154batch: iter_time=5.298e-05, forward_time=0.053, loss_ctc=97.212, loss=97.212, backward_time=0.058, grad_norm=133.214, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.004, optim0_lr0=1.588e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 17:46:57,065 (trainer:779) INFO: 4epoch:train:155-231batch: iter_time=5.169e-05, forward_time=0.055, loss_ctc=89.554, loss=89.554, backward_time=0.059, grad_norm=138.075, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.004, optim0_lr0=1.614e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 17:47:09,365 (trainer:779) INFO: 4epoch:train:232-308batch: iter_time=5.258e-05, forward_time=0.055, loss_ctc=97.827, loss=97.827, backward_time=0.059, grad_norm=138.399, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.005, optim0_lr0=1.639e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 17:47:21,470 (trainer:779) INFO: 4epoch:train:309-385batch: iter_time=5.240e-05, forward_time=0.054, loss_ctc=106.858, loss=106.858, backward_time=0.058, grad_norm=124.372, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.005, optim0_lr0=1.665e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 17:47:33,917 (trainer:779) INFO: 4epoch:train:386-462batch: iter_time=4.990e-05, forward_time=0.055, loss_ctc=104.980, loss=104.980, backward_time=0.060, grad_norm=141.449, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.004, optim0_lr0=1.691e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 17:47:45,921 (trainer:779) INFO: 4epoch:train:463-539batch: iter_time=5.023e-05, forward_time=0.053, loss_ctc=113.570, loss=113.570, backward_time=0.058, grad_norm=115.709, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.004, optim0_lr0=1.716e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 17:47:58,109 (trainer:779) INFO: 4epoch:train:540-616batch: iter_time=5.048e-05, forward_time=0.054, loss_ctc=97.764, loss=97.764, backward_time=0.058, grad_norm=127.778, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.004, optim0_lr0=1.742e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 17:48:10,498 (trainer:779) INFO: 4epoch:train:617-693batch: iter_time=4.943e-05, forward_time=0.055, loss_ctc=115.413, loss=115.413, backward_time=0.059, grad_norm=136.710, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.004, optim0_lr0=1.768e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 17:48:22,077 (trainer:779) INFO: 4epoch:train:694-770batch: iter_time=4.870e-05, forward_time=0.051, loss_ctc=92.973, loss=92.973, backward_time=0.055, grad_norm=120.255, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.004, optim0_lr0=1.793e-04, train_time=0.150
[lambda-Lambda-Vector] 2025-04-01 17:48:34,283 (trainer:779) INFO: 4epoch:train:771-847batch: iter_time=4.942e-05, forward_time=0.054, loss_ctc=104.628, loss=104.628, backward_time=0.059, grad_norm=147.345, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.004, optim0_lr0=1.819e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 17:48:46,160 (trainer:779) INFO: 4epoch:train:848-924batch: iter_time=4.903e-05, forward_time=0.053, loss_ctc=83.420, loss=83.420, backward_time=0.057, grad_norm=117.845, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.004, optim0_lr0=1.845e-04, train_time=0.154
[lambda-Lambda-Vector] 2025-04-01 17:48:58,238 (trainer:779) INFO: 4epoch:train:925-1001batch: iter_time=4.893e-05, forward_time=0.054, loss_ctc=88.786, loss=88.786, backward_time=0.058, grad_norm=124.078, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.004, optim0_lr0=1.870e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 17:49:11,003 (trainer:779) INFO: 4epoch:train:1002-1078batch: iter_time=4.881e-05, forward_time=0.056, loss_ctc=118.241, loss=118.241, backward_time=0.061, grad_norm=156.173, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.004, optim0_lr0=1.896e-04, train_time=0.166
[lambda-Lambda-Vector] 2025-04-01 17:49:23,673 (trainer:779) INFO: 4epoch:train:1079-1155batch: iter_time=4.868e-05, forward_time=0.056, loss_ctc=128.828, loss=128.828, backward_time=0.061, grad_norm=162.227, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.004, optim0_lr0=1.922e-04, train_time=0.164
[lambda-Lambda-Vector] 2025-04-01 17:49:35,813 (trainer:779) INFO: 4epoch:train:1156-1232batch: iter_time=4.945e-05, forward_time=0.054, loss_ctc=99.036, loss=99.036, backward_time=0.058, grad_norm=145.542, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.004, optim0_lr0=1.947e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 17:49:47,821 (trainer:779) INFO: 4epoch:train:1233-1309batch: iter_time=5.072e-05, forward_time=0.053, loss_ctc=102.063, loss=102.063, backward_time=0.058, grad_norm=128.332, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.005, optim0_lr0=1.973e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 17:49:59,757 (trainer:779) INFO: 4epoch:train:1310-1386batch: iter_time=4.943e-05, forward_time=0.053, loss_ctc=93.468, loss=93.468, backward_time=0.058, grad_norm=108.029, clip=100.000, loss_scale=3.745e+05, optim_step_time=0.005, optim0_lr0=1.999e-04, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 17:50:11,707 (trainer:779) INFO: 4epoch:train:1387-1463batch: iter_time=5.001e-05, forward_time=0.053, loss_ctc=98.747, loss=98.747, backward_time=0.058, grad_norm=103.843, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.005, optim0_lr0=2.024e-04, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 17:50:24,052 (trainer:779) INFO: 4epoch:train:1464-1540batch: iter_time=5.620e-05, forward_time=0.055, loss_ctc=91.772, loss=91.772, backward_time=0.059, grad_norm=137.687, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.005, optim0_lr0=2.050e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 17:51:12,370 (trainer:365) INFO: 4epoch results: [train] iter_time=8.546e-05, forward_time=0.054, loss_ctc=100.401, loss=100.401, backward_time=0.058, grad_norm=131.745, clip=100.000, loss_scale=2.953e+05, optim_step_time=0.004, optim0_lr0=1.808e-04, train_time=0.159, time=4 minutes and 6.98 seconds, total_count=6196, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=112.503, cer_ctc=0.823, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=112.503, time=46.56 seconds, total_count=1276, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 17:51:13,923 (trainer:433) INFO: The best model has been updated: valid.cer_ctc
[lambda-Lambda-Vector] 2025-04-01 17:51:13,923 (trainer:299) INFO: 5/70epoch started. Estimated time to finish: 5 hours, 26 minutes and 1.17 seconds
[lambda-Lambda-Vector] 2025-04-01 17:51:26,344 (trainer:779) INFO: 5epoch:train:1-77batch: iter_time=7.021e-04, forward_time=0.052, loss_ctc=91.694, loss=91.694, backward_time=0.056, grad_norm=141.653, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.004, optim0_lr0=2.079e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 17:51:38,392 (trainer:779) INFO: 5epoch:train:78-154batch: iter_time=5.162e-05, forward_time=0.053, loss_ctc=100.060, loss=100.060, backward_time=0.058, grad_norm=116.956, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.004, optim0_lr0=2.104e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 17:51:50,674 (trainer:779) INFO: 5epoch:train:155-231batch: iter_time=5.081e-05, forward_time=0.055, loss_ctc=94.262, loss=94.262, backward_time=0.059, grad_norm=136.618, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.004, optim0_lr0=2.130e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 17:52:03,038 (trainer:779) INFO: 5epoch:train:232-308batch: iter_time=5.002e-05, forward_time=0.055, loss_ctc=96.081, loss=96.081, backward_time=0.059, grad_norm=180.846, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.004, optim0_lr0=2.156e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 17:52:15,039 (trainer:779) INFO: 5epoch:train:309-385batch: iter_time=5.092e-05, forward_time=0.053, loss_ctc=90.015, loss=90.015, backward_time=0.057, grad_norm=170.659, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.004, optim0_lr0=2.181e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 17:52:27,366 (trainer:779) INFO: 5epoch:train:386-462batch: iter_time=4.917e-05, forward_time=0.055, loss_ctc=96.062, loss=96.062, backward_time=0.059, grad_norm=207.134, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.004, optim0_lr0=2.207e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 17:52:39,399 (trainer:779) INFO: 5epoch:train:463-539batch: iter_time=4.915e-05, forward_time=0.053, loss_ctc=102.254, loss=102.254, backward_time=0.058, grad_norm=153.569, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.004, optim0_lr0=2.233e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 17:52:51,192 (trainer:779) INFO: 5epoch:train:540-616batch: iter_time=4.922e-05, forward_time=0.052, loss_ctc=85.506, loss=85.506, backward_time=0.056, grad_norm=143.121, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.004, optim0_lr0=2.258e-04, train_time=0.153
[lambda-Lambda-Vector] 2025-04-01 17:53:03,168 (trainer:779) INFO: 5epoch:train:617-693batch: iter_time=4.987e-05, forward_time=0.053, loss_ctc=93.081, loss=93.081, backward_time=0.057, grad_norm=149.986, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.004, optim0_lr0=2.284e-04, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 17:53:15,549 (trainer:779) INFO: 5epoch:train:694-770batch: iter_time=4.957e-05, forward_time=0.055, loss_ctc=114.730, loss=114.730, backward_time=0.059, grad_norm=227.740, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.004, optim0_lr0=2.310e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 17:53:28,539 (trainer:779) INFO: 5epoch:train:771-847batch: iter_time=4.984e-05, forward_time=0.053, loss_ctc=102.729, loss=102.729, backward_time=0.058, grad_norm=180.450, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.005, optim0_lr0=2.335e-04, train_time=0.169
[lambda-Lambda-Vector] 2025-04-01 17:53:40,757 (trainer:779) INFO: 5epoch:train:848-924batch: iter_time=5.068e-05, forward_time=0.054, loss_ctc=100.903, loss=100.903, backward_time=0.058, grad_norm=195.510, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.005, optim0_lr0=2.361e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 17:53:53,018 (trainer:779) INFO: 5epoch:train:925-1001batch: iter_time=5.020e-05, forward_time=0.054, loss_ctc=95.481, loss=95.481, backward_time=0.059, grad_norm=183.555, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.005, optim0_lr0=2.387e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 17:54:05,252 (trainer:779) INFO: 5epoch:train:1002-1078batch: iter_time=5.189e-05, forward_time=0.054, loss_ctc=109.170, loss=109.170, backward_time=0.059, grad_norm=190.125, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.005, optim0_lr0=2.412e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 17:54:17,354 (trainer:779) INFO: 5epoch:train:1079-1155batch: iter_time=4.943e-05, forward_time=0.054, loss_ctc=101.655, loss=101.655, backward_time=0.058, grad_norm=257.776, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.004, optim0_lr0=2.438e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 17:54:29,674 (trainer:779) INFO: 5epoch:train:1156-1232batch: iter_time=4.997e-05, forward_time=0.054, loss_ctc=115.161, loss=115.161, backward_time=0.059, grad_norm=283.928, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.004, optim0_lr0=2.464e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 17:54:42,098 (trainer:779) INFO: 5epoch:train:1233-1309batch: iter_time=5.041e-05, forward_time=0.055, loss_ctc=100.407, loss=100.407, backward_time=0.060, grad_norm=306.858, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.004, optim0_lr0=2.489e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 17:54:54,190 (trainer:779) INFO: 5epoch:train:1310-1386batch: iter_time=4.995e-05, forward_time=0.054, loss_ctc=106.482, loss=106.482, backward_time=0.058, grad_norm=823.913, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.004, optim0_lr0=2.515e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 17:55:06,428 (trainer:779) INFO: 5epoch:train:1387-1463batch: iter_time=5.024e-05, forward_time=0.054, loss_ctc=116.654, loss=116.654, backward_time=0.059, grad_norm=796.567, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.004, optim0_lr0=2.541e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 17:55:19,005 (trainer:779) INFO: 5epoch:train:1464-1540batch: iter_time=5.620e-05, forward_time=0.056, loss_ctc=119.659, loss=119.659, backward_time=0.060, grad_norm=599.909, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.005, optim0_lr0=2.566e-04, train_time=0.163
[lambda-Lambda-Vector] 2025-04-01 17:56:06,198 (trainer:365) INFO: 5epoch results: [train] iter_time=8.279e-05, forward_time=0.054, loss_ctc=100.967, loss=100.967, backward_time=0.058, grad_norm=272.881, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.004, optim0_lr0=2.324e-04, train_time=0.159, time=4 minutes and 6.82 seconds, total_count=7745, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=103.560, cer_ctc=0.995, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=103.560, time=45.46 seconds, total_count=1595, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 17:56:08,702 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 17:56:08,702 (trainer:299) INFO: 6/70epoch started. Estimated time to finish: 5 hours, 20 minutes and 43.95 seconds
[lambda-Lambda-Vector] 2025-04-01 17:56:21,560 (trainer:779) INFO: 6epoch:train:1-77batch: iter_time=6.662e-04, forward_time=0.054, loss_ctc=102.081, loss=102.081, backward_time=0.058, grad_norm=475.722, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.005, optim0_lr0=2.595e-04, train_time=0.167
[lambda-Lambda-Vector] 2025-04-01 17:56:33,640 (trainer:779) INFO: 6epoch:train:78-154batch: iter_time=5.418e-05, forward_time=0.054, loss_ctc=96.244, loss=96.244, backward_time=0.058, grad_norm=275.885, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.005, optim0_lr0=2.621e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 17:56:46,078 (trainer:779) INFO: 6epoch:train:155-231batch: iter_time=5.261e-05, forward_time=0.055, loss_ctc=118.434, loss=118.434, backward_time=0.060, grad_norm=478.240, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.005, optim0_lr0=2.646e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 17:56:58,303 (trainer:779) INFO: 6epoch:train:232-308batch: iter_time=5.257e-05, forward_time=0.054, loss_ctc=109.361, loss=109.361, backward_time=0.058, grad_norm=405.472, clip=100.000, loss_scale=8.852e+05, optim_step_time=0.005, optim0_lr0=2.672e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 17:57:10,434 (trainer:779) INFO: 6epoch:train:309-385batch: iter_time=5.446e-05, forward_time=0.054, loss_ctc=104.174, loss=104.174, backward_time=0.058, grad_norm=617.918, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.005, optim0_lr0=2.698e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 17:57:22,416 (trainer:779) INFO: 6epoch:train:386-462batch: iter_time=5.404e-05, forward_time=0.053, loss_ctc=99.096, loss=99.096, backward_time=0.057, grad_norm=530.652, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.005, optim0_lr0=2.723e-04, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 17:57:34,290 (trainer:779) INFO: 6epoch:train:463-539batch: iter_time=5.332e-05, forward_time=0.053, loss_ctc=89.940, loss=89.940, backward_time=0.057, grad_norm=379.180, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.005, optim0_lr0=2.749e-04, train_time=0.154
[lambda-Lambda-Vector] 2025-04-01 17:57:46,520 (trainer:779) INFO: 6epoch:train:540-616batch: iter_time=5.438e-05, forward_time=0.054, loss_ctc=103.813, loss=103.813, backward_time=0.059, grad_norm=2.043e+03, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.005, optim0_lr0=2.775e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 17:57:58,729 (trainer:779) INFO: 6epoch:train:617-693batch: iter_time=5.338e-05, forward_time=0.054, loss_ctc=105.710, loss=105.710, backward_time=0.058, grad_norm=354.465, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.005, optim0_lr0=2.800e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 17:58:11,015 (trainer:779) INFO: 6epoch:train:694-770batch: iter_time=5.205e-05, forward_time=0.054, loss_ctc=115.973, loss=115.973, backward_time=0.059, grad_norm=160.169, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.005, optim0_lr0=2.826e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 17:58:23,270 (trainer:779) INFO: 6epoch:train:771-847batch: iter_time=5.340e-05, forward_time=0.055, loss_ctc=89.563, loss=89.563, backward_time=0.058, grad_norm=79.028, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.005, optim0_lr0=2.852e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 17:58:35,366 (trainer:779) INFO: 6epoch:train:848-924batch: iter_time=5.242e-05, forward_time=0.054, loss_ctc=110.576, loss=110.576, backward_time=0.058, grad_norm=101.363, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.005, optim0_lr0=2.877e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 17:58:47,419 (trainer:779) INFO: 6epoch:train:925-1001batch: iter_time=5.422e-05, forward_time=0.053, loss_ctc=119.305, loss=119.305, backward_time=0.058, grad_norm=183.262, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.005, optim0_lr0=2.903e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 17:58:59,728 (trainer:779) INFO: 6epoch:train:1002-1078batch: iter_time=5.457e-05, forward_time=0.054, loss_ctc=112.937, loss=112.937, backward_time=0.059, grad_norm=145.533, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.005, optim0_lr0=2.929e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 17:59:12,560 (trainer:779) INFO: 6epoch:train:1079-1155batch: iter_time=5.336e-05, forward_time=0.057, loss_ctc=123.757, loss=123.757, backward_time=0.062, grad_norm=231.116, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.005, optim0_lr0=2.954e-04, train_time=0.167
[lambda-Lambda-Vector] 2025-04-01 17:59:24,475 (trainer:779) INFO: 6epoch:train:1156-1232batch: iter_time=5.321e-05, forward_time=0.053, loss_ctc=98.305, loss=98.305, backward_time=0.057, grad_norm=189.732, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.005, optim0_lr0=2.980e-04, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 17:59:36,842 (trainer:779) INFO: 6epoch:train:1233-1309batch: iter_time=5.210e-05, forward_time=0.055, loss_ctc=111.113, loss=111.113, backward_time=0.059, grad_norm=154.477, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.004, optim0_lr0=3.006e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 17:59:48,886 (trainer:779) INFO: 6epoch:train:1310-1386batch: iter_time=5.119e-05, forward_time=0.053, loss_ctc=98.680, loss=98.680, backward_time=0.058, grad_norm=125.681, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.004, optim0_lr0=3.031e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 18:00:00,939 (trainer:779) INFO: 6epoch:train:1387-1463batch: iter_time=5.202e-05, forward_time=0.054, loss_ctc=97.399, loss=97.399, backward_time=0.058, grad_norm=62.885, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.004, optim0_lr0=3.057e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 18:00:13,199 (trainer:779) INFO: 6epoch:train:1464-1540batch: iter_time=5.154e-05, forward_time=0.054, loss_ctc=106.219, loss=106.219, backward_time=0.059, grad_norm=71.327, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.004, optim0_lr0=3.083e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 18:01:01,296 (trainer:365) INFO: 6epoch results: [train] iter_time=8.347e-05, forward_time=0.054, loss_ctc=104.833, loss=104.833, backward_time=0.058, grad_norm=351.539, clip=100.000, loss_scale=9.623e+05, optim_step_time=0.005, optim0_lr0=2.840e-04, train_time=0.159, time=4 minutes and 6.23 seconds, total_count=9294, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=122.552, cer_ctc=0.928, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=122.552, time=46.37 seconds, total_count=1914, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 18:01:02,863 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 18:01:02,863 (trainer:299) INFO: 7/70epoch started. Estimated time to finish: 5 hours, 15 minutes and 27.63 seconds
[lambda-Lambda-Vector] 2025-04-01 18:01:15,781 (trainer:779) INFO: 7epoch:train:1-77batch: iter_time=7.849e-04, forward_time=0.054, loss_ctc=109.137, loss=109.137, backward_time=0.058, grad_norm=128.142, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.004, optim0_lr0=3.111e-04, train_time=0.168
[lambda-Lambda-Vector] 2025-04-01 18:01:28,223 (trainer:779) INFO: 7epoch:train:78-154batch: iter_time=5.008e-05, forward_time=0.055, loss_ctc=123.891, loss=123.891, backward_time=0.060, grad_norm=157.354, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.004, optim0_lr0=3.137e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 18:01:40,704 (trainer:779) INFO: 7epoch:train:155-231batch: iter_time=5.008e-05, forward_time=0.055, loss_ctc=103.461, loss=103.461, backward_time=0.060, grad_norm=378.043, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.005, optim0_lr0=3.163e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 18:01:52,695 (trainer:779) INFO: 7epoch:train:232-308batch: iter_time=4.950e-05, forward_time=0.053, loss_ctc=102.817, loss=102.817, backward_time=0.057, grad_norm=590.875, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.004, optim0_lr0=3.188e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 18:02:04,663 (trainer:779) INFO: 7epoch:train:309-385batch: iter_time=4.938e-05, forward_time=0.054, loss_ctc=85.425, loss=85.425, backward_time=0.057, grad_norm=48.181, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.004, optim0_lr0=3.214e-04, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 18:02:16,829 (trainer:779) INFO: 7epoch:train:386-462batch: iter_time=5.026e-05, forward_time=0.054, loss_ctc=104.981, loss=104.981, backward_time=0.058, grad_norm=53.911, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.005, optim0_lr0=3.240e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 18:02:29,391 (trainer:779) INFO: 7epoch:train:463-539batch: iter_time=5.487e-05, forward_time=0.056, loss_ctc=119.805, loss=119.805, backward_time=0.060, grad_norm=54.895, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.005, optim0_lr0=3.265e-04, train_time=0.163
[lambda-Lambda-Vector] 2025-04-01 18:02:41,645 (trainer:779) INFO: 7epoch:train:540-616batch: iter_time=4.865e-05, forward_time=0.054, loss_ctc=102.783, loss=102.783, backward_time=0.059, grad_norm=47.561, clip=98.701, loss_scale=1.049e+06, optim_step_time=0.004, optim0_lr0=3.291e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 18:02:53,767 (trainer:779) INFO: 7epoch:train:617-693batch: iter_time=4.710e-05, forward_time=0.054, loss_ctc=97.632, loss=97.632, backward_time=0.058, grad_norm=47.022, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.004, optim0_lr0=3.317e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 18:03:07,119 (trainer:779) INFO: 7epoch:train:694-770batch: iter_time=4.737e-05, forward_time=0.055, loss_ctc=116.995, loss=116.995, backward_time=0.059, grad_norm=59.277, clip=100.000, loss_scale=1.920e+06, optim_step_time=0.004, optim0_lr0=3.342e-04, train_time=0.173
[lambda-Lambda-Vector] 2025-04-01 18:03:19,141 (trainer:779) INFO: 7epoch:train:771-847batch: iter_time=4.953e-05, forward_time=0.053, loss_ctc=104.053, loss=104.053, backward_time=0.058, grad_norm=53.155, clip=98.701, loss_scale=2.097e+06, optim_step_time=0.005, optim0_lr0=3.368e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 18:03:34,449 (trainer:779) INFO: 7epoch:train:848-924batch: iter_time=6.122e-05, forward_time=0.067, loss_ctc=99.990, loss=99.990, backward_time=0.072, grad_norm=56.472, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.005, optim0_lr0=3.394e-04, train_time=0.199
[lambda-Lambda-Vector] 2025-04-01 18:03:51,702 (trainer:779) INFO: 7epoch:train:925-1001batch: iter_time=5.337e-05, forward_time=0.077, loss_ctc=105.331, loss=105.331, backward_time=0.082, grad_norm=54.981, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.005, optim0_lr0=3.419e-04, train_time=0.224
[lambda-Lambda-Vector] 2025-04-01 18:04:10,371 (trainer:779) INFO: 7epoch:train:1002-1078batch: iter_time=4.999e-05, forward_time=0.083, loss_ctc=105.584, loss=105.584, backward_time=0.089, grad_norm=67.436, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.005, optim0_lr0=3.445e-04, train_time=0.242
[lambda-Lambda-Vector] 2025-04-01 18:04:27,075 (trainer:779) INFO: 7epoch:train:1079-1155batch: iter_time=5.095e-05, forward_time=0.075, loss_ctc=100.059, loss=100.059, backward_time=0.079, grad_norm=49.338, clip=98.701, loss_scale=2.097e+06, optim_step_time=0.005, optim0_lr0=3.471e-04, train_time=0.217
[lambda-Lambda-Vector] 2025-04-01 18:04:45,952 (trainer:779) INFO: 7epoch:train:1156-1232batch: iter_time=5.344e-05, forward_time=0.084, loss_ctc=115.813, loss=115.813, backward_time=0.089, grad_norm=46.117, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.005, optim0_lr0=3.496e-04, train_time=0.245
[lambda-Lambda-Vector] 2025-04-01 18:05:03,182 (trainer:779) INFO: 7epoch:train:1233-1309batch: iter_time=5.310e-05, forward_time=0.077, loss_ctc=106.513, loss=106.513, backward_time=0.081, grad_norm=51.542, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.005, optim0_lr0=3.522e-04, train_time=0.224
[lambda-Lambda-Vector] 2025-04-01 18:05:19,867 (trainer:779) INFO: 7epoch:train:1310-1386batch: iter_time=5.033e-05, forward_time=0.073, loss_ctc=94.121, loss=94.121, backward_time=0.080, grad_norm=41.587, clip=98.701, loss_scale=2.097e+06, optim_step_time=0.005, optim0_lr0=3.548e-04, train_time=0.217
[lambda-Lambda-Vector] 2025-04-01 18:05:37,144 (trainer:779) INFO: 7epoch:train:1387-1463batch: iter_time=4.986e-05, forward_time=0.075, loss_ctc=126.211, loss=126.211, backward_time=0.083, grad_norm=47.657, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.005, optim0_lr0=3.573e-04, train_time=0.224
[lambda-Lambda-Vector] 2025-04-01 18:05:54,397 (trainer:779) INFO: 7epoch:train:1464-1540batch: iter_time=5.039e-05, forward_time=0.077, loss_ctc=99.354, loss=99.354, backward_time=0.081, grad_norm=40.215, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.005, optim0_lr0=3.599e-04, train_time=0.224
[lambda-Lambda-Vector] 2025-04-01 18:06:59,544 (trainer:365) INFO: 7epoch results: [train] iter_time=8.739e-05, forward_time=0.064, loss_ctc=105.216, loss=105.216, backward_time=0.069, grad_norm=103.337, clip=99.742, loss_scale=1.619e+06, optim_step_time=0.005, optim0_lr0=3.357e-04, train_time=0.189, time=4 minutes and 53.78 seconds, total_count=10843, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=117.941, cer_ctc=0.932, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=117.941, time=1 minute and 2.9 seconds, total_count=2233, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 18:07:02,104 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 18:07:02,104 (trainer:299) INFO: 8/70epoch started. Estimated time to finish: 5 hours, 20 minutes and 3.36 seconds
[lambda-Lambda-Vector] 2025-04-01 18:07:19,591 (trainer:779) INFO: 8epoch:train:1-77batch: iter_time=8.272e-04, forward_time=0.074, loss_ctc=112.486, loss=112.486, backward_time=0.080, grad_norm=42.941, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.005, optim0_lr0=3.628e-04, train_time=0.227
[lambda-Lambda-Vector] 2025-04-01 18:07:36,502 (trainer:779) INFO: 8epoch:train:78-154batch: iter_time=5.030e-05, forward_time=0.076, loss_ctc=103.038, loss=103.038, backward_time=0.081, grad_norm=45.507, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.005, optim0_lr0=3.653e-04, train_time=0.220
[lambda-Lambda-Vector] 2025-04-01 18:07:54,601 (trainer:779) INFO: 8epoch:train:155-231batch: iter_time=5.210e-05, forward_time=0.081, loss_ctc=140.123, loss=140.123, backward_time=0.087, grad_norm=47.347, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.005, optim0_lr0=3.679e-04, train_time=0.235
[lambda-Lambda-Vector] 2025-04-01 18:08:11,798 (trainer:779) INFO: 8epoch:train:232-308batch: iter_time=5.070e-05, forward_time=0.077, loss_ctc=88.343, loss=88.343, backward_time=0.081, grad_norm=36.526, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.005, optim0_lr0=3.705e-04, train_time=0.223
[lambda-Lambda-Vector] 2025-04-01 18:08:29,019 (trainer:779) INFO: 8epoch:train:309-385batch: iter_time=4.967e-05, forward_time=0.075, loss_ctc=99.724, loss=99.724, backward_time=0.084, grad_norm=46.662, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.004, optim0_lr0=3.730e-04, train_time=0.224
[lambda-Lambda-Vector] 2025-04-01 18:08:45,215 (trainer:779) INFO: 8epoch:train:386-462batch: iter_time=4.951e-05, forward_time=0.071, loss_ctc=102.035, loss=102.035, backward_time=0.078, grad_norm=114.045, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.004, optim0_lr0=3.756e-04, train_time=0.210
[lambda-Lambda-Vector] 2025-04-01 18:09:02,284 (trainer:779) INFO: 8epoch:train:463-539batch: iter_time=4.982e-05, forward_time=0.076, loss_ctc=110.922, loss=110.922, backward_time=0.079, grad_norm=80.088, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.005, optim0_lr0=3.782e-04, train_time=0.222
[lambda-Lambda-Vector] 2025-04-01 18:09:19,924 (trainer:779) INFO: 8epoch:train:540-616batch: iter_time=4.842e-05, forward_time=0.077, loss_ctc=112.621, loss=112.621, backward_time=0.086, grad_norm=69.952, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.005, optim0_lr0=3.807e-04, train_time=0.229
[lambda-Lambda-Vector] 2025-04-01 18:09:36,514 (trainer:779) INFO: 8epoch:train:617-693batch: iter_time=4.829e-05, forward_time=0.074, loss_ctc=111.849, loss=111.849, backward_time=0.078, grad_norm=67.727, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.004, optim0_lr0=3.833e-04, train_time=0.215
[lambda-Lambda-Vector] 2025-04-01 18:09:52,890 (trainer:779) INFO: 8epoch:train:694-770batch: iter_time=4.913e-05, forward_time=0.072, loss_ctc=106.343, loss=106.343, backward_time=0.079, grad_norm=68.052, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.004, optim0_lr0=3.859e-04, train_time=0.213
[lambda-Lambda-Vector] 2025-04-01 18:10:08,328 (trainer:779) INFO: 8epoch:train:771-847batch: iter_time=4.962e-05, forward_time=0.068, loss_ctc=106.522, loss=106.522, backward_time=0.073, grad_norm=62.689, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.004, optim0_lr0=3.884e-04, train_time=0.200
[lambda-Lambda-Vector] 2025-04-01 18:10:24,609 (trainer:779) INFO: 8epoch:train:848-924batch: iter_time=4.813e-05, forward_time=0.072, loss_ctc=113.196, loss=113.196, backward_time=0.077, grad_norm=66.163, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.004, optim0_lr0=3.910e-04, train_time=0.211
[lambda-Lambda-Vector] 2025-04-01 18:10:40,356 (trainer:779) INFO: 8epoch:train:925-1001batch: iter_time=4.980e-05, forward_time=0.071, loss_ctc=81.116, loss=81.116, backward_time=0.075, grad_norm=61.063, clip=98.701, loss_scale=2.097e+06, optim_step_time=0.005, optim0_lr0=3.936e-04, train_time=0.204
[lambda-Lambda-Vector] 2025-04-01 18:10:56,547 (trainer:779) INFO: 8epoch:train:1002-1078batch: iter_time=4.861e-05, forward_time=0.072, loss_ctc=103.349, loss=103.349, backward_time=0.077, grad_norm=76.677, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.005, optim0_lr0=3.961e-04, train_time=0.210
[lambda-Lambda-Vector] 2025-04-01 18:11:12,547 (trainer:779) INFO: 8epoch:train:1079-1155batch: iter_time=4.940e-05, forward_time=0.071, loss_ctc=94.084, loss=94.084, backward_time=0.076, grad_norm=87.680, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.005, optim0_lr0=3.987e-04, train_time=0.208
[lambda-Lambda-Vector] 2025-04-01 18:11:28,342 (trainer:779) INFO: 8epoch:train:1156-1232batch: iter_time=4.802e-05, forward_time=0.071, loss_ctc=107.286, loss=107.286, backward_time=0.076, grad_norm=98.506, clip=100.000, loss_scale=4.140e+06, optim_step_time=0.004, optim0_lr0=4.013e-04, train_time=0.205
[lambda-Lambda-Vector] 2025-04-01 18:11:45,524 (trainer:779) INFO: 8epoch:train:1233-1309batch: iter_time=4.945e-05, forward_time=0.076, loss_ctc=96.906, loss=96.906, backward_time=0.082, grad_norm=67.785, clip=98.701, loss_scale=4.194e+06, optim_step_time=0.004, optim0_lr0=4.038e-04, train_time=0.223
[lambda-Lambda-Vector] 2025-04-01 18:12:02,312 (trainer:779) INFO: 8epoch:train:1310-1386batch: iter_time=5.226e-05, forward_time=0.075, loss_ctc=106.578, loss=106.578, backward_time=0.080, grad_norm=112.858, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.005, optim0_lr0=4.064e-04, train_time=0.218
[lambda-Lambda-Vector] 2025-04-01 18:12:20,938 (trainer:779) INFO: 8epoch:train:1387-1463batch: iter_time=5.496e-05, forward_time=0.077, loss_ctc=109.629, loss=109.629, backward_time=0.085, grad_norm=104.001, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.005, optim0_lr0=4.090e-04, train_time=0.242
[lambda-Lambda-Vector] 2025-04-01 18:12:38,136 (trainer:779) INFO: 8epoch:train:1464-1540batch: iter_time=5.699e-05, forward_time=0.077, loss_ctc=109.317, loss=109.317, backward_time=0.081, grad_norm=78.940, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.005, optim0_lr0=4.115e-04, train_time=0.223
[lambda-Lambda-Vector] 2025-04-01 18:13:39,902 (trainer:365) INFO: 8epoch results: [train] iter_time=8.884e-05, forward_time=0.074, loss_ctc=104.639, loss=104.639, backward_time=0.080, grad_norm=71.876, clip=99.871, loss_scale=2.628e+06, optim_step_time=0.005, optim0_lr0=3.873e-04, train_time=0.218, time=5 minutes and 38.28 seconds, total_count=12392, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=113.011, cer_ctc=0.931, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=113.011, time=59.52 seconds, total_count=2552, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 18:13:41,516 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 18:13:41,517 (trainer:299) INFO: 9/70epoch started. Estimated time to finish: 5 hours, 27 minutes and 11.67 seconds
[lambda-Lambda-Vector] 2025-04-01 18:13:57,838 (trainer:779) INFO: 9epoch:train:1-77batch: iter_time=8.024e-04, forward_time=0.068, loss_ctc=113.238, loss=113.238, backward_time=0.075, grad_norm=62.892, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.005, optim0_lr0=4.144e-04, train_time=0.212
[lambda-Lambda-Vector] 2025-04-01 18:14:13,306 (trainer:779) INFO: 9epoch:train:78-154batch: iter_time=5.966e-05, forward_time=0.070, loss_ctc=83.265, loss=83.265, backward_time=0.073, grad_norm=71.526, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.005, optim0_lr0=4.170e-04, train_time=0.201
[lambda-Lambda-Vector] 2025-04-01 18:14:29,561 (trainer:779) INFO: 9epoch:train:155-231batch: iter_time=6.448e-05, forward_time=0.072, loss_ctc=96.030, loss=96.030, backward_time=0.075, grad_norm=92.024, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.005, optim0_lr0=4.195e-04, train_time=0.211
[lambda-Lambda-Vector] 2025-04-01 18:14:45,222 (trainer:779) INFO: 9epoch:train:232-308batch: iter_time=6.551e-05, forward_time=0.070, loss_ctc=90.300, loss=90.300, backward_time=0.075, grad_norm=157.546, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.005, optim0_lr0=4.221e-04, train_time=0.203
[lambda-Lambda-Vector] 2025-04-01 18:15:01,654 (trainer:779) INFO: 9epoch:train:309-385batch: iter_time=6.531e-05, forward_time=0.074, loss_ctc=120.461, loss=120.461, backward_time=0.077, grad_norm=161.631, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.005, optim0_lr0=4.247e-04, train_time=0.213
[lambda-Lambda-Vector] 2025-04-01 18:15:18,636 (trainer:779) INFO: 9epoch:train:386-462batch: iter_time=6.556e-05, forward_time=0.074, loss_ctc=104.801, loss=104.801, backward_time=0.080, grad_norm=250.098, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.005, optim0_lr0=4.272e-04, train_time=0.220
[lambda-Lambda-Vector] 2025-04-01 18:15:36,383 (trainer:779) INFO: 9epoch:train:463-539batch: iter_time=6.461e-05, forward_time=0.076, loss_ctc=130.498, loss=130.498, backward_time=0.079, grad_norm=564.522, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.005, optim0_lr0=4.298e-04, train_time=0.230
[lambda-Lambda-Vector] 2025-04-01 18:15:51,861 (trainer:779) INFO: 9epoch:train:540-616batch: iter_time=6.476e-05, forward_time=0.070, loss_ctc=87.727, loss=87.727, backward_time=0.072, grad_norm=250.126, clip=97.403, loss_scale=4.194e+06, optim_step_time=0.005, optim0_lr0=4.324e-04, train_time=0.201
[lambda-Lambda-Vector] 2025-04-01 18:16:07,500 (trainer:779) INFO: 9epoch:train:617-693batch: iter_time=6.081e-05, forward_time=0.069, loss_ctc=111.205, loss=111.205, backward_time=0.074, grad_norm=138.617, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.005, optim0_lr0=4.349e-04, train_time=0.203
[lambda-Lambda-Vector] 2025-04-01 18:16:23,434 (trainer:779) INFO: 9epoch:train:694-770batch: iter_time=6.019e-05, forward_time=0.070, loss_ctc=107.039, loss=107.039, backward_time=0.077, grad_norm=152.894, clip=98.701, loss_scale=4.194e+06, optim_step_time=0.005, optim0_lr0=4.375e-04, train_time=0.207
[lambda-Lambda-Vector] 2025-04-01 18:16:39,073 (trainer:779) INFO: 9epoch:train:771-847batch: iter_time=6.390e-05, forward_time=0.070, loss_ctc=107.101, loss=107.101, backward_time=0.073, grad_norm=71.990, clip=98.701, loss_scale=4.194e+06, optim_step_time=0.005, optim0_lr0=4.401e-04, train_time=0.203
[lambda-Lambda-Vector] 2025-04-01 18:16:54,845 (trainer:779) INFO: 9epoch:train:848-924batch: iter_time=6.226e-05, forward_time=0.072, loss_ctc=106.752, loss=106.752, backward_time=0.075, grad_norm=61.384, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.005, optim0_lr0=4.426e-04, train_time=0.205
[lambda-Lambda-Vector] 2025-04-01 18:17:11,162 (trainer:779) INFO: 9epoch:train:925-1001batch: iter_time=6.274e-05, forward_time=0.073, loss_ctc=109.589, loss=109.589, backward_time=0.076, grad_norm=58.956, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.005, optim0_lr0=4.452e-04, train_time=0.212
[lambda-Lambda-Vector] 2025-04-01 18:17:27,341 (trainer:779) INFO: 9epoch:train:1002-1078batch: iter_time=6.228e-05, forward_time=0.071, loss_ctc=120.225, loss=120.225, backward_time=0.078, grad_norm=54.747, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.005, optim0_lr0=4.478e-04, train_time=0.210
[lambda-Lambda-Vector] 2025-04-01 18:17:43,282 (trainer:779) INFO: 9epoch:train:1079-1155batch: iter_time=6.201e-05, forward_time=0.070, loss_ctc=111.897, loss=111.897, backward_time=0.077, grad_norm=50.543, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.005, optim0_lr0=4.503e-04, train_time=0.207
[lambda-Lambda-Vector] 2025-04-01 18:17:59,212 (trainer:779) INFO: 9epoch:train:1156-1232batch: iter_time=6.323e-05, forward_time=0.073, loss_ctc=106.190, loss=106.190, backward_time=0.075, grad_norm=57.718, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.005, optim0_lr0=4.529e-04, train_time=0.207
[lambda-Lambda-Vector] 2025-04-01 18:18:15,521 (trainer:779) INFO: 9epoch:train:1233-1309batch: iter_time=6.191e-05, forward_time=0.072, loss_ctc=118.946, loss=118.946, backward_time=0.079, grad_norm=82.994, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.005, optim0_lr0=4.555e-04, train_time=0.212
[lambda-Lambda-Vector] 2025-04-01 18:18:31,762 (trainer:779) INFO: 9epoch:train:1310-1386batch: iter_time=6.138e-05, forward_time=0.072, loss_ctc=104.826, loss=104.826, backward_time=0.075, grad_norm=79.710, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.005, optim0_lr0=4.580e-04, train_time=0.211
[lambda-Lambda-Vector] 2025-04-01 18:18:46,582 (trainer:779) INFO: 9epoch:train:1387-1463batch: iter_time=6.273e-05, forward_time=0.067, loss_ctc=87.902, loss=87.902, backward_time=0.070, grad_norm=41.595, clip=98.701, loss_scale=4.194e+06, optim_step_time=0.005, optim0_lr0=4.606e-04, train_time=0.192
[lambda-Lambda-Vector] 2025-04-01 18:19:02,727 (trainer:779) INFO: 9epoch:train:1464-1540batch: iter_time=6.235e-05, forward_time=0.070, loss_ctc=99.156, loss=99.156, backward_time=0.078, grad_norm=56.976, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.005, optim0_lr0=4.632e-04, train_time=0.210
[lambda-Lambda-Vector] 2025-04-01 18:20:01,961 (trainer:365) INFO: 9epoch results: [train] iter_time=9.960e-05, forward_time=0.071, loss_ctc=104.655, loss=104.655, backward_time=0.076, grad_norm=125.622, clip=99.677, loss_scale=4.194e+06, optim_step_time=0.005, optim0_lr0=4.389e-04, train_time=0.208, time=5 minutes and 23.35 seconds, total_count=13941, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=129.871, cer_ctc=0.941, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=129.871, time=57.1 seconds, total_count=2871, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 18:20:04,606 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 18:20:04,606 (trainer:299) INFO: 10/70epoch started. Estimated time to finish: 5 hours, 29 minutes and 25.41 seconds
[lambda-Lambda-Vector] 2025-04-01 18:20:21,627 (trainer:779) INFO: 10epoch:train:1-77batch: iter_time=8.152e-04, forward_time=0.073, loss_ctc=109.310, loss=109.310, backward_time=0.077, grad_norm=48.360, clip=100.000, loss_scale=5.175e+06, optim_step_time=0.005, optim0_lr0=4.660e-04, train_time=0.221
[lambda-Lambda-Vector] 2025-04-01 18:20:37,422 (trainer:779) INFO: 10epoch:train:78-154batch: iter_time=6.528e-05, forward_time=0.072, loss_ctc=84.256, loss=84.256, backward_time=0.074, grad_norm=46.943, clip=98.701, loss_scale=8.389e+06, optim_step_time=0.005, optim0_lr0=4.686e-04, train_time=0.205
[lambda-Lambda-Vector] 2025-04-01 18:20:53,586 (trainer:779) INFO: 10epoch:train:155-231batch: iter_time=6.379e-05, forward_time=0.073, loss_ctc=119.443, loss=119.443, backward_time=0.076, grad_norm=64.274, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.005, optim0_lr0=4.712e-04, train_time=0.210
[lambda-Lambda-Vector] 2025-04-01 18:21:09,288 (trainer:779) INFO: 10epoch:train:232-308batch: iter_time=6.385e-05, forward_time=0.068, loss_ctc=108.192, loss=108.192, backward_time=0.076, grad_norm=53.944, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.005, optim0_lr0=4.737e-04, train_time=0.204
[lambda-Lambda-Vector] 2025-04-01 18:21:27,033 (trainer:779) INFO: 10epoch:train:309-385batch: iter_time=6.375e-05, forward_time=0.079, loss_ctc=99.522, loss=99.522, backward_time=0.082, grad_norm=54.507, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.005, optim0_lr0=4.763e-04, train_time=0.230
[lambda-Lambda-Vector] 2025-04-01 18:21:44,215 (trainer:779) INFO: 10epoch:train:386-462batch: iter_time=6.099e-05, forward_time=0.077, loss_ctc=114.993, loss=114.993, backward_time=0.080, grad_norm=60.205, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.005, optim0_lr0=4.789e-04, train_time=0.223
[lambda-Lambda-Vector] 2025-04-01 18:22:02,571 (trainer:779) INFO: 10epoch:train:463-539batch: iter_time=6.011e-05, forward_time=0.083, loss_ctc=96.041, loss=96.041, backward_time=0.086, grad_norm=79.890, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.005, optim0_lr0=4.814e-04, train_time=0.238
[lambda-Lambda-Vector] 2025-04-01 18:22:20,412 (trainer:779) INFO: 10epoch:train:540-616batch: iter_time=6.166e-05, forward_time=0.078, loss_ctc=105.318, loss=105.318, backward_time=0.086, grad_norm=73.806, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.005, optim0_lr0=4.840e-04, train_time=0.232
[lambda-Lambda-Vector] 2025-04-01 18:22:37,956 (trainer:779) INFO: 10epoch:train:617-693batch: iter_time=6.122e-05, forward_time=0.078, loss_ctc=110.231, loss=110.231, backward_time=0.084, grad_norm=80.717, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.005, optim0_lr0=4.866e-04, train_time=0.228
[lambda-Lambda-Vector] 2025-04-01 18:22:56,374 (trainer:779) INFO: 10epoch:train:694-770batch: iter_time=6.172e-05, forward_time=0.084, loss_ctc=114.264, loss=114.264, backward_time=0.084, grad_norm=49.033, clip=97.403, loss_scale=8.389e+06, optim_step_time=0.005, optim0_lr0=4.891e-04, train_time=0.239
[lambda-Lambda-Vector] 2025-04-01 18:23:13,846 (trainer:779) INFO: 10epoch:train:771-847batch: iter_time=5.963e-05, forward_time=0.078, loss_ctc=97.100, loss=97.100, backward_time=0.084, grad_norm=47.975, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.005, optim0_lr0=4.917e-04, train_time=0.227
[lambda-Lambda-Vector] 2025-04-01 18:23:31,920 (trainer:779) INFO: 10epoch:train:848-924batch: iter_time=5.790e-05, forward_time=0.082, loss_ctc=108.354, loss=108.354, backward_time=0.086, grad_norm=48.956, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.005, optim0_lr0=4.943e-04, train_time=0.235
[lambda-Lambda-Vector] 2025-04-01 18:23:47,988 (trainer:779) INFO: 10epoch:train:925-1001batch: iter_time=5.805e-05, forward_time=0.072, loss_ctc=113.920, loss=113.920, backward_time=0.075, grad_norm=40.689, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.005, optim0_lr0=4.968e-04, train_time=0.209
[lambda-Lambda-Vector] 2025-04-01 18:24:04,295 (trainer:779) INFO: 10epoch:train:1002-1078batch: iter_time=6.148e-05, forward_time=0.073, loss_ctc=90.199, loss=90.199, backward_time=0.076, grad_norm=39.934, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.005, optim0_lr0=4.993e-04, train_time=0.212
[lambda-Lambda-Vector] 2025-04-01 18:24:20,996 (trainer:779) INFO: 10epoch:train:1079-1155batch: iter_time=5.259e-05, forward_time=0.075, loss_ctc=115.972, loss=115.972, backward_time=0.079, grad_norm=49.303, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.005, optim0_lr0=4.990e-04, train_time=0.217
[lambda-Lambda-Vector] 2025-04-01 18:24:38,111 (trainer:779) INFO: 10epoch:train:1156-1232batch: iter_time=5.506e-05, forward_time=0.073, loss_ctc=110.591, loss=110.591, backward_time=0.078, grad_norm=47.257, clip=98.701, loss_scale=8.389e+06, optim_step_time=0.005, optim0_lr0=4.977e-04, train_time=0.222
[lambda-Lambda-Vector] 2025-04-01 18:24:54,070 (trainer:779) INFO: 10epoch:train:1233-1309batch: iter_time=5.681e-05, forward_time=0.070, loss_ctc=105.061, loss=105.061, backward_time=0.076, grad_norm=47.621, clip=98.701, loss_scale=8.389e+06, optim_step_time=0.005, optim0_lr0=4.965e-04, train_time=0.207
[lambda-Lambda-Vector] 2025-04-01 18:25:11,050 (trainer:779) INFO: 10epoch:train:1310-1386batch: iter_time=5.782e-05, forward_time=0.075, loss_ctc=121.311, loss=121.311, backward_time=0.079, grad_norm=54.690, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.005, optim0_lr0=4.952e-04, train_time=0.220
[lambda-Lambda-Vector] 2025-04-01 18:25:27,325 (trainer:779) INFO: 10epoch:train:1387-1463batch: iter_time=5.889e-05, forward_time=0.072, loss_ctc=101.005, loss=101.005, backward_time=0.076, grad_norm=40.758, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.005, optim0_lr0=4.940e-04, train_time=0.211
[lambda-Lambda-Vector] 2025-04-01 18:25:42,681 (trainer:779) INFO: 10epoch:train:1464-1540batch: iter_time=5.684e-05, forward_time=0.067, loss_ctc=96.860, loss=96.860, backward_time=0.073, grad_norm=48.762, clip=98.701, loss_scale=8.389e+06, optim_step_time=0.005, optim0_lr0=4.928e-04, train_time=0.199
[lambda-Lambda-Vector] 2025-04-01 18:26:43,275 (trainer:365) INFO: 10epoch results: [train] iter_time=9.730e-05, forward_time=0.075, loss_ctc=104.827, loss=104.827, backward_time=0.079, grad_norm=53.780, clip=99.613, loss_scale=8.229e+06, optim_step_time=0.005, optim0_lr0=4.867e-04, train_time=0.219, time=5 minutes and 39.85 seconds, total_count=15490, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=111.731, cer_ctc=0.942, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=111.731, time=58.82 seconds, total_count=3190, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 18:26:44,979 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 18:26:44,979 (trainer:299) INFO: 11/70epoch started. Estimated time to finish: 5 hours, 31 minutes and 39.49 seconds
[lambda-Lambda-Vector] 2025-04-01 18:27:03,206 (trainer:779) INFO: 11epoch:train:1-77batch: iter_time=9.653e-04, forward_time=0.080, loss_ctc=89.765, loss=89.765, backward_time=0.080, grad_norm=58.395, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.006, optim0_lr0=4.914e-04, train_time=0.237
[lambda-Lambda-Vector] 2025-04-01 18:27:19,423 (trainer:779) INFO: 11epoch:train:78-154batch: iter_time=6.544e-05, forward_time=0.072, loss_ctc=102.442, loss=102.442, backward_time=0.076, grad_norm=50.257, clip=98.701, loss_scale=8.389e+06, optim_step_time=0.005, optim0_lr0=4.902e-04, train_time=0.211
[lambda-Lambda-Vector] 2025-04-01 18:27:35,979 (trainer:779) INFO: 11epoch:train:155-231batch: iter_time=6.444e-05, forward_time=0.074, loss_ctc=114.757, loss=114.757, backward_time=0.079, grad_norm=51.013, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.005, optim0_lr0=4.890e-04, train_time=0.215
[lambda-Lambda-Vector] 2025-04-01 18:27:53,070 (trainer:779) INFO: 11epoch:train:232-308batch: iter_time=5.550e-05, forward_time=0.077, loss_ctc=117.428, loss=117.428, backward_time=0.081, grad_norm=47.210, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.005, optim0_lr0=4.878e-04, train_time=0.222
[lambda-Lambda-Vector] 2025-04-01 18:28:10,298 (trainer:779) INFO: 11epoch:train:309-385batch: iter_time=6.423e-05, forward_time=0.074, loss_ctc=119.466, loss=119.466, backward_time=0.084, grad_norm=53.040, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.005, optim0_lr0=4.866e-04, train_time=0.224
[lambda-Lambda-Vector] 2025-04-01 18:28:26,701 (trainer:779) INFO: 11epoch:train:386-462batch: iter_time=6.395e-05, forward_time=0.068, loss_ctc=100.143, loss=100.143, backward_time=0.074, grad_norm=41.690, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.005, optim0_lr0=4.854e-04, train_time=0.213
[lambda-Lambda-Vector] 2025-04-01 18:28:42,516 (trainer:779) INFO: 11epoch:train:463-539batch: iter_time=5.877e-05, forward_time=0.069, loss_ctc=100.505, loss=100.505, backward_time=0.076, grad_norm=48.465, clip=100.000, loss_scale=1.155e+07, optim_step_time=0.005, optim0_lr0=4.842e-04, train_time=0.205
[lambda-Lambda-Vector] 2025-04-01 18:28:58,518 (trainer:779) INFO: 11epoch:train:540-616batch: iter_time=5.731e-05, forward_time=0.071, loss_ctc=114.923, loss=114.923, backward_time=0.076, grad_norm=44.853, clip=98.701, loss_scale=1.678e+07, optim_step_time=0.005, optim0_lr0=4.831e-04, train_time=0.208
[lambda-Lambda-Vector] 2025-04-01 18:29:14,873 (trainer:779) INFO: 11epoch:train:617-693batch: iter_time=5.845e-05, forward_time=0.074, loss_ctc=94.906, loss=94.906, backward_time=0.076, grad_norm=45.566, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.005, optim0_lr0=4.819e-04, train_time=0.212
[lambda-Lambda-Vector] 2025-04-01 18:29:31,033 (trainer:779) INFO: 11epoch:train:694-770batch: iter_time=5.744e-05, forward_time=0.071, loss_ctc=94.448, loss=94.448, backward_time=0.077, grad_norm=46.648, clip=96.104, loss_scale=1.678e+07, optim_step_time=0.005, optim0_lr0=4.808e-04, train_time=0.210
[lambda-Lambda-Vector] 2025-04-01 18:29:47,229 (trainer:779) INFO: 11epoch:train:771-847batch: iter_time=5.707e-05, forward_time=0.073, loss_ctc=107.749, loss=107.749, backward_time=0.076, grad_norm=51.342, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.005, optim0_lr0=4.796e-04, train_time=0.210
[lambda-Lambda-Vector] 2025-04-01 18:30:03,060 (trainer:779) INFO: 11epoch:train:848-924batch: iter_time=5.708e-05, forward_time=0.071, loss_ctc=112.385, loss=112.385, backward_time=0.075, grad_norm=46.756, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.005, optim0_lr0=4.785e-04, train_time=0.205
[lambda-Lambda-Vector] 2025-04-01 18:30:18,795 (trainer:779) INFO: 11epoch:train:925-1001batch: iter_time=6.606e-05, forward_time=0.070, loss_ctc=104.643, loss=104.643, backward_time=0.074, grad_norm=50.214, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.006, optim0_lr0=4.774e-04, train_time=0.204
[lambda-Lambda-Vector] 2025-04-01 18:30:35,936 (trainer:779) INFO: 11epoch:train:1002-1078batch: iter_time=6.154e-05, forward_time=0.074, loss_ctc=97.220, loss=97.220, backward_time=0.082, grad_norm=45.408, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.005, optim0_lr0=4.763e-04, train_time=0.223
[lambda-Lambda-Vector] 2025-04-01 18:30:52,506 (trainer:779) INFO: 11epoch:train:1079-1155batch: iter_time=6.440e-05, forward_time=0.074, loss_ctc=118.215, loss=118.215, backward_time=0.078, grad_norm=60.865, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.005, optim0_lr0=4.752e-04, train_time=0.215
[lambda-Lambda-Vector] 2025-04-01 18:31:09,318 (trainer:779) INFO: 11epoch:train:1156-1232batch: iter_time=6.190e-05, forward_time=0.076, loss_ctc=101.735, loss=101.735, backward_time=0.080, grad_norm=60.075, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.005, optim0_lr0=4.741e-04, train_time=0.218
[lambda-Lambda-Vector] 2025-04-01 18:31:27,074 (trainer:779) INFO: 11epoch:train:1233-1309batch: iter_time=6.312e-05, forward_time=0.079, loss_ctc=119.804, loss=119.804, backward_time=0.083, grad_norm=61.818, clip=98.701, loss_scale=1.678e+07, optim_step_time=0.005, optim0_lr0=4.730e-04, train_time=0.230
[lambda-Lambda-Vector] 2025-04-01 18:31:44,567 (trainer:779) INFO: 11epoch:train:1310-1386batch: iter_time=6.338e-05, forward_time=0.078, loss_ctc=91.404, loss=91.404, backward_time=0.082, grad_norm=59.909, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.005, optim0_lr0=4.719e-04, train_time=0.227
[lambda-Lambda-Vector] 2025-04-01 18:32:02,585 (trainer:779) INFO: 11epoch:train:1387-1463batch: iter_time=5.921e-05, forward_time=0.080, loss_ctc=110.851, loss=110.851, backward_time=0.084, grad_norm=69.877, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.005, optim0_lr0=4.708e-04, train_time=0.234
[lambda-Lambda-Vector] 2025-04-01 18:32:18,998 (trainer:779) INFO: 11epoch:train:1464-1540batch: iter_time=6.419e-05, forward_time=0.074, loss_ctc=93.659, loss=93.659, backward_time=0.077, grad_norm=65.449, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.005, optim0_lr0=4.698e-04, train_time=0.213
[lambda-Lambda-Vector] 2025-04-01 18:33:20,481 (trainer:365) INFO: 11epoch results: [train] iter_time=1.061e-04, forward_time=0.074, loss_ctc=104.414, loss=104.414, backward_time=0.078, grad_norm=53.027, clip=99.613, loss_scale=1.402e+07, optim_step_time=0.005, optim0_lr0=4.803e-04, train_time=0.217, time=5 minutes and 36.18 seconds, total_count=17039, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=126.492, cer_ctc=0.948, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=126.492, time=59.32 seconds, total_count=3509, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 18:33:22,992 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 18:33:23,009 (trainer:487) INFO: The model files were removed: exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/1epoch.pth
[lambda-Lambda-Vector] 2025-04-01 18:33:23,009 (trainer:299) INFO: 12/70epoch started. Estimated time to finish: 5 hours, 32 minutes and 3.82 seconds
[lambda-Lambda-Vector] 2025-04-01 18:33:39,767 (trainer:779) INFO: 12epoch:train:1-77batch: iter_time=5.992e-04, forward_time=0.072, loss_ctc=97.828, loss=97.828, backward_time=0.075, grad_norm=65.821, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.005, optim0_lr0=4.686e-04, train_time=0.217
[lambda-Lambda-Vector] 2025-04-01 18:33:56,227 (trainer:779) INFO: 12epoch:train:78-154batch: iter_time=5.863e-05, forward_time=0.073, loss_ctc=96.924, loss=96.924, backward_time=0.077, grad_norm=60.060, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.005, optim0_lr0=4.675e-04, train_time=0.214
[lambda-Lambda-Vector] 2025-04-01 18:34:12,202 (trainer:779) INFO: 12epoch:train:155-231batch: iter_time=6.415e-05, forward_time=0.074, loss_ctc=107.343, loss=107.343, backward_time=0.074, grad_norm=51.103, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.005, optim0_lr0=4.665e-04, train_time=0.207
[lambda-Lambda-Vector] 2025-04-01 18:34:28,656 (trainer:779) INFO: 12epoch:train:232-308batch: iter_time=1.231e-04, forward_time=0.075, loss_ctc=108.768, loss=108.768, backward_time=0.077, grad_norm=57.725, clip=98.701, loss_scale=1.678e+07, optim_step_time=0.005, optim0_lr0=4.654e-04, train_time=0.214
[lambda-Lambda-Vector] 2025-04-01 18:34:47,070 (trainer:779) INFO: 12epoch:train:309-385batch: iter_time=6.422e-05, forward_time=0.085, loss_ctc=109.574, loss=109.574, backward_time=0.083, grad_norm=48.281, clip=98.701, loss_scale=1.678e+07, optim_step_time=0.005, optim0_lr0=4.644e-04, train_time=0.239
[lambda-Lambda-Vector] 2025-04-01 18:35:04,095 (trainer:779) INFO: 12epoch:train:386-462batch: iter_time=6.328e-05, forward_time=0.078, loss_ctc=104.521, loss=104.521, backward_time=0.079, grad_norm=52.636, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.005, optim0_lr0=4.634e-04, train_time=0.221
[lambda-Lambda-Vector] 2025-04-01 18:35:20,502 (trainer:779) INFO: 12epoch:train:463-539batch: iter_time=5.858e-05, forward_time=0.075, loss_ctc=93.450, loss=93.450, backward_time=0.078, grad_norm=46.133, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.005, optim0_lr0=4.624e-04, train_time=0.213
[lambda-Lambda-Vector] 2025-04-01 18:35:34,614 (trainer:779) INFO: 12epoch:train:540-616batch: iter_time=6.338e-05, forward_time=0.064, loss_ctc=108.713, loss=108.713, backward_time=0.066, grad_norm=54.908, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.005, optim0_lr0=4.614e-04, train_time=0.183
[lambda-Lambda-Vector] 2025-04-01 18:35:46,424 (trainer:779) INFO: 12epoch:train:617-693batch: iter_time=5.731e-05, forward_time=0.053, loss_ctc=80.502, loss=80.502, backward_time=0.056, grad_norm=51.751, clip=97.403, loss_scale=1.678e+07, optim_step_time=0.005, optim0_lr0=4.604e-04, train_time=0.153
[lambda-Lambda-Vector] 2025-04-01 18:35:58,816 (trainer:779) INFO: 12epoch:train:694-770batch: iter_time=5.301e-05, forward_time=0.055, loss_ctc=113.220, loss=113.220, backward_time=0.059, grad_norm=59.811, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.005, optim0_lr0=4.594e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 18:36:11,348 (trainer:779) INFO: 12epoch:train:771-847batch: iter_time=5.172e-05, forward_time=0.055, loss_ctc=118.000, loss=118.000, backward_time=0.060, grad_norm=72.909, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.005, optim0_lr0=4.584e-04, train_time=0.163
[lambda-Lambda-Vector] 2025-04-01 18:36:23,730 (trainer:779) INFO: 12epoch:train:848-924batch: iter_time=5.285e-05, forward_time=0.055, loss_ctc=91.749, loss=91.749, backward_time=0.059, grad_norm=75.080, clip=98.701, loss_scale=1.678e+07, optim_step_time=0.005, optim0_lr0=4.574e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 18:36:36,178 (trainer:779) INFO: 12epoch:train:925-1001batch: iter_time=6.056e-05, forward_time=0.055, loss_ctc=111.796, loss=111.796, backward_time=0.059, grad_norm=77.780, clip=100.000, loss_scale=2.549e+07, optim_step_time=0.005, optim0_lr0=4.564e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 18:36:48,779 (trainer:779) INFO: 12epoch:train:1002-1078batch: iter_time=6.227e-05, forward_time=0.056, loss_ctc=121.089, loss=121.089, backward_time=0.060, grad_norm=73.053, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.005, optim0_lr0=4.554e-04, train_time=0.164
[lambda-Lambda-Vector] 2025-04-01 18:37:01,046 (trainer:779) INFO: 12epoch:train:1079-1155batch: iter_time=5.724e-05, forward_time=0.054, loss_ctc=109.762, loss=109.762, backward_time=0.059, grad_norm=84.003, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.005, optim0_lr0=4.545e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 18:37:14,290 (trainer:779) INFO: 12epoch:train:1156-1232batch: iter_time=5.115e-05, forward_time=0.054, loss_ctc=106.724, loss=106.724, backward_time=0.059, grad_norm=79.003, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.005, optim0_lr0=4.535e-04, train_time=0.172
[lambda-Lambda-Vector] 2025-04-01 18:37:26,361 (trainer:779) INFO: 12epoch:train:1233-1309batch: iter_time=5.069e-05, forward_time=0.053, loss_ctc=103.376, loss=103.376, backward_time=0.058, grad_norm=81.053, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.005, optim0_lr0=4.525e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 18:37:38,806 (trainer:779) INFO: 12epoch:train:1310-1386batch: iter_time=5.617e-05, forward_time=0.056, loss_ctc=106.008, loss=106.008, backward_time=0.059, grad_norm=81.152, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.005, optim0_lr0=4.516e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 18:37:51,070 (trainer:779) INFO: 12epoch:train:1387-1463batch: iter_time=5.170e-05, forward_time=0.055, loss_ctc=98.682, loss=98.682, backward_time=0.059, grad_norm=74.231, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.005, optim0_lr0=4.507e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 18:38:03,240 (trainer:779) INFO: 12epoch:train:1464-1540batch: iter_time=5.080e-05, forward_time=0.054, loss_ctc=114.482, loss=114.482, backward_time=0.058, grad_norm=62.644, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.005, optim0_lr0=4.497e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 18:38:55,313 (trainer:365) INFO: 12epoch results: [train] iter_time=8.725e-05, forward_time=0.062, loss_ctc=104.161, loss=104.161, backward_time=0.066, grad_norm=65.419, clip=99.677, loss_scale=2.315e+07, optim_step_time=0.005, optim0_lr0=4.589e-04, train_time=0.182, time=4 minutes and 41.99 seconds, total_count=18588, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=116.817, cer_ctc=0.942, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=116.817, time=50.31 seconds, total_count=3828, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 18:38:56,976 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 18:38:56,993 (trainer:487) INFO: The model files were removed: exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/5epoch.pth
[lambda-Lambda-Vector] 2025-04-01 18:38:56,993 (trainer:299) INFO: 13/70epoch started. Estimated time to finish: 5 hours, 26 minutes and 8.21 seconds
[lambda-Lambda-Vector] 2025-04-01 18:39:13,341 (trainer:779) INFO: 13epoch:train:1-77batch: iter_time=7.561e-04, forward_time=0.069, loss_ctc=104.862, loss=104.862, backward_time=0.073, grad_norm=77.502, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.006, optim0_lr0=4.487e-04, train_time=0.212
[lambda-Lambda-Vector] 2025-04-01 18:39:29,236 (trainer:779) INFO: 13epoch:train:78-154batch: iter_time=7.245e-05, forward_time=0.071, loss_ctc=101.835, loss=101.835, backward_time=0.077, grad_norm=81.947, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.006, optim0_lr0=4.478e-04, train_time=0.206
[lambda-Lambda-Vector] 2025-04-01 18:39:41,728 (trainer:779) INFO: 13epoch:train:155-231batch: iter_time=5.691e-05, forward_time=0.056, loss_ctc=120.882, loss=120.882, backward_time=0.060, grad_norm=62.597, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.005, optim0_lr0=4.468e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 18:39:54,381 (trainer:779) INFO: 13epoch:train:232-308batch: iter_time=5.169e-05, forward_time=0.056, loss_ctc=122.022, loss=122.022, backward_time=0.061, grad_norm=72.404, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.005, optim0_lr0=4.459e-04, train_time=0.164
[lambda-Lambda-Vector] 2025-04-01 18:40:06,553 (trainer:779) INFO: 13epoch:train:309-385batch: iter_time=5.100e-05, forward_time=0.054, loss_ctc=109.954, loss=109.954, backward_time=0.058, grad_norm=69.049, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.005, optim0_lr0=4.450e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 18:40:20,092 (trainer:779) INFO: 13epoch:train:386-462batch: iter_time=5.192e-05, forward_time=0.056, loss_ctc=112.430, loss=112.430, backward_time=0.060, grad_norm=67.317, clip=98.701, loss_scale=3.355e+07, optim_step_time=0.005, optim0_lr0=4.441e-04, train_time=0.176
[lambda-Lambda-Vector] 2025-04-01 18:40:32,145 (trainer:779) INFO: 13epoch:train:463-539batch: iter_time=5.125e-05, forward_time=0.054, loss_ctc=106.964, loss=106.964, backward_time=0.058, grad_norm=58.241, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.005, optim0_lr0=4.432e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 18:40:44,229 (trainer:779) INFO: 13epoch:train:540-616batch: iter_time=5.356e-05, forward_time=0.054, loss_ctc=91.488, loss=91.488, backward_time=0.058, grad_norm=59.587, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.005, optim0_lr0=4.423e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 18:40:56,482 (trainer:779) INFO: 13epoch:train:617-693batch: iter_time=5.242e-05, forward_time=0.054, loss_ctc=102.732, loss=102.732, backward_time=0.059, grad_norm=62.686, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.005, optim0_lr0=4.414e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 18:41:08,770 (trainer:779) INFO: 13epoch:train:694-770batch: iter_time=5.216e-05, forward_time=0.054, loss_ctc=105.404, loss=105.404, backward_time=0.059, grad_norm=57.462, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.005, optim0_lr0=4.406e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 18:41:21,023 (trainer:779) INFO: 13epoch:train:771-847batch: iter_time=5.026e-05, forward_time=0.054, loss_ctc=107.618, loss=107.618, backward_time=0.059, grad_norm=66.703, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.005, optim0_lr0=4.397e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 18:41:32,987 (trainer:779) INFO: 13epoch:train:848-924batch: iter_time=4.967e-05, forward_time=0.053, loss_ctc=99.043, loss=99.043, backward_time=0.057, grad_norm=61.643, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.005, optim0_lr0=4.388e-04, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 18:41:44,925 (trainer:779) INFO: 13epoch:train:925-1001batch: iter_time=4.821e-05, forward_time=0.053, loss_ctc=104.355, loss=104.355, backward_time=0.057, grad_norm=73.912, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.005, optim0_lr0=4.379e-04, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 18:41:57,141 (trainer:779) INFO: 13epoch:train:1002-1078batch: iter_time=4.856e-05, forward_time=0.055, loss_ctc=81.311, loss=81.311, backward_time=0.058, grad_norm=67.572, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.004, optim0_lr0=4.371e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 18:42:09,105 (trainer:779) INFO: 13epoch:train:1079-1155batch: iter_time=4.856e-05, forward_time=0.053, loss_ctc=98.688, loss=98.688, backward_time=0.057, grad_norm=64.571, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.004, optim0_lr0=4.362e-04, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 18:42:21,643 (trainer:779) INFO: 13epoch:train:1156-1232batch: iter_time=4.811e-05, forward_time=0.055, loss_ctc=109.584, loss=109.584, backward_time=0.060, grad_norm=54.849, clip=98.701, loss_scale=3.355e+07, optim_step_time=0.005, optim0_lr0=4.354e-04, train_time=0.163
[lambda-Lambda-Vector] 2025-04-01 18:42:33,528 (trainer:779) INFO: 13epoch:train:1233-1309batch: iter_time=4.857e-05, forward_time=0.053, loss_ctc=109.313, loss=109.313, backward_time=0.057, grad_norm=58.770, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.005, optim0_lr0=4.345e-04, train_time=0.154
[lambda-Lambda-Vector] 2025-04-01 18:42:45,823 (trainer:779) INFO: 13epoch:train:1310-1386batch: iter_time=5.019e-05, forward_time=0.054, loss_ctc=118.814, loss=118.814, backward_time=0.059, grad_norm=68.969, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.005, optim0_lr0=4.337e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 18:42:58,000 (trainer:779) INFO: 13epoch:train:1387-1463batch: iter_time=4.940e-05, forward_time=0.054, loss_ctc=93.735, loss=93.735, backward_time=0.058, grad_norm=66.078, clip=100.000, loss_scale=5.578e+07, optim_step_time=0.005, optim0_lr0=4.329e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 18:43:09,907 (trainer:779) INFO: 13epoch:train:1464-1540batch: iter_time=5.005e-05, forward_time=0.053, loss_ctc=97.033, loss=97.033, backward_time=0.057, grad_norm=71.702, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.005, optim0_lr0=4.320e-04, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 18:43:57,341 (trainer:365) INFO: 13epoch results: [train] iter_time=8.675e-05, forward_time=0.056, loss_ctc=104.122, loss=104.122, backward_time=0.060, grad_norm=66.362, clip=99.871, loss_scale=3.652e+07, optim_step_time=0.005, optim0_lr0=4.402e-04, train_time=0.164, time=4 minutes and 14.74 seconds, total_count=20137, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=120.004, cer_ctc=0.938, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=120.004, time=45.61 seconds, total_count=4147, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 18:43:59,744 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 18:43:59,760 (trainer:487) INFO: The model files were removed: exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/2epoch.pth
[lambda-Lambda-Vector] 2025-04-01 18:43:59,760 (trainer:299) INFO: 14/70epoch started. Estimated time to finish: 5 hours, 17 minutes and 59.05 seconds
[lambda-Lambda-Vector] 2025-04-01 18:44:13,051 (trainer:779) INFO: 14epoch:train:1-77batch: iter_time=7.199e-04, forward_time=0.056, loss_ctc=108.699, loss=108.699, backward_time=0.060, grad_norm=109.050, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.005, optim0_lr0=4.311e-04, train_time=0.172
[lambda-Lambda-Vector] 2025-04-01 18:44:24,826 (trainer:779) INFO: 14epoch:train:78-154batch: iter_time=5.470e-05, forward_time=0.052, loss_ctc=92.742, loss=92.742, backward_time=0.056, grad_norm=101.248, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.005, optim0_lr0=4.303e-04, train_time=0.153
[lambda-Lambda-Vector] 2025-04-01 18:44:36,611 (trainer:779) INFO: 14epoch:train:155-231batch: iter_time=5.400e-05, forward_time=0.052, loss_ctc=95.214, loss=95.214, backward_time=0.056, grad_norm=87.720, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.005, optim0_lr0=4.295e-04, train_time=0.153
[lambda-Lambda-Vector] 2025-04-01 18:44:48,532 (trainer:779) INFO: 14epoch:train:232-308batch: iter_time=5.138e-05, forward_time=0.053, loss_ctc=92.887, loss=92.887, backward_time=0.057, grad_norm=83.639, clip=98.701, loss_scale=6.711e+07, optim_step_time=0.005, optim0_lr0=4.287e-04, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 18:45:00,523 (trainer:779) INFO: 14epoch:train:309-385batch: iter_time=5.324e-05, forward_time=0.053, loss_ctc=102.500, loss=102.500, backward_time=0.057, grad_norm=96.175, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.005, optim0_lr0=4.279e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 18:45:12,778 (trainer:779) INFO: 14epoch:train:386-462batch: iter_time=5.287e-05, forward_time=0.054, loss_ctc=104.069, loss=104.069, backward_time=0.059, grad_norm=129.798, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.005, optim0_lr0=4.271e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 18:45:24,995 (trainer:779) INFO: 14epoch:train:463-539batch: iter_time=5.201e-05, forward_time=0.054, loss_ctc=120.996, loss=120.996, backward_time=0.059, grad_norm=94.621, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.005, optim0_lr0=4.263e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 18:45:37,517 (trainer:779) INFO: 14epoch:train:540-616batch: iter_time=5.029e-05, forward_time=0.055, loss_ctc=115.626, loss=115.626, backward_time=0.060, grad_norm=469.339, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.005, optim0_lr0=4.255e-04, train_time=0.163
[lambda-Lambda-Vector] 2025-04-01 18:45:49,312 (trainer:779) INFO: 14epoch:train:617-693batch: iter_time=5.124e-05, forward_time=0.052, loss_ctc=87.757, loss=87.757, backward_time=0.056, grad_norm=282.628, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.005, optim0_lr0=4.247e-04, train_time=0.153
[lambda-Lambda-Vector] 2025-04-01 18:46:01,611 (trainer:779) INFO: 14epoch:train:694-770batch: iter_time=5.059e-05, forward_time=0.054, loss_ctc=108.775, loss=108.775, backward_time=0.059, grad_norm=193.844, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.005, optim0_lr0=4.239e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 18:46:13,895 (trainer:779) INFO: 14epoch:train:771-847batch: iter_time=5.118e-05, forward_time=0.054, loss_ctc=103.375, loss=103.375, backward_time=0.059, grad_norm=1.422e+03, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.005, optim0_lr0=4.231e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 18:46:26,605 (trainer:779) INFO: 14epoch:train:848-924batch: iter_time=5.049e-05, forward_time=0.056, loss_ctc=123.990, loss=123.990, backward_time=0.061, grad_norm=82.550, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.005, optim0_lr0=4.223e-04, train_time=0.165
[lambda-Lambda-Vector] 2025-04-01 18:46:38,836 (trainer:779) INFO: 14epoch:train:925-1001batch: iter_time=5.514e-05, forward_time=0.055, loss_ctc=94.980, loss=94.980, backward_time=0.058, grad_norm=79.629, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.005, optim0_lr0=4.216e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 18:46:51,322 (trainer:779) INFO: 14epoch:train:1002-1078batch: iter_time=5.754e-05, forward_time=0.056, loss_ctc=107.901, loss=107.901, backward_time=0.059, grad_norm=72.341, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.005, optim0_lr0=4.208e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 18:47:04,556 (trainer:779) INFO: 14epoch:train:1079-1155batch: iter_time=5.228e-05, forward_time=0.054, loss_ctc=118.585, loss=118.585, backward_time=0.059, grad_norm=75.229, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.005, optim0_lr0=4.200e-04, train_time=0.172
[lambda-Lambda-Vector] 2025-04-01 18:47:16,691 (trainer:779) INFO: 14epoch:train:1156-1232batch: iter_time=5.158e-05, forward_time=0.054, loss_ctc=95.716, loss=95.716, backward_time=0.058, grad_norm=61.047, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.005, optim0_lr0=4.193e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 18:47:28,978 (trainer:779) INFO: 14epoch:train:1233-1309batch: iter_time=5.123e-05, forward_time=0.054, loss_ctc=121.202, loss=121.202, backward_time=0.059, grad_norm=61.809, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.005, optim0_lr0=4.185e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 18:47:41,222 (trainer:779) INFO: 14epoch:train:1310-1386batch: iter_time=5.166e-05, forward_time=0.054, loss_ctc=102.823, loss=102.823, backward_time=0.059, grad_norm=65.289, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.005, optim0_lr0=4.178e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 18:47:53,642 (trainer:779) INFO: 14epoch:train:1387-1463batch: iter_time=5.150e-05, forward_time=0.055, loss_ctc=103.177, loss=103.177, backward_time=0.059, grad_norm=85.094, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.005, optim0_lr0=4.170e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 18:48:06,054 (trainer:779) INFO: 14epoch:train:1464-1540batch: iter_time=5.129e-05, forward_time=0.055, loss_ctc=101.247, loss=101.247, backward_time=0.059, grad_norm=90.765, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.005, optim0_lr0=4.163e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 18:48:53,522 (trainer:365) INFO: 14epoch results: [train] iter_time=8.543e-05, forward_time=0.054, loss_ctc=104.047, loss=104.047, backward_time=0.058, grad_norm=186.464, clip=99.935, loss_scale=6.711e+07, optim_step_time=0.005, optim0_lr0=4.235e-04, train_time=0.160, time=4 minutes and 7.96 seconds, total_count=21686, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=117.797, cer_ctc=0.942, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=117.797, time=45.8 seconds, total_count=4466, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 18:48:55,108 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 18:48:55,124 (trainer:487) INFO: The model files were removed: exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/11epoch.pth
[lambda-Lambda-Vector] 2025-04-01 18:48:55,124 (trainer:299) INFO: 15/70epoch started. Estimated time to finish: 5 hours, 9 minutes and 46.9 seconds
[lambda-Lambda-Vector] 2025-04-01 18:49:08,298 (trainer:779) INFO: 15epoch:train:1-77batch: iter_time=8.698e-04, forward_time=0.055, loss_ctc=115.965, loss=115.965, backward_time=0.059, grad_norm=89.711, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.005, optim0_lr0=4.155e-04, train_time=0.171
[lambda-Lambda-Vector] 2025-04-01 18:49:20,054 (trainer:779) INFO: 15epoch:train:78-154batch: iter_time=5.395e-05, forward_time=0.052, loss_ctc=86.848, loss=86.848, backward_time=0.056, grad_norm=70.258, clip=98.701, loss_scale=6.711e+07, optim_step_time=0.005, optim0_lr0=4.147e-04, train_time=0.153
[lambda-Lambda-Vector] 2025-04-01 18:49:32,224 (trainer:779) INFO: 15epoch:train:155-231batch: iter_time=5.535e-05, forward_time=0.054, loss_ctc=101.298, loss=101.298, backward_time=0.058, grad_norm=67.629, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.005, optim0_lr0=4.140e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 18:49:45,634 (trainer:779) INFO: 15epoch:train:232-308batch: iter_time=5.363e-05, forward_time=0.055, loss_ctc=109.563, loss=109.563, backward_time=0.060, grad_norm=84.560, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.005, optim0_lr0=4.133e-04, train_time=0.174
[lambda-Lambda-Vector] 2025-04-01 18:49:57,568 (trainer:779) INFO: 15epoch:train:309-385batch: iter_time=5.216e-05, forward_time=0.053, loss_ctc=94.289, loss=94.289, backward_time=0.057, grad_norm=68.876, clip=100.000, loss_scale=1.290e+08, optim_step_time=0.005, optim0_lr0=4.125e-04, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 18:50:09,685 (trainer:779) INFO: 15epoch:train:386-462batch: iter_time=5.132e-05, forward_time=0.054, loss_ctc=103.095, loss=103.095, backward_time=0.058, grad_norm=70.306, clip=98.701, loss_scale=1.342e+08, optim_step_time=0.005, optim0_lr0=4.118e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 18:50:21,961 (trainer:779) INFO: 15epoch:train:463-539batch: iter_time=5.036e-05, forward_time=0.054, loss_ctc=114.967, loss=114.967, backward_time=0.059, grad_norm=72.779, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.005, optim0_lr0=4.111e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 18:50:34,187 (trainer:779) INFO: 15epoch:train:540-616batch: iter_time=5.111e-05, forward_time=0.054, loss_ctc=108.133, loss=108.133, backward_time=0.059, grad_norm=62.690, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.005, optim0_lr0=4.104e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 18:50:46,287 (trainer:779) INFO: 15epoch:train:617-693batch: iter_time=5.147e-05, forward_time=0.054, loss_ctc=101.844, loss=101.844, backward_time=0.058, grad_norm=59.002, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.005, optim0_lr0=4.097e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 18:50:58,323 (trainer:779) INFO: 15epoch:train:694-770batch: iter_time=5.095e-05, forward_time=0.054, loss_ctc=79.626, loss=79.626, backward_time=0.057, grad_norm=64.239, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.005, optim0_lr0=4.090e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 18:51:10,759 (trainer:779) INFO: 15epoch:train:771-847batch: iter_time=4.862e-05, forward_time=0.055, loss_ctc=107.210, loss=107.210, backward_time=0.060, grad_norm=77.124, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.005, optim0_lr0=4.083e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 18:51:23,034 (trainer:779) INFO: 15epoch:train:848-924batch: iter_time=5.277e-05, forward_time=0.054, loss_ctc=111.080, loss=111.080, backward_time=0.059, grad_norm=61.708, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.005, optim0_lr0=4.076e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 18:51:35,182 (trainer:779) INFO: 15epoch:train:925-1001batch: iter_time=4.903e-05, forward_time=0.054, loss_ctc=102.765, loss=102.765, backward_time=0.058, grad_norm=54.011, clip=98.701, loss_scale=1.342e+08, optim_step_time=0.005, optim0_lr0=4.069e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 18:51:47,285 (trainer:779) INFO: 15epoch:train:1002-1078batch: iter_time=4.977e-05, forward_time=0.053, loss_ctc=106.870, loss=106.870, backward_time=0.058, grad_norm=64.422, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.005, optim0_lr0=4.062e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 18:51:59,252 (trainer:779) INFO: 15epoch:train:1079-1155batch: iter_time=4.881e-05, forward_time=0.053, loss_ctc=99.220, loss=99.220, backward_time=0.057, grad_norm=59.335, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.005, optim0_lr0=4.055e-04, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 18:52:11,576 (trainer:779) INFO: 15epoch:train:1156-1232batch: iter_time=4.877e-05, forward_time=0.054, loss_ctc=112.038, loss=112.038, backward_time=0.059, grad_norm=65.429, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.005, optim0_lr0=4.048e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 18:52:23,930 (trainer:779) INFO: 15epoch:train:1233-1309batch: iter_time=4.939e-05, forward_time=0.055, loss_ctc=102.941, loss=102.941, backward_time=0.059, grad_norm=64.641, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.005, optim0_lr0=4.042e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 18:52:35,926 (trainer:779) INFO: 15epoch:train:1310-1386batch: iter_time=4.972e-05, forward_time=0.053, loss_ctc=110.577, loss=110.577, backward_time=0.058, grad_norm=62.562, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.005, optim0_lr0=4.035e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 18:52:48,367 (trainer:779) INFO: 15epoch:train:1387-1463batch: iter_time=4.991e-05, forward_time=0.055, loss_ctc=129.276, loss=129.276, backward_time=0.060, grad_norm=73.228, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.005, optim0_lr0=4.028e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 18:53:00,726 (trainer:779) INFO: 15epoch:train:1464-1540batch: iter_time=4.984e-05, forward_time=0.054, loss_ctc=103.327, loss=103.327, backward_time=0.059, grad_norm=85.166, clip=98.701, loss_scale=1.342e+08, optim_step_time=0.005, optim0_lr0=4.021e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 18:53:49,021 (trainer:365) INFO: 15epoch results: [train] iter_time=9.153e-05, forward_time=0.054, loss_ctc=103.998, loss=103.998, backward_time=0.058, grad_norm=69.119, clip=99.742, loss_scale=1.206e+08, optim_step_time=0.005, optim0_lr0=4.087e-04, train_time=0.159, time=4 minutes and 7.38 seconds, total_count=23235, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=117.218, cer_ctc=0.939, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=117.218, time=46.51 seconds, total_count=4785, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 18:53:50,614 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 18:53:50,630 (trainer:487) INFO: The model files were removed: exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/10epoch.pth
[lambda-Lambda-Vector] 2025-04-01 18:53:50,630 (trainer:299) INFO: 16/70epoch started. Estimated time to finish: 5 hours, 2 minutes and 1.52 seconds
[lambda-Lambda-Vector] 2025-04-01 18:54:03,754 (trainer:779) INFO: 16epoch:train:1-77batch: iter_time=6.406e-04, forward_time=0.055, loss_ctc=110.126, loss=110.126, backward_time=0.059, grad_norm=86.782, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.005, optim0_lr0=4.014e-04, train_time=0.170
[lambda-Lambda-Vector] 2025-04-01 18:54:16,074 (trainer:779) INFO: 16epoch:train:78-154batch: iter_time=5.324e-05, forward_time=0.054, loss_ctc=107.091, loss=107.091, backward_time=0.059, grad_norm=69.547, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.005, optim0_lr0=4.007e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 18:54:28,063 (trainer:779) INFO: 16epoch:train:155-231batch: iter_time=5.298e-05, forward_time=0.053, loss_ctc=93.942, loss=93.942, backward_time=0.057, grad_norm=71.262, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.005, optim0_lr0=4.001e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 18:54:40,068 (trainer:779) INFO: 16epoch:train:232-308batch: iter_time=5.632e-05, forward_time=0.053, loss_ctc=108.682, loss=108.682, backward_time=0.057, grad_norm=78.670, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.005, optim0_lr0=3.994e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 18:54:51,984 (trainer:779) INFO: 16epoch:train:309-385batch: iter_time=5.156e-05, forward_time=0.053, loss_ctc=85.139, loss=85.139, backward_time=0.057, grad_norm=81.129, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.005, optim0_lr0=3.988e-04, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 18:55:04,416 (trainer:779) INFO: 16epoch:train:386-462batch: iter_time=5.166e-05, forward_time=0.055, loss_ctc=114.529, loss=114.529, backward_time=0.060, grad_norm=80.634, clip=98.701, loss_scale=1.342e+08, optim_step_time=0.005, optim0_lr0=3.981e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 18:55:16,720 (trainer:779) INFO: 16epoch:train:463-539batch: iter_time=5.879e-05, forward_time=0.055, loss_ctc=97.595, loss=97.595, backward_time=0.059, grad_norm=70.752, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.005, optim0_lr0=3.975e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 18:55:28,748 (trainer:779) INFO: 16epoch:train:540-616batch: iter_time=5.243e-05, forward_time=0.053, loss_ctc=106.123, loss=106.123, backward_time=0.058, grad_norm=78.429, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.005, optim0_lr0=3.968e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 18:55:41,238 (trainer:779) INFO: 16epoch:train:617-693batch: iter_time=5.660e-05, forward_time=0.055, loss_ctc=115.894, loss=115.894, backward_time=0.060, grad_norm=88.462, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.005, optim0_lr0=3.962e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 18:55:53,353 (trainer:779) INFO: 16epoch:train:694-770batch: iter_time=5.053e-05, forward_time=0.054, loss_ctc=106.221, loss=106.221, backward_time=0.058, grad_norm=75.176, clip=100.000, loss_scale=1.429e+08, optim_step_time=0.005, optim0_lr0=3.955e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 18:56:05,825 (trainer:779) INFO: 16epoch:train:771-847batch: iter_time=4.924e-05, forward_time=0.055, loss_ctc=116.653, loss=116.653, backward_time=0.060, grad_norm=91.247, clip=98.701, loss_scale=2.684e+08, optim_step_time=0.005, optim0_lr0=3.949e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 18:56:18,079 (trainer:779) INFO: 16epoch:train:848-924batch: iter_time=5.001e-05, forward_time=0.054, loss_ctc=105.076, loss=105.076, backward_time=0.059, grad_norm=81.358, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.005, optim0_lr0=3.943e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 18:56:30,098 (trainer:779) INFO: 16epoch:train:925-1001batch: iter_time=5.049e-05, forward_time=0.053, loss_ctc=106.728, loss=106.728, backward_time=0.057, grad_norm=94.955, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.005, optim0_lr0=3.937e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 18:56:43,254 (trainer:779) INFO: 16epoch:train:1002-1078batch: iter_time=4.816e-05, forward_time=0.054, loss_ctc=111.943, loss=111.943, backward_time=0.058, grad_norm=87.673, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.005, optim0_lr0=3.930e-04, train_time=0.171
[lambda-Lambda-Vector] 2025-04-01 18:56:55,543 (trainer:779) INFO: 16epoch:train:1079-1155batch: iter_time=4.795e-05, forward_time=0.054, loss_ctc=106.776, loss=106.776, backward_time=0.059, grad_norm=83.567, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.005, optim0_lr0=3.924e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 18:57:07,669 (trainer:779) INFO: 16epoch:train:1156-1232batch: iter_time=4.886e-05, forward_time=0.054, loss_ctc=114.288, loss=114.288, backward_time=0.058, grad_norm=77.037, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.005, optim0_lr0=3.918e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 18:57:19,851 (trainer:779) INFO: 16epoch:train:1233-1309batch: iter_time=4.899e-05, forward_time=0.054, loss_ctc=100.100, loss=100.100, backward_time=0.058, grad_norm=90.819, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.005, optim0_lr0=3.912e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 18:57:32,071 (trainer:779) INFO: 16epoch:train:1310-1386batch: iter_time=4.946e-05, forward_time=0.054, loss_ctc=90.597, loss=90.597, backward_time=0.058, grad_norm=77.461, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.005, optim0_lr0=3.906e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 18:57:44,347 (trainer:779) INFO: 16epoch:train:1387-1463batch: iter_time=4.829e-05, forward_time=0.054, loss_ctc=105.986, loss=105.986, backward_time=0.059, grad_norm=77.660, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.005, optim0_lr0=3.900e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 18:57:56,492 (trainer:779) INFO: 16epoch:train:1464-1540batch: iter_time=4.980e-05, forward_time=0.054, loss_ctc=86.914, loss=86.914, backward_time=0.058, grad_norm=59.704, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.005, optim0_lr0=3.893e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 18:58:43,814 (trainer:365) INFO: 16epoch results: [train] iter_time=8.054e-05, forward_time=0.054, loss_ctc=103.780, loss=103.780, backward_time=0.058, grad_norm=80.185, clip=99.871, loss_scale=2.021e+08, optim_step_time=0.005, optim0_lr0=3.952e-04, train_time=0.160, time=4 minutes and 7.64 seconds, total_count=24784, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=123.583, cer_ctc=0.935, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=123.583, time=45.54 seconds, total_count=5104, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 18:58:45,437 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 18:58:45,453 (trainer:487) INFO: The model files were removed: exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/14epoch.pth
[lambda-Lambda-Vector] 2025-04-01 18:58:45,453 (trainer:299) INFO: 17/70epoch started. Estimated time to finish: 4 hours, 54 minutes and 35.06 seconds
[lambda-Lambda-Vector] 2025-04-01 18:58:58,521 (trainer:779) INFO: 17epoch:train:1-77batch: iter_time=8.022e-04, forward_time=0.055, loss_ctc=107.912, loss=107.912, backward_time=0.059, grad_norm=95.363, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.005, optim0_lr0=3.887e-04, train_time=0.170
[lambda-Lambda-Vector] 2025-04-01 18:59:11,950 (trainer:779) INFO: 17epoch:train:78-154batch: iter_time=5.301e-05, forward_time=0.055, loss_ctc=115.507, loss=115.507, backward_time=0.060, grad_norm=91.521, clip=98.701, loss_scale=2.684e+08, optim_step_time=0.005, optim0_lr0=3.881e-04, train_time=0.174
[lambda-Lambda-Vector] 2025-04-01 18:59:24,275 (trainer:779) INFO: 17epoch:train:155-231batch: iter_time=5.270e-05, forward_time=0.055, loss_ctc=102.289, loss=102.289, backward_time=0.059, grad_norm=74.822, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.005, optim0_lr0=3.875e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 18:59:36,304 (trainer:779) INFO: 17epoch:train:232-308batch: iter_time=5.246e-05, forward_time=0.053, loss_ctc=105.256, loss=105.256, backward_time=0.058, grad_norm=71.551, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.005, optim0_lr0=3.869e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 18:59:48,569 (trainer:779) INFO: 17epoch:train:309-385batch: iter_time=5.172e-05, forward_time=0.054, loss_ctc=107.888, loss=107.888, backward_time=0.059, grad_norm=85.042, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.005, optim0_lr0=3.863e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 19:00:01,086 (trainer:779) INFO: 17epoch:train:386-462batch: iter_time=5.145e-05, forward_time=0.055, loss_ctc=114.748, loss=114.748, backward_time=0.060, grad_norm=87.424, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.005, optim0_lr0=3.857e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 19:00:14,139 (trainer:779) INFO: 17epoch:train:463-539batch: iter_time=1.074e-04, forward_time=0.059, loss_ctc=100.946, loss=100.946, backward_time=0.061, grad_norm=77.077, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.005, optim0_lr0=3.851e-04, train_time=0.169
[lambda-Lambda-Vector] 2025-04-01 19:00:33,243 (trainer:779) INFO: 17epoch:train:540-616batch: iter_time=6.638e-05, forward_time=0.086, loss_ctc=96.491, loss=96.491, backward_time=0.089, grad_norm=62.731, clip=98.701, loss_scale=2.684e+08, optim_step_time=0.006, optim0_lr0=3.845e-04, train_time=0.248
[lambda-Lambda-Vector] 2025-04-01 19:00:53,363 (trainer:779) INFO: 17epoch:train:617-693batch: iter_time=6.730e-05, forward_time=0.089, loss_ctc=107.009, loss=107.009, backward_time=0.090, grad_norm=66.617, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.006, optim0_lr0=3.839e-04, train_time=0.261
[lambda-Lambda-Vector] 2025-04-01 19:01:12,278 (trainer:779) INFO: 17epoch:train:694-770batch: iter_time=6.527e-05, forward_time=0.082, loss_ctc=100.764, loss=100.764, backward_time=0.088, grad_norm=71.134, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.006, optim0_lr0=3.834e-04, train_time=0.246
[lambda-Lambda-Vector] 2025-04-01 19:01:24,692 (trainer:779) INFO: 17epoch:train:771-847batch: iter_time=5.139e-05, forward_time=0.055, loss_ctc=99.441, loss=99.441, backward_time=0.059, grad_norm=59.168, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.005, optim0_lr0=3.828e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 19:01:36,653 (trainer:779) INFO: 17epoch:train:848-924batch: iter_time=4.975e-05, forward_time=0.054, loss_ctc=84.258, loss=84.258, backward_time=0.057, grad_norm=48.919, clip=98.701, loss_scale=2.684e+08, optim_step_time=0.005, optim0_lr0=3.822e-04, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 19:01:49,098 (trainer:779) INFO: 17epoch:train:925-1001batch: iter_time=5.203e-05, forward_time=0.055, loss_ctc=106.166, loss=106.166, backward_time=0.060, grad_norm=61.310, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.005, optim0_lr0=3.816e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 19:02:01,354 (trainer:779) INFO: 17epoch:train:1002-1078batch: iter_time=4.872e-05, forward_time=0.054, loss_ctc=116.193, loss=116.193, backward_time=0.059, grad_norm=65.032, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.005, optim0_lr0=3.811e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 19:02:13,162 (trainer:779) INFO: 17epoch:train:1079-1155batch: iter_time=4.738e-05, forward_time=0.052, loss_ctc=95.852, loss=95.852, backward_time=0.057, grad_norm=60.667, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.005, optim0_lr0=3.805e-04, train_time=0.153
[lambda-Lambda-Vector] 2025-04-01 19:02:25,383 (trainer:779) INFO: 17epoch:train:1156-1232batch: iter_time=4.949e-05, forward_time=0.054, loss_ctc=114.659, loss=114.659, backward_time=0.059, grad_norm=51.127, clip=100.000, loss_scale=3.242e+08, optim_step_time=0.005, optim0_lr0=3.799e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 19:02:37,506 (trainer:779) INFO: 17epoch:train:1233-1309batch: iter_time=4.870e-05, forward_time=0.054, loss_ctc=103.314, loss=103.314, backward_time=0.058, grad_norm=45.781, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.005, optim0_lr0=3.794e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 19:02:49,951 (trainer:779) INFO: 17epoch:train:1310-1386batch: iter_time=5.228e-05, forward_time=0.055, loss_ctc=99.046, loss=99.046, backward_time=0.060, grad_norm=40.566, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.005, optim0_lr0=3.788e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 19:03:02,074 (trainer:779) INFO: 17epoch:train:1387-1463batch: iter_time=5.278e-05, forward_time=0.054, loss_ctc=101.008, loss=101.008, backward_time=0.058, grad_norm=59.911, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.005, optim0_lr0=3.783e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 19:03:14,265 (trainer:779) INFO: 17epoch:train:1464-1540batch: iter_time=4.806e-05, forward_time=0.054, loss_ctc=110.730, loss=110.730, backward_time=0.059, grad_norm=70.881, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.005, optim0_lr0=3.777e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 19:04:02,680 (trainer:365) INFO: 17epoch results: [train] iter_time=9.320e-05, forward_time=0.059, loss_ctc=103.849, loss=103.849, backward_time=0.063, grad_norm=67.442, clip=99.806, loss_scale=3.261e+08, optim_step_time=0.005, optim0_lr0=3.831e-04, train_time=0.174, time=4 minutes and 30.54 seconds, total_count=26333, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=123.870, cer_ctc=0.934, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=123.870, time=46.68 seconds, total_count=5423, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 19:04:04,318 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 19:04:04,334 (trainer:487) INFO: The model files were removed: exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/12epoch.pth
[lambda-Lambda-Vector] 2025-04-01 19:04:04,334 (trainer:299) INFO: 18/70epoch started. Estimated time to finish: 4 hours, 48 minutes and 41.45 seconds
[lambda-Lambda-Vector] 2025-04-01 19:04:17,495 (trainer:779) INFO: 18epoch:train:1-77batch: iter_time=8.907e-04, forward_time=0.055, loss_ctc=95.619, loss=95.619, backward_time=0.059, grad_norm=87.025, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.005, optim0_lr0=3.771e-04, train_time=0.171
[lambda-Lambda-Vector] 2025-04-01 19:04:29,128 (trainer:779) INFO: 18epoch:train:78-154batch: iter_time=5.039e-05, forward_time=0.052, loss_ctc=81.795, loss=81.795, backward_time=0.055, grad_norm=85.180, clip=98.701, loss_scale=5.369e+08, optim_step_time=0.004, optim0_lr0=3.765e-04, train_time=0.151
[lambda-Lambda-Vector] 2025-04-01 19:04:41,620 (trainer:779) INFO: 18epoch:train:155-231batch: iter_time=5.717e-05, forward_time=0.055, loss_ctc=116.605, loss=116.605, backward_time=0.060, grad_norm=117.206, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.005, optim0_lr0=3.760e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 19:04:53,730 (trainer:779) INFO: 18epoch:train:232-308batch: iter_time=5.363e-05, forward_time=0.054, loss_ctc=114.804, loss=114.804, backward_time=0.058, grad_norm=92.668, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.005, optim0_lr0=3.754e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 19:05:05,958 (trainer:779) INFO: 18epoch:train:309-385batch: iter_time=6.497e-05, forward_time=0.054, loss_ctc=104.187, loss=104.187, backward_time=0.058, grad_norm=90.168, clip=98.701, loss_scale=5.369e+08, optim_step_time=0.005, optim0_lr0=3.749e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 19:05:18,500 (trainer:779) INFO: 18epoch:train:386-462batch: iter_time=6.273e-05, forward_time=0.056, loss_ctc=111.815, loss=111.815, backward_time=0.060, grad_norm=90.792, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.005, optim0_lr0=3.744e-04, train_time=0.163
[lambda-Lambda-Vector] 2025-04-01 19:05:31,392 (trainer:779) INFO: 18epoch:train:463-539batch: iter_time=6.333e-05, forward_time=0.057, loss_ctc=118.500, loss=118.500, backward_time=0.061, grad_norm=105.429, clip=98.701, loss_scale=5.369e+08, optim_step_time=0.005, optim0_lr0=3.738e-04, train_time=0.167
[lambda-Lambda-Vector] 2025-04-01 19:05:44,076 (trainer:779) INFO: 18epoch:train:540-616batch: iter_time=6.392e-05, forward_time=0.058, loss_ctc=94.220, loss=94.220, backward_time=0.059, grad_norm=73.759, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.006, optim0_lr0=3.733e-04, train_time=0.165
[lambda-Lambda-Vector] 2025-04-01 19:06:03,386 (trainer:779) INFO: 18epoch:train:617-693batch: iter_time=6.484e-05, forward_time=0.088, loss_ctc=104.779, loss=104.779, backward_time=0.091, grad_norm=54.920, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.006, optim0_lr0=3.728e-04, train_time=0.251
[lambda-Lambda-Vector] 2025-04-01 19:06:23,134 (trainer:779) INFO: 18epoch:train:694-770batch: iter_time=6.523e-05, forward_time=0.095, loss_ctc=113.810, loss=113.810, backward_time=0.085, grad_norm=55.854, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.006, optim0_lr0=3.722e-04, train_time=0.256
[lambda-Lambda-Vector] 2025-04-01 19:06:40,494 (trainer:779) INFO: 18epoch:train:771-847batch: iter_time=6.228e-05, forward_time=0.073, loss_ctc=117.437, loss=117.437, backward_time=0.077, grad_norm=60.699, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.006, optim0_lr0=3.717e-04, train_time=0.225
[lambda-Lambda-Vector] 2025-04-01 19:06:52,644 (trainer:779) INFO: 18epoch:train:848-924batch: iter_time=5.342e-05, forward_time=0.054, loss_ctc=95.149, loss=95.149, backward_time=0.058, grad_norm=51.653, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.005, optim0_lr0=3.712e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 19:07:04,809 (trainer:779) INFO: 18epoch:train:925-1001batch: iter_time=5.561e-05, forward_time=0.054, loss_ctc=100.539, loss=100.539, backward_time=0.058, grad_norm=66.747, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.005, optim0_lr0=3.706e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 19:07:17,270 (trainer:779) INFO: 18epoch:train:1002-1078batch: iter_time=6.455e-05, forward_time=0.055, loss_ctc=113.637, loss=113.637, backward_time=0.059, grad_norm=112.302, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.005, optim0_lr0=3.701e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 19:07:29,700 (trainer:779) INFO: 18epoch:train:1079-1155batch: iter_time=6.209e-05, forward_time=0.055, loss_ctc=112.963, loss=112.963, backward_time=0.059, grad_norm=105.394, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.005, optim0_lr0=3.696e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 19:07:42,382 (trainer:779) INFO: 18epoch:train:1156-1232batch: iter_time=5.546e-05, forward_time=0.056, loss_ctc=102.462, loss=102.462, backward_time=0.061, grad_norm=48.801, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.005, optim0_lr0=3.691e-04, train_time=0.165
[lambda-Lambda-Vector] 2025-04-01 19:07:54,681 (trainer:779) INFO: 18epoch:train:1233-1309batch: iter_time=5.393e-05, forward_time=0.055, loss_ctc=100.638, loss=100.638, backward_time=0.059, grad_norm=46.216, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.005, optim0_lr0=3.686e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 19:08:06,829 (trainer:779) INFO: 18epoch:train:1310-1386batch: iter_time=5.574e-05, forward_time=0.054, loss_ctc=102.931, loss=102.931, backward_time=0.058, grad_norm=75.057, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.005, optim0_lr0=3.681e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 19:08:19,178 (trainer:779) INFO: 18epoch:train:1387-1463batch: iter_time=5.473e-05, forward_time=0.055, loss_ctc=92.919, loss=92.919, backward_time=0.059, grad_norm=91.523, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.005, optim0_lr0=3.675e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 19:08:31,087 (trainer:779) INFO: 18epoch:train:1464-1540batch: iter_time=5.187e-05, forward_time=0.053, loss_ctc=99.023, loss=99.023, backward_time=0.057, grad_norm=63.699, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.005, optim0_lr0=3.670e-04, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 19:09:18,443 (trainer:365) INFO: 18epoch results: [train] iter_time=1.000e-04, forward_time=0.059, loss_ctc=103.792, loss=103.792, backward_time=0.063, grad_norm=78.656, clip=99.806, loss_scale=5.369e+08, optim_step_time=0.005, optim0_lr0=3.720e-04, train_time=0.173, time=4 minutes and 28.51 seconds, total_count=27882, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=124.323, cer_ctc=0.942, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=124.323, time=45.6 seconds, total_count=5742, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 19:09:21,080 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 19:09:21,080 (trainer:299) INFO: 19/70epoch started. Estimated time to finish: 4 hours, 42 minutes and 45.53 seconds
[lambda-Lambda-Vector] 2025-04-01 19:09:34,133 (trainer:779) INFO: 19epoch:train:1-77batch: iter_time=6.907e-04, forward_time=0.054, loss_ctc=100.541, loss=100.541, backward_time=0.058, grad_norm=69.670, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.005, optim0_lr0=3.665e-04, train_time=0.169
[lambda-Lambda-Vector] 2025-04-01 19:09:45,869 (trainer:779) INFO: 19epoch:train:78-154batch: iter_time=5.354e-05, forward_time=0.052, loss_ctc=82.265, loss=82.265, backward_time=0.056, grad_norm=86.701, clip=98.701, loss_scale=7.879e+08, optim_step_time=0.005, optim0_lr0=3.660e-04, train_time=0.152
[lambda-Lambda-Vector] 2025-04-01 19:09:58,231 (trainer:779) INFO: 19epoch:train:155-231batch: iter_time=5.281e-05, forward_time=0.055, loss_ctc=102.715, loss=102.715, backward_time=0.059, grad_norm=62.595, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.005, optim0_lr0=3.655e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 19:10:10,569 (trainer:779) INFO: 19epoch:train:232-308batch: iter_time=5.246e-05, forward_time=0.055, loss_ctc=100.231, loss=100.231, backward_time=0.059, grad_norm=75.971, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.005, optim0_lr0=3.650e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 19:10:22,364 (trainer:779) INFO: 19epoch:train:309-385batch: iter_time=5.383e-05, forward_time=0.052, loss_ctc=99.086, loss=99.086, backward_time=0.056, grad_norm=83.641, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.005, optim0_lr0=3.645e-04, train_time=0.153
[lambda-Lambda-Vector] 2025-04-01 19:10:34,359 (trainer:779) INFO: 19epoch:train:386-462batch: iter_time=6.466e-05, forward_time=0.054, loss_ctc=90.872, loss=90.872, backward_time=0.056, grad_norm=68.989, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.005, optim0_lr0=3.640e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 19:10:46,720 (trainer:779) INFO: 19epoch:train:463-539batch: iter_time=5.398e-05, forward_time=0.055, loss_ctc=106.142, loss=106.142, backward_time=0.059, grad_norm=88.421, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.005, optim0_lr0=3.635e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 19:10:58,699 (trainer:779) INFO: 19epoch:train:540-616batch: iter_time=5.241e-05, forward_time=0.053, loss_ctc=102.051, loss=102.051, backward_time=0.057, grad_norm=162.427, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.005, optim0_lr0=3.630e-04, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 19:11:11,122 (trainer:779) INFO: 19epoch:train:617-693batch: iter_time=5.280e-05, forward_time=0.055, loss_ctc=122.192, loss=122.192, backward_time=0.060, grad_norm=189.115, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.005, optim0_lr0=3.625e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 19:11:23,533 (trainer:779) INFO: 19epoch:train:694-770batch: iter_time=5.155e-05, forward_time=0.055, loss_ctc=110.018, loss=110.018, backward_time=0.060, grad_norm=232.269, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.005, optim0_lr0=3.620e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 19:11:37,453 (trainer:779) INFO: 19epoch:train:771-847batch: iter_time=6.394e-05, forward_time=0.063, loss_ctc=98.286, loss=98.286, backward_time=0.066, grad_norm=165.518, clip=97.403, loss_scale=1.074e+09, optim_step_time=0.006, optim0_lr0=3.615e-04, train_time=0.181
[lambda-Lambda-Vector] 2025-04-01 19:11:56,324 (trainer:779) INFO: 19epoch:train:848-924batch: iter_time=6.553e-05, forward_time=0.086, loss_ctc=109.180, loss=109.180, backward_time=0.085, grad_norm=82.458, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.006, optim0_lr0=3.610e-04, train_time=0.245
[lambda-Lambda-Vector] 2025-04-01 19:12:15,783 (trainer:779) INFO: 19epoch:train:925-1001batch: iter_time=6.535e-05, forward_time=0.085, loss_ctc=118.723, loss=118.723, backward_time=0.093, grad_norm=126.676, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.006, optim0_lr0=3.606e-04, train_time=0.253
[lambda-Lambda-Vector] 2025-04-01 19:12:35,146 (trainer:779) INFO: 19epoch:train:1002-1078batch: iter_time=6.566e-05, forward_time=0.086, loss_ctc=111.971, loss=111.971, backward_time=0.094, grad_norm=133.011, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.006, optim0_lr0=3.601e-04, train_time=0.251
[lambda-Lambda-Vector] 2025-04-01 19:12:53,799 (trainer:779) INFO: 19epoch:train:1079-1155batch: iter_time=6.672e-05, forward_time=0.081, loss_ctc=116.865, loss=116.865, backward_time=0.091, grad_norm=110.682, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.006, optim0_lr0=3.596e-04, train_time=0.242
[lambda-Lambda-Vector] 2025-04-01 19:13:13,003 (trainer:779) INFO: 19epoch:train:1156-1232batch: iter_time=6.333e-05, forward_time=0.085, loss_ctc=104.512, loss=104.512, backward_time=0.083, grad_norm=108.921, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.006, optim0_lr0=3.591e-04, train_time=0.249
[lambda-Lambda-Vector] 2025-04-01 19:13:31,147 (trainer:779) INFO: 19epoch:train:1233-1309batch: iter_time=6.410e-05, forward_time=0.081, loss_ctc=112.627, loss=112.627, backward_time=0.082, grad_norm=116.665, clip=98.701, loss_scale=1.074e+09, optim_step_time=0.006, optim0_lr0=3.586e-04, train_time=0.236
[lambda-Lambda-Vector] 2025-04-01 19:13:49,360 (trainer:779) INFO: 19epoch:train:1310-1386batch: iter_time=6.869e-05, forward_time=0.081, loss_ctc=85.332, loss=85.332, backward_time=0.087, grad_norm=97.479, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.006, optim0_lr0=3.582e-04, train_time=0.236
[lambda-Lambda-Vector] 2025-04-01 19:14:02,288 (trainer:779) INFO: 19epoch:train:1387-1463batch: iter_time=5.705e-05, forward_time=0.057, loss_ctc=114.893, loss=114.893, backward_time=0.062, grad_norm=97.641, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.005, optim0_lr0=3.577e-04, train_time=0.168
[lambda-Lambda-Vector] 2025-04-01 19:14:15,572 (trainer:779) INFO: 19epoch:train:1464-1540batch: iter_time=5.214e-05, forward_time=0.055, loss_ctc=109.054, loss=109.054, backward_time=0.059, grad_norm=146.172, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.005, optim0_lr0=3.572e-04, train_time=0.172
[lambda-Lambda-Vector] 2025-04-01 19:15:02,926 (trainer:365) INFO: 19epoch results: [train] iter_time=9.027e-05, forward_time=0.065, loss_ctc=103.617, loss=103.617, backward_time=0.069, grad_norm=115.120, clip=99.742, loss_scale=1.033e+09, optim_step_time=0.005, optim0_lr0=3.618e-04, train_time=0.191, time=4 minutes and 56.18 seconds, total_count=29431, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=115.276, cer_ctc=0.930, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=115.276, time=45.67 seconds, total_count=6061, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 19:15:04,567 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 19:15:04,601 (trainer:487) INFO: The model files were removed: exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/9epoch.pth, exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/18epoch.pth
[lambda-Lambda-Vector] 2025-04-01 19:15:04,601 (trainer:299) INFO: 20/70epoch started. Estimated time to finish: 4 hours, 38 minutes and 5.6 seconds
[lambda-Lambda-Vector] 2025-04-01 19:15:17,328 (trainer:779) INFO: 20epoch:train:1-77batch: iter_time=7.282e-04, forward_time=0.053, loss_ctc=90.159, loss=90.159, backward_time=0.057, grad_norm=112.638, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.005, optim0_lr0=3.567e-04, train_time=0.165
[lambda-Lambda-Vector] 2025-04-01 19:15:29,790 (trainer:779) INFO: 20epoch:train:78-154batch: iter_time=5.759e-05, forward_time=0.055, loss_ctc=98.510, loss=98.510, backward_time=0.060, grad_norm=123.391, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.005, optim0_lr0=3.562e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 19:15:45,633 (trainer:779) INFO: 20epoch:train:155-231batch: iter_time=6.422e-05, forward_time=0.070, loss_ctc=105.646, loss=105.646, backward_time=0.077, grad_norm=195.445, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.006, optim0_lr0=3.558e-04, train_time=0.206
[lambda-Lambda-Vector] 2025-04-01 19:16:01,787 (trainer:779) INFO: 20epoch:train:232-308batch: iter_time=6.817e-05, forward_time=0.073, loss_ctc=97.816, loss=97.816, backward_time=0.077, grad_norm=108.225, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.006, optim0_lr0=3.553e-04, train_time=0.210
[lambda-Lambda-Vector] 2025-04-01 19:16:15,380 (trainer:779) INFO: 20epoch:train:309-385batch: iter_time=5.631e-05, forward_time=0.060, loss_ctc=115.524, loss=115.524, backward_time=0.065, grad_norm=121.363, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.005, optim0_lr0=3.549e-04, train_time=0.176
[lambda-Lambda-Vector] 2025-04-01 19:16:27,871 (trainer:779) INFO: 20epoch:train:386-462batch: iter_time=5.230e-05, forward_time=0.055, loss_ctc=112.232, loss=112.232, backward_time=0.060, grad_norm=140.556, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.005, optim0_lr0=3.544e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 19:16:40,185 (trainer:779) INFO: 20epoch:train:463-539batch: iter_time=5.350e-05, forward_time=0.055, loss_ctc=97.512, loss=97.512, backward_time=0.059, grad_norm=106.795, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.005, optim0_lr0=3.539e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 19:16:53,085 (trainer:779) INFO: 20epoch:train:540-616batch: iter_time=5.372e-05, forward_time=0.053, loss_ctc=101.792, loss=101.792, backward_time=0.057, grad_norm=80.403, clip=100.000, loss_scale=1.729e+09, optim_step_time=0.005, optim0_lr0=3.535e-04, train_time=0.167
[lambda-Lambda-Vector] 2025-04-01 19:17:05,479 (trainer:779) INFO: 20epoch:train:617-693batch: iter_time=5.681e-05, forward_time=0.055, loss_ctc=100.670, loss=100.670, backward_time=0.059, grad_norm=132.808, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.005, optim0_lr0=3.530e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 19:17:17,623 (trainer:779) INFO: 20epoch:train:694-770batch: iter_time=5.419e-05, forward_time=0.054, loss_ctc=118.645, loss=118.645, backward_time=0.058, grad_norm=115.322, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.005, optim0_lr0=3.526e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 19:17:29,856 (trainer:779) INFO: 20epoch:train:771-847batch: iter_time=5.501e-05, forward_time=0.054, loss_ctc=111.377, loss=111.377, backward_time=0.058, grad_norm=141.812, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.005, optim0_lr0=3.521e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 19:17:43,565 (trainer:779) INFO: 20epoch:train:848-924batch: iter_time=6.293e-05, forward_time=0.062, loss_ctc=101.840, loss=101.840, backward_time=0.064, grad_norm=135.865, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.006, optim0_lr0=3.517e-04, train_time=0.178
[lambda-Lambda-Vector] 2025-04-01 19:18:00,736 (trainer:779) INFO: 20epoch:train:925-1001batch: iter_time=6.708e-05, forward_time=0.078, loss_ctc=95.821, loss=95.821, backward_time=0.078, grad_norm=136.411, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.006, optim0_lr0=3.512e-04, train_time=0.223
[lambda-Lambda-Vector] 2025-04-01 19:18:17,719 (trainer:779) INFO: 20epoch:train:1002-1078batch: iter_time=6.598e-05, forward_time=0.077, loss_ctc=109.572, loss=109.572, backward_time=0.080, grad_norm=108.290, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.006, optim0_lr0=3.508e-04, train_time=0.220
[lambda-Lambda-Vector] 2025-04-01 19:18:33,966 (trainer:779) INFO: 20epoch:train:1079-1155batch: iter_time=6.662e-05, forward_time=0.075, loss_ctc=87.663, loss=87.663, backward_time=0.075, grad_norm=68.078, clip=97.403, loss_scale=2.147e+09, optim_step_time=0.006, optim0_lr0=3.504e-04, train_time=0.211
[lambda-Lambda-Vector] 2025-04-01 19:18:50,748 (trainer:779) INFO: 20epoch:train:1156-1232batch: iter_time=6.511e-05, forward_time=0.074, loss_ctc=103.248, loss=103.248, backward_time=0.080, grad_norm=67.085, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.006, optim0_lr0=3.499e-04, train_time=0.218
[lambda-Lambda-Vector] 2025-04-01 19:19:07,728 (trainer:779) INFO: 20epoch:train:1233-1309batch: iter_time=6.252e-05, forward_time=0.079, loss_ctc=106.666, loss=106.666, backward_time=0.074, grad_norm=68.296, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.006, optim0_lr0=3.495e-04, train_time=0.220
[lambda-Lambda-Vector] 2025-04-01 19:19:25,608 (trainer:779) INFO: 20epoch:train:1310-1386batch: iter_time=6.420e-05, forward_time=0.080, loss_ctc=122.148, loss=122.148, backward_time=0.087, grad_norm=80.616, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.006, optim0_lr0=3.490e-04, train_time=0.232
[lambda-Lambda-Vector] 2025-04-01 19:19:42,153 (trainer:779) INFO: 20epoch:train:1387-1463batch: iter_time=6.426e-05, forward_time=0.076, loss_ctc=107.020, loss=107.020, backward_time=0.074, grad_norm=90.247, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.006, optim0_lr0=3.486e-04, train_time=0.215
[lambda-Lambda-Vector] 2025-04-01 19:19:58,535 (trainer:779) INFO: 20epoch:train:1464-1540batch: iter_time=6.217e-05, forward_time=0.076, loss_ctc=108.681, loss=108.681, backward_time=0.075, grad_norm=78.678, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.006, optim0_lr0=3.482e-04, train_time=0.213
[lambda-Lambda-Vector] 2025-04-01 19:21:03,137 (trainer:365) INFO: 20epoch results: [train] iter_time=9.379e-05, forward_time=0.066, loss_ctc=103.803, loss=103.803, backward_time=0.069, grad_norm=110.281, clip=99.871, loss_scale=1.753e+09, optim_step_time=0.005, optim0_lr0=3.524e-04, train_time=0.191, time=4 minutes and 56.03 seconds, total_count=30980, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=114.313, cer_ctc=0.939, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=114.313, time=1 minute and 2.51 seconds, total_count=6380, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 19:21:05,834 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 19:21:05,853 (trainer:487) INFO: The model files were removed: exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/15epoch.pth
[lambda-Lambda-Vector] 2025-04-01 19:21:05,853 (trainer:299) INFO: 21/70epoch started. Estimated time to finish: 4 hours, 34 minutes and 3.64 seconds
[lambda-Lambda-Vector] 2025-04-01 19:21:21,353 (trainer:779) INFO: 21epoch:train:1-77batch: iter_time=6.628e-04, forward_time=0.065, loss_ctc=95.099, loss=95.099, backward_time=0.070, grad_norm=68.002, clip=98.701, loss_scale=2.147e+09, optim_step_time=0.005, optim0_lr0=3.477e-04, train_time=0.201
[lambda-Lambda-Vector] 2025-04-01 19:21:33,783 (trainer:779) INFO: 21epoch:train:78-154batch: iter_time=4.893e-05, forward_time=0.055, loss_ctc=127.419, loss=127.419, backward_time=0.060, grad_norm=69.302, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.005, optim0_lr0=3.473e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 19:21:46,036 (trainer:779) INFO: 21epoch:train:155-231batch: iter_time=4.943e-05, forward_time=0.054, loss_ctc=102.883, loss=102.883, backward_time=0.059, grad_norm=70.673, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.005, optim0_lr0=3.468e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 19:21:58,177 (trainer:779) INFO: 21epoch:train:232-308batch: iter_time=4.905e-05, forward_time=0.054, loss_ctc=107.319, loss=107.319, backward_time=0.058, grad_norm=76.597, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.005, optim0_lr0=3.464e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 19:22:10,421 (trainer:779) INFO: 21epoch:train:309-385batch: iter_time=4.847e-05, forward_time=0.054, loss_ctc=112.628, loss=112.628, backward_time=0.059, grad_norm=70.878, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.004, optim0_lr0=3.460e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 19:22:22,668 (trainer:779) INFO: 21epoch:train:386-462batch: iter_time=4.819e-05, forward_time=0.054, loss_ctc=103.012, loss=103.012, backward_time=0.059, grad_norm=65.389, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.005, optim0_lr0=3.456e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 19:22:34,603 (trainer:779) INFO: 21epoch:train:463-539batch: iter_time=4.848e-05, forward_time=0.053, loss_ctc=95.601, loss=95.601, backward_time=0.057, grad_norm=55.928, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.005, optim0_lr0=3.451e-04, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 19:22:47,154 (trainer:779) INFO: 21epoch:train:540-616batch: iter_time=4.812e-05, forward_time=0.055, loss_ctc=119.596, loss=119.596, backward_time=0.060, grad_norm=63.265, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.004, optim0_lr0=3.447e-04, train_time=0.163
[lambda-Lambda-Vector] 2025-04-01 19:22:58,993 (trainer:779) INFO: 21epoch:train:617-693batch: iter_time=4.897e-05, forward_time=0.052, loss_ctc=98.103, loss=98.103, backward_time=0.057, grad_norm=59.473, clip=98.701, loss_scale=2.147e+09, optim_step_time=0.004, optim0_lr0=3.443e-04, train_time=0.154
[lambda-Lambda-Vector] 2025-04-01 19:23:10,978 (trainer:779) INFO: 21epoch:train:694-770batch: iter_time=4.853e-05, forward_time=0.053, loss_ctc=97.124, loss=97.124, backward_time=0.057, grad_norm=60.262, clip=98.701, loss_scale=2.147e+09, optim_step_time=0.004, optim0_lr0=3.439e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 19:23:23,379 (trainer:779) INFO: 21epoch:train:771-847batch: iter_time=4.854e-05, forward_time=0.055, loss_ctc=105.903, loss=105.903, backward_time=0.059, grad_norm=78.379, clip=98.701, loss_scale=2.147e+09, optim_step_time=0.005, optim0_lr0=3.435e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 19:23:35,358 (trainer:779) INFO: 21epoch:train:848-924batch: iter_time=4.615e-05, forward_time=0.053, loss_ctc=92.259, loss=92.259, backward_time=0.057, grad_norm=68.484, clip=98.701, loss_scale=2.147e+09, optim_step_time=0.004, optim0_lr0=3.430e-04, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 19:23:47,814 (trainer:779) INFO: 21epoch:train:925-1001batch: iter_time=4.887e-05, forward_time=0.055, loss_ctc=107.223, loss=107.223, backward_time=0.060, grad_norm=67.194, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.005, optim0_lr0=3.426e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 19:24:00,321 (trainer:779) INFO: 21epoch:train:1002-1078batch: iter_time=5.658e-05, forward_time=0.055, loss_ctc=113.199, loss=113.199, backward_time=0.060, grad_norm=95.069, clip=100.000, loss_scale=3.765e+09, optim_step_time=0.005, optim0_lr0=3.422e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 19:24:12,595 (trainer:779) INFO: 21epoch:train:1079-1155batch: iter_time=6.169e-05, forward_time=0.055, loss_ctc=96.833, loss=96.833, backward_time=0.058, grad_norm=75.921, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.005, optim0_lr0=3.418e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 19:24:25,044 (trainer:779) INFO: 21epoch:train:1156-1232batch: iter_time=6.174e-05, forward_time=0.055, loss_ctc=115.772, loss=115.772, backward_time=0.059, grad_norm=76.372, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.005, optim0_lr0=3.414e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 19:24:37,347 (trainer:779) INFO: 21epoch:train:1233-1309batch: iter_time=6.326e-05, forward_time=0.055, loss_ctc=101.338, loss=101.338, backward_time=0.058, grad_norm=62.942, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.006, optim0_lr0=3.410e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 19:24:50,882 (trainer:779) INFO: 21epoch:train:1310-1386batch: iter_time=5.957e-05, forward_time=0.056, loss_ctc=109.965, loss=109.965, backward_time=0.060, grad_norm=73.394, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.005, optim0_lr0=3.406e-04, train_time=0.176
[lambda-Lambda-Vector] 2025-04-01 19:25:03,178 (trainer:779) INFO: 21epoch:train:1387-1463batch: iter_time=5.952e-05, forward_time=0.055, loss_ctc=96.780, loss=96.780, backward_time=0.058, grad_norm=70.745, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.005, optim0_lr0=3.402e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 19:25:15,386 (trainer:779) INFO: 21epoch:train:1464-1540batch: iter_time=6.170e-05, forward_time=0.054, loss_ctc=92.288, loss=92.288, backward_time=0.058, grad_norm=62.762, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.005, optim0_lr0=3.398e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 19:26:02,709 (trainer:365) INFO: 21epoch results: [train] iter_time=8.323e-05, forward_time=0.055, loss_ctc=103.725, loss=103.725, backward_time=0.059, grad_norm=69.460, clip=99.677, loss_scale=2.881e+09, optim_step_time=0.005, optim0_lr0=3.437e-04, train_time=0.162, time=4 minutes and 11.29 seconds, total_count=32529, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=116.375, cer_ctc=0.933, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=116.375, time=45.56 seconds, total_count=6699, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 19:26:04,314 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 19:26:04,330 (trainer:487) INFO: The model files were removed: exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/20epoch.pth
[lambda-Lambda-Vector] 2025-04-01 19:26:04,330 (trainer:299) INFO: 22/70epoch started. Estimated time to finish: 4 hours, 27 minutes and 23.84 seconds
[lambda-Lambda-Vector] 2025-04-01 19:26:17,600 (trainer:779) INFO: 22epoch:train:1-77batch: iter_time=0.001, forward_time=0.055, loss_ctc=119.580, loss=119.580, backward_time=0.060, grad_norm=75.355, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.005, optim0_lr0=3.393e-04, train_time=0.172
[lambda-Lambda-Vector] 2025-04-01 19:26:30,030 (trainer:779) INFO: 22epoch:train:78-154batch: iter_time=5.693e-05, forward_time=0.055, loss_ctc=103.553, loss=103.553, backward_time=0.060, grad_norm=70.040, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.005, optim0_lr0=3.389e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 19:26:42,190 (trainer:779) INFO: 22epoch:train:155-231batch: iter_time=5.683e-05, forward_time=0.054, loss_ctc=98.789, loss=98.789, backward_time=0.058, grad_norm=72.083, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.005, optim0_lr0=3.385e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 19:26:54,307 (trainer:779) INFO: 22epoch:train:232-308batch: iter_time=5.648e-05, forward_time=0.054, loss_ctc=97.928, loss=97.928, backward_time=0.058, grad_norm=74.986, clip=98.701, loss_scale=4.295e+09, optim_step_time=0.005, optim0_lr0=3.381e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 19:27:06,623 (trainer:779) INFO: 22epoch:train:309-385batch: iter_time=5.602e-05, forward_time=0.055, loss_ctc=105.874, loss=105.874, backward_time=0.059, grad_norm=67.159, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.005, optim0_lr0=3.377e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 19:27:18,766 (trainer:779) INFO: 22epoch:train:386-462batch: iter_time=5.546e-05, forward_time=0.054, loss_ctc=104.247, loss=104.247, backward_time=0.058, grad_norm=86.534, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.005, optim0_lr0=3.373e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 19:27:32,068 (trainer:779) INFO: 22epoch:train:463-539batch: iter_time=5.653e-05, forward_time=0.055, loss_ctc=105.493, loss=105.493, backward_time=0.060, grad_norm=82.995, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.005, optim0_lr0=3.369e-04, train_time=0.173
[lambda-Lambda-Vector] 2025-04-01 19:27:44,050 (trainer:779) INFO: 22epoch:train:540-616batch: iter_time=5.521e-05, forward_time=0.054, loss_ctc=83.991, loss=83.991, backward_time=0.057, grad_norm=73.352, clip=98.701, loss_scale=4.295e+09, optim_step_time=0.005, optim0_lr0=3.365e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 19:27:56,220 (trainer:779) INFO: 22epoch:train:617-693batch: iter_time=5.588e-05, forward_time=0.054, loss_ctc=100.752, loss=100.752, backward_time=0.058, grad_norm=70.126, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.005, optim0_lr0=3.362e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 19:28:08,460 (trainer:779) INFO: 22epoch:train:694-770batch: iter_time=5.630e-05, forward_time=0.055, loss_ctc=89.051, loss=89.051, backward_time=0.059, grad_norm=62.726, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.005, optim0_lr0=3.358e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 19:28:20,831 (trainer:779) INFO: 22epoch:train:771-847batch: iter_time=5.559e-05, forward_time=0.055, loss_ctc=111.505, loss=111.505, backward_time=0.060, grad_norm=80.378, clip=98.701, loss_scale=4.295e+09, optim_step_time=0.005, optim0_lr0=3.354e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 19:28:33,178 (trainer:779) INFO: 22epoch:train:848-924batch: iter_time=5.663e-05, forward_time=0.055, loss_ctc=117.154, loss=117.154, backward_time=0.060, grad_norm=86.503, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.005, optim0_lr0=3.350e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 19:28:45,785 (trainer:779) INFO: 22epoch:train:925-1001batch: iter_time=5.837e-05, forward_time=0.056, loss_ctc=108.233, loss=108.233, backward_time=0.061, grad_norm=66.607, clip=98.701, loss_scale=4.295e+09, optim_step_time=0.005, optim0_lr0=3.346e-04, train_time=0.164
[lambda-Lambda-Vector] 2025-04-01 19:28:58,109 (trainer:779) INFO: 22epoch:train:1002-1078batch: iter_time=5.619e-05, forward_time=0.055, loss_ctc=101.701, loss=101.701, backward_time=0.059, grad_norm=70.527, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.005, optim0_lr0=3.342e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 19:29:10,510 (trainer:779) INFO: 22epoch:train:1079-1155batch: iter_time=5.585e-05, forward_time=0.055, loss_ctc=105.154, loss=105.154, backward_time=0.060, grad_norm=62.250, clip=98.701, loss_scale=4.295e+09, optim_step_time=0.005, optim0_lr0=3.338e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 19:29:22,586 (trainer:779) INFO: 22epoch:train:1156-1232batch: iter_time=5.599e-05, forward_time=0.053, loss_ctc=101.116, loss=101.116, backward_time=0.058, grad_norm=57.482, clip=98.701, loss_scale=4.295e+09, optim_step_time=0.005, optim0_lr0=3.335e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 19:29:34,983 (trainer:779) INFO: 22epoch:train:1233-1309batch: iter_time=5.540e-05, forward_time=0.055, loss_ctc=113.438, loss=113.438, backward_time=0.060, grad_norm=75.984, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.005, optim0_lr0=3.331e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 19:29:47,288 (trainer:779) INFO: 22epoch:train:1310-1386batch: iter_time=5.610e-05, forward_time=0.055, loss_ctc=100.812, loss=100.812, backward_time=0.059, grad_norm=71.944, clip=98.701, loss_scale=4.295e+09, optim_step_time=0.005, optim0_lr0=3.327e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 19:29:59,790 (trainer:779) INFO: 22epoch:train:1387-1463batch: iter_time=5.614e-05, forward_time=0.056, loss_ctc=106.344, loss=106.344, backward_time=0.060, grad_norm=79.047, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.005, optim0_lr0=3.323e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 19:30:11,688 (trainer:779) INFO: 22epoch:train:1464-1540batch: iter_time=5.570e-05, forward_time=0.053, loss_ctc=105.807, loss=105.807, backward_time=0.057, grad_norm=69.943, clip=100.000, loss_scale=8.144e+09, optim_step_time=0.005, optim0_lr0=3.319e-04, train_time=0.154
[lambda-Lambda-Vector] 2025-04-01 19:30:59,055 (trainer:365) INFO: 22epoch results: [train] iter_time=1.032e-04, forward_time=0.055, loss_ctc=103.481, loss=103.481, backward_time=0.059, grad_norm=73.086, clip=99.548, loss_scale=4.511e+09, optim_step_time=0.005, optim0_lr0=3.356e-04, train_time=0.161, time=4 minutes and 9.14 seconds, total_count=34078, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=122.903, cer_ctc=0.934, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=122.903, time=45.59 seconds, total_count=7018, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 19:31:01,619 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 19:31:01,635 (trainer:487) INFO: The model files were removed: exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/13epoch.pth
[lambda-Lambda-Vector] 2025-04-01 19:31:01,635 (trainer:299) INFO: 23/70epoch started. Estimated time to finish: 4 hours, 20 minutes and 50.7 seconds
[lambda-Lambda-Vector] 2025-04-01 19:31:14,440 (trainer:779) INFO: 23epoch:train:1-77batch: iter_time=7.932e-04, forward_time=0.053, loss_ctc=100.903, loss=100.903, backward_time=0.058, grad_norm=65.773, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.005, optim0_lr0=3.315e-04, train_time=0.166
[lambda-Lambda-Vector] 2025-04-01 19:31:26,049 (trainer:779) INFO: 23epoch:train:78-154batch: iter_time=5.900e-05, forward_time=0.052, loss_ctc=83.972, loss=83.972, backward_time=0.056, grad_norm=53.631, clip=98.701, loss_scale=8.590e+09, optim_step_time=0.005, optim0_lr0=3.312e-04, train_time=0.151
[lambda-Lambda-Vector] 2025-04-01 19:31:38,816 (trainer:779) INFO: 23epoch:train:155-231batch: iter_time=5.762e-05, forward_time=0.056, loss_ctc=125.563, loss=125.563, backward_time=0.062, grad_norm=96.064, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.005, optim0_lr0=3.308e-04, train_time=0.166
[lambda-Lambda-Vector] 2025-04-01 19:31:51,308 (trainer:779) INFO: 23epoch:train:232-308batch: iter_time=5.667e-05, forward_time=0.055, loss_ctc=119.876, loss=119.876, backward_time=0.060, grad_norm=66.828, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.005, optim0_lr0=3.304e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 19:32:04,073 (trainer:779) INFO: 23epoch:train:309-385batch: iter_time=5.707e-05, forward_time=0.056, loss_ctc=135.575, loss=135.575, backward_time=0.062, grad_norm=88.493, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.005, optim0_lr0=3.300e-04, train_time=0.166
[lambda-Lambda-Vector] 2025-04-01 19:32:16,152 (trainer:779) INFO: 23epoch:train:386-462batch: iter_time=5.547e-05, forward_time=0.054, loss_ctc=99.723, loss=99.723, backward_time=0.058, grad_norm=94.377, clip=98.701, loss_scale=8.590e+09, optim_step_time=0.005, optim0_lr0=3.297e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 19:32:28,444 (trainer:779) INFO: 23epoch:train:463-539batch: iter_time=5.611e-05, forward_time=0.055, loss_ctc=96.333, loss=96.333, backward_time=0.059, grad_norm=224.390, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.005, optim0_lr0=3.293e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 19:32:40,479 (trainer:779) INFO: 23epoch:train:540-616batch: iter_time=5.505e-05, forward_time=0.053, loss_ctc=98.412, loss=98.412, backward_time=0.058, grad_norm=79.077, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.005, optim0_lr0=3.289e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 19:32:52,866 (trainer:779) INFO: 23epoch:train:617-693batch: iter_time=5.743e-05, forward_time=0.055, loss_ctc=111.526, loss=111.526, backward_time=0.060, grad_norm=142.107, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.005, optim0_lr0=3.286e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 19:33:05,044 (trainer:779) INFO: 23epoch:train:694-770batch: iter_time=5.583e-05, forward_time=0.054, loss_ctc=98.397, loss=98.397, backward_time=0.059, grad_norm=96.821, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.005, optim0_lr0=3.282e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 19:33:17,338 (trainer:779) INFO: 23epoch:train:771-847batch: iter_time=5.889e-05, forward_time=0.055, loss_ctc=102.319, loss=102.319, backward_time=0.059, grad_norm=119.747, clip=98.701, loss_scale=8.590e+09, optim_step_time=0.005, optim0_lr0=3.279e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 19:33:29,549 (trainer:779) INFO: 23epoch:train:848-924batch: iter_time=5.520e-05, forward_time=0.054, loss_ctc=115.320, loss=115.320, backward_time=0.059, grad_norm=126.816, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.005, optim0_lr0=3.275e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 19:33:41,970 (trainer:779) INFO: 23epoch:train:925-1001batch: iter_time=5.789e-05, forward_time=0.055, loss_ctc=101.830, loss=101.830, backward_time=0.060, grad_norm=102.533, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.005, optim0_lr0=3.271e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 19:33:53,949 (trainer:779) INFO: 23epoch:train:1002-1078batch: iter_time=5.503e-05, forward_time=0.053, loss_ctc=89.050, loss=89.050, backward_time=0.058, grad_norm=73.287, clip=98.701, loss_scale=8.590e+09, optim_step_time=0.005, optim0_lr0=3.268e-04, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 19:34:06,234 (trainer:779) INFO: 23epoch:train:1079-1155batch: iter_time=5.550e-05, forward_time=0.055, loss_ctc=100.953, loss=100.953, backward_time=0.059, grad_norm=110.563, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.005, optim0_lr0=3.264e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 19:34:18,254 (trainer:779) INFO: 23epoch:train:1156-1232batch: iter_time=5.554e-05, forward_time=0.053, loss_ctc=99.836, loss=99.836, backward_time=0.058, grad_norm=130.376, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.005, optim0_lr0=3.261e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 19:34:31,604 (trainer:779) INFO: 23epoch:train:1233-1309batch: iter_time=5.517e-05, forward_time=0.055, loss_ctc=113.735, loss=113.735, backward_time=0.060, grad_norm=96.771, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.005, optim0_lr0=3.257e-04, train_time=0.173
[lambda-Lambda-Vector] 2025-04-01 19:34:43,741 (trainer:779) INFO: 23epoch:train:1310-1386batch: iter_time=5.564e-05, forward_time=0.054, loss_ctc=97.667, loss=97.667, backward_time=0.058, grad_norm=88.457, clip=98.701, loss_scale=8.590e+09, optim_step_time=0.005, optim0_lr0=3.253e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 19:34:56,361 (trainer:779) INFO: 23epoch:train:1387-1463batch: iter_time=5.517e-05, forward_time=0.056, loss_ctc=97.545, loss=97.545, backward_time=0.061, grad_norm=86.736, clip=98.701, loss_scale=8.590e+09, optim_step_time=0.005, optim0_lr0=3.250e-04, train_time=0.164
[lambda-Lambda-Vector] 2025-04-01 19:35:08,586 (trainer:779) INFO: 23epoch:train:1464-1540batch: iter_time=5.474e-05, forward_time=0.054, loss_ctc=107.216, loss=107.216, backward_time=0.059, grad_norm=95.101, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.005, optim0_lr0=3.246e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 19:35:55,804 (trainer:365) INFO: 23epoch results: [train] iter_time=9.281e-05, forward_time=0.054, loss_ctc=103.342, loss=103.342, backward_time=0.059, grad_norm=101.809, clip=99.613, loss_scale=8.590e+09, optim_step_time=0.005, optim0_lr0=3.280e-04, train_time=0.160, time=4 minutes and 8.72 seconds, total_count=35627, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=119.191, cer_ctc=0.936, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=119.191, time=45.45 seconds, total_count=7337, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 19:35:57,412 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 19:35:57,412 (trainer:299) INFO: 24/70epoch started. Estimated time to finish: 4 hours, 14 minutes and 22.77 seconds
[lambda-Lambda-Vector] 2025-04-01 19:36:10,349 (trainer:779) INFO: 24epoch:train:1-77batch: iter_time=8.206e-04, forward_time=0.054, loss_ctc=103.224, loss=103.224, backward_time=0.058, grad_norm=67.437, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.005, optim0_lr0=3.243e-04, train_time=0.168
[lambda-Lambda-Vector] 2025-04-01 19:36:22,468 (trainer:779) INFO: 24epoch:train:78-154batch: iter_time=5.634e-05, forward_time=0.054, loss_ctc=99.141, loss=99.141, backward_time=0.058, grad_norm=55.999, clip=98.701, loss_scale=8.590e+09, optim_step_time=0.005, optim0_lr0=3.239e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 19:36:34,833 (trainer:779) INFO: 24epoch:train:155-231batch: iter_time=5.673e-05, forward_time=0.055, loss_ctc=90.433, loss=90.433, backward_time=0.059, grad_norm=57.725, clip=96.104, loss_scale=8.590e+09, optim_step_time=0.005, optim0_lr0=3.236e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 19:36:48,210 (trainer:779) INFO: 24epoch:train:232-308batch: iter_time=5.553e-05, forward_time=0.055, loss_ctc=95.607, loss=95.607, backward_time=0.060, grad_norm=61.055, clip=97.403, loss_scale=8.590e+09, optim_step_time=0.005, optim0_lr0=3.232e-04, train_time=0.174
[lambda-Lambda-Vector] 2025-04-01 19:37:00,340 (trainer:779) INFO: 24epoch:train:309-385batch: iter_time=5.436e-05, forward_time=0.054, loss_ctc=105.475, loss=105.475, backward_time=0.058, grad_norm=74.522, clip=100.000, loss_scale=9.929e+09, optim_step_time=0.005, optim0_lr0=3.229e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 19:37:12,573 (trainer:779) INFO: 24epoch:train:386-462batch: iter_time=5.563e-05, forward_time=0.054, loss_ctc=106.255, loss=106.255, backward_time=0.059, grad_norm=86.239, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.005, optim0_lr0=3.225e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 19:37:24,504 (trainer:779) INFO: 24epoch:train:463-539batch: iter_time=5.529e-05, forward_time=0.053, loss_ctc=93.947, loss=93.947, backward_time=0.057, grad_norm=86.540, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.005, optim0_lr0=3.222e-04, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 19:37:36,896 (trainer:779) INFO: 24epoch:train:540-616batch: iter_time=5.542e-05, forward_time=0.055, loss_ctc=116.524, loss=116.524, backward_time=0.060, grad_norm=100.127, clip=98.701, loss_scale=1.718e+10, optim_step_time=0.005, optim0_lr0=3.218e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 19:37:49,178 (trainer:779) INFO: 24epoch:train:617-693batch: iter_time=5.435e-05, forward_time=0.054, loss_ctc=109.723, loss=109.723, backward_time=0.059, grad_norm=84.428, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.005, optim0_lr0=3.215e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 19:38:01,454 (trainer:779) INFO: 24epoch:train:694-770batch: iter_time=5.428e-05, forward_time=0.054, loss_ctc=111.451, loss=111.451, backward_time=0.059, grad_norm=87.210, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.005, optim0_lr0=3.211e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 19:38:13,653 (trainer:779) INFO: 24epoch:train:771-847batch: iter_time=5.324e-05, forward_time=0.054, loss_ctc=116.731, loss=116.731, backward_time=0.059, grad_norm=86.304, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.005, optim0_lr0=3.208e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 19:38:25,794 (trainer:779) INFO: 24epoch:train:848-924batch: iter_time=5.577e-05, forward_time=0.054, loss_ctc=108.177, loss=108.177, backward_time=0.059, grad_norm=73.910, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.005, optim0_lr0=3.205e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 19:38:38,029 (trainer:779) INFO: 24epoch:train:925-1001batch: iter_time=5.570e-05, forward_time=0.054, loss_ctc=94.217, loss=94.217, backward_time=0.059, grad_norm=78.579, clip=98.701, loss_scale=1.718e+10, optim_step_time=0.005, optim0_lr0=3.201e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 19:38:50,508 (trainer:779) INFO: 24epoch:train:1002-1078batch: iter_time=5.456e-05, forward_time=0.055, loss_ctc=112.132, loss=112.132, backward_time=0.060, grad_norm=79.231, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.005, optim0_lr0=3.198e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 19:39:02,415 (trainer:779) INFO: 24epoch:train:1079-1155batch: iter_time=5.444e-05, forward_time=0.053, loss_ctc=99.028, loss=99.028, backward_time=0.057, grad_norm=68.261, clip=98.701, loss_scale=1.718e+10, optim_step_time=0.005, optim0_lr0=3.195e-04, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 19:39:14,919 (trainer:779) INFO: 24epoch:train:1156-1232batch: iter_time=5.452e-05, forward_time=0.055, loss_ctc=121.597, loss=121.597, backward_time=0.060, grad_norm=58.907, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.005, optim0_lr0=3.191e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 19:39:27,041 (trainer:779) INFO: 24epoch:train:1233-1309batch: iter_time=5.758e-05, forward_time=0.054, loss_ctc=96.689, loss=96.689, backward_time=0.058, grad_norm=56.840, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.005, optim0_lr0=3.188e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 19:39:39,584 (trainer:779) INFO: 24epoch:train:1310-1386batch: iter_time=5.519e-05, forward_time=0.056, loss_ctc=108.174, loss=108.174, backward_time=0.060, grad_norm=498.846, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.005, optim0_lr0=3.185e-04, train_time=0.163
[lambda-Lambda-Vector] 2025-04-01 19:39:51,929 (trainer:779) INFO: 24epoch:train:1387-1463batch: iter_time=5.479e-05, forward_time=0.055, loss_ctc=93.829, loss=93.829, backward_time=0.059, grad_norm=61.507, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.005, optim0_lr0=3.181e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 19:40:04,082 (trainer:779) INFO: 24epoch:train:1464-1540batch: iter_time=5.548e-05, forward_time=0.054, loss_ctc=97.756, loss=97.756, backward_time=0.059, grad_norm=67.679, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.005, optim0_lr0=3.178e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 19:40:52,895 (trainer:365) INFO: 24epoch results: [train] iter_time=9.319e-05, forward_time=0.054, loss_ctc=103.391, loss=103.391, backward_time=0.059, grad_norm=94.696, clip=99.419, loss_scale=1.511e+10, optim_step_time=0.005, optim0_lr0=3.210e-04, train_time=0.160, time=4 minutes and 8.52 seconds, total_count=37176, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=117.993, cer_ctc=0.937, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=117.993, time=46.96 seconds, total_count=7656, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 19:40:54,541 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 19:40:54,558 (trainer:487) INFO: The model files were removed: exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/23epoch.pth
[lambda-Lambda-Vector] 2025-04-01 19:40:54,558 (trainer:299) INFO: 25/70epoch started. Estimated time to finish: 4 hours, 8 minutes and 5.14 seconds
[lambda-Lambda-Vector] 2025-04-01 19:41:07,607 (trainer:779) INFO: 25epoch:train:1-77batch: iter_time=7.439e-04, forward_time=0.055, loss_ctc=102.389, loss=102.389, backward_time=0.058, grad_norm=162.076, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.005, optim0_lr0=3.174e-04, train_time=0.169
[lambda-Lambda-Vector] 2025-04-01 19:41:20,127 (trainer:779) INFO: 25epoch:train:78-154batch: iter_time=6.460e-05, forward_time=0.056, loss_ctc=103.855, loss=103.855, backward_time=0.059, grad_norm=224.655, clip=98.701, loss_scale=1.718e+10, optim_step_time=0.005, optim0_lr0=3.171e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 19:41:32,300 (trainer:779) INFO: 25epoch:train:155-231batch: iter_time=5.560e-05, forward_time=0.054, loss_ctc=107.899, loss=107.899, backward_time=0.058, grad_norm=211.409, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.005, optim0_lr0=3.168e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 19:41:44,885 (trainer:779) INFO: 25epoch:train:232-308batch: iter_time=6.298e-05, forward_time=0.056, loss_ctc=107.413, loss=107.413, backward_time=0.060, grad_norm=124.597, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.005, optim0_lr0=3.165e-04, train_time=0.163
[lambda-Lambda-Vector] 2025-04-01 19:41:57,061 (trainer:779) INFO: 25epoch:train:309-385batch: iter_time=6.476e-05, forward_time=0.055, loss_ctc=92.076, loss=92.076, backward_time=0.057, grad_norm=77.117, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.006, optim0_lr0=3.161e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 19:42:09,296 (trainer:779) INFO: 25epoch:train:386-462batch: iter_time=5.960e-05, forward_time=0.055, loss_ctc=96.751, loss=96.751, backward_time=0.058, grad_norm=86.706, clip=98.701, loss_scale=1.718e+10, optim_step_time=0.005, optim0_lr0=3.158e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 19:42:22,128 (trainer:779) INFO: 25epoch:train:463-539batch: iter_time=6.188e-05, forward_time=0.057, loss_ctc=116.899, loss=116.899, backward_time=0.061, grad_norm=96.705, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.006, optim0_lr0=3.155e-04, train_time=0.167
[lambda-Lambda-Vector] 2025-04-01 19:42:34,382 (trainer:779) INFO: 25epoch:train:540-616batch: iter_time=5.743e-05, forward_time=0.054, loss_ctc=108.510, loss=108.510, backward_time=0.059, grad_norm=78.580, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.005, optim0_lr0=3.152e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 19:42:46,828 (trainer:779) INFO: 25epoch:train:617-693batch: iter_time=6.304e-05, forward_time=0.055, loss_ctc=119.334, loss=119.334, backward_time=0.059, grad_norm=79.036, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.006, optim0_lr0=3.148e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 19:42:59,115 (trainer:779) INFO: 25epoch:train:694-770batch: iter_time=6.175e-05, forward_time=0.055, loss_ctc=101.643, loss=101.643, backward_time=0.058, grad_norm=78.892, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.006, optim0_lr0=3.145e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 19:43:11,616 (trainer:779) INFO: 25epoch:train:771-847batch: iter_time=6.216e-05, forward_time=0.056, loss_ctc=98.729, loss=98.729, backward_time=0.060, grad_norm=103.329, clip=98.701, loss_scale=2.231e+10, optim_step_time=0.005, optim0_lr0=3.142e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 19:43:23,728 (trainer:779) INFO: 25epoch:train:848-924batch: iter_time=5.993e-05, forward_time=0.054, loss_ctc=90.089, loss=90.089, backward_time=0.057, grad_norm=87.237, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.005, optim0_lr0=3.139e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 19:43:37,015 (trainer:779) INFO: 25epoch:train:925-1001batch: iter_time=5.980e-05, forward_time=0.055, loss_ctc=106.894, loss=106.894, backward_time=0.059, grad_norm=93.059, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.005, optim0_lr0=3.136e-04, train_time=0.172
[lambda-Lambda-Vector] 2025-04-01 19:43:49,682 (trainer:779) INFO: 25epoch:train:1002-1078batch: iter_time=6.081e-05, forward_time=0.056, loss_ctc=124.205, loss=124.205, backward_time=0.061, grad_norm=88.932, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.005, optim0_lr0=3.132e-04, train_time=0.164
[lambda-Lambda-Vector] 2025-04-01 19:44:01,824 (trainer:779) INFO: 25epoch:train:1079-1155batch: iter_time=6.536e-05, forward_time=0.054, loss_ctc=91.893, loss=91.893, backward_time=0.057, grad_norm=86.514, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.006, optim0_lr0=3.129e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 19:44:14,163 (trainer:779) INFO: 25epoch:train:1156-1232batch: iter_time=6.007e-05, forward_time=0.055, loss_ctc=97.901, loss=97.901, backward_time=0.059, grad_norm=102.657, clip=98.701, loss_scale=3.436e+10, optim_step_time=0.005, optim0_lr0=3.126e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 19:44:27,019 (trainer:779) INFO: 25epoch:train:1233-1309batch: iter_time=6.338e-05, forward_time=0.057, loss_ctc=113.490, loss=113.490, backward_time=0.061, grad_norm=130.862, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.006, optim0_lr0=3.123e-04, train_time=0.167
[lambda-Lambda-Vector] 2025-04-01 19:44:39,648 (trainer:779) INFO: 25epoch:train:1310-1386batch: iter_time=6.125e-05, forward_time=0.056, loss_ctc=92.816, loss=92.816, backward_time=0.060, grad_norm=101.751, clip=96.104, loss_scale=3.436e+10, optim_step_time=0.006, optim0_lr0=3.120e-04, train_time=0.164
[lambda-Lambda-Vector] 2025-04-01 19:44:52,295 (trainer:779) INFO: 25epoch:train:1387-1463batch: iter_time=6.105e-05, forward_time=0.056, loss_ctc=99.554, loss=99.554, backward_time=0.060, grad_norm=88.253, clip=98.701, loss_scale=3.436e+10, optim_step_time=0.006, optim0_lr0=3.117e-04, train_time=0.164
[lambda-Lambda-Vector] 2025-04-01 19:45:04,606 (trainer:779) INFO: 25epoch:train:1464-1540batch: iter_time=5.961e-05, forward_time=0.055, loss_ctc=108.659, loss=108.659, backward_time=0.059, grad_norm=118.942, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.005, optim0_lr0=3.114e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 19:45:51,811 (trainer:365) INFO: 25epoch results: [train] iter_time=9.514e-05, forward_time=0.055, loss_ctc=103.334, loss=103.334, backward_time=0.059, grad_norm=110.875, clip=99.484, loss_scale=2.522e+10, optim_step_time=0.005, optim0_lr0=3.144e-04, train_time=0.162, time=4 minutes and 11.83 seconds, total_count=38725, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=118.368, cer_ctc=0.934, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=118.368, time=45.42 seconds, total_count=7975, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 19:45:53,435 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 19:45:53,469 (trainer:487) INFO: The model files were removed: exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/16epoch.pth, exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/24epoch.pth
[lambda-Lambda-Vector] 2025-04-01 19:45:53,470 (trainer:299) INFO: 26/70epoch started. Estimated time to finish: 4 hours, 1 minute and 57.13 seconds
[lambda-Lambda-Vector] 2025-04-01 19:46:07,505 (trainer:779) INFO: 26epoch:train:1-77batch: iter_time=8.576e-04, forward_time=0.055, loss_ctc=94.119, loss=94.119, backward_time=0.058, grad_norm=122.677, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.005, optim0_lr0=3.110e-04, train_time=0.182
[lambda-Lambda-Vector] 2025-04-01 19:46:19,594 (trainer:779) INFO: 26epoch:train:78-154batch: iter_time=6.621e-05, forward_time=0.054, loss_ctc=80.433, loss=80.433, backward_time=0.057, grad_norm=65.197, clip=96.104, loss_scale=3.436e+10, optim_step_time=0.006, optim0_lr0=3.107e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 19:46:32,110 (trainer:779) INFO: 26epoch:train:155-231batch: iter_time=6.128e-05, forward_time=0.055, loss_ctc=114.118, loss=114.118, backward_time=0.060, grad_norm=93.011, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.005, optim0_lr0=3.104e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 19:46:44,352 (trainer:779) INFO: 26epoch:train:232-308batch: iter_time=6.369e-05, forward_time=0.055, loss_ctc=100.179, loss=100.179, backward_time=0.058, grad_norm=74.600, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.006, optim0_lr0=3.101e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 19:46:56,678 (trainer:779) INFO: 26epoch:train:309-385batch: iter_time=6.253e-05, forward_time=0.055, loss_ctc=100.086, loss=100.086, backward_time=0.059, grad_norm=76.737, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.006, optim0_lr0=3.098e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 19:47:09,166 (trainer:779) INFO: 26epoch:train:386-462batch: iter_time=6.167e-05, forward_time=0.056, loss_ctc=109.967, loss=109.967, backward_time=0.060, grad_norm=113.052, clip=98.701, loss_scale=3.436e+10, optim_step_time=0.006, optim0_lr0=3.095e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 19:47:21,646 (trainer:779) INFO: 26epoch:train:463-539batch: iter_time=5.941e-05, forward_time=0.055, loss_ctc=110.853, loss=110.853, backward_time=0.060, grad_norm=87.137, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.005, optim0_lr0=3.092e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 19:47:34,200 (trainer:779) INFO: 26epoch:train:540-616batch: iter_time=6.136e-05, forward_time=0.056, loss_ctc=111.998, loss=111.998, backward_time=0.060, grad_norm=68.385, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.006, optim0_lr0=3.089e-04, train_time=0.163
[lambda-Lambda-Vector] 2025-04-01 19:47:46,688 (trainer:779) INFO: 26epoch:train:617-693batch: iter_time=6.218e-05, forward_time=0.056, loss_ctc=111.766, loss=111.766, backward_time=0.059, grad_norm=56.654, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.006, optim0_lr0=3.086e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 19:47:59,052 (trainer:779) INFO: 26epoch:train:694-770batch: iter_time=6.225e-05, forward_time=0.055, loss_ctc=98.172, loss=98.172, backward_time=0.059, grad_norm=61.997, clip=98.701, loss_scale=3.436e+10, optim_step_time=0.006, optim0_lr0=3.083e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 19:48:11,451 (trainer:779) INFO: 26epoch:train:771-847batch: iter_time=6.141e-05, forward_time=0.055, loss_ctc=114.262, loss=114.262, backward_time=0.059, grad_norm=59.968, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.006, optim0_lr0=3.080e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 19:48:23,813 (trainer:779) INFO: 26epoch:train:848-924batch: iter_time=6.256e-05, forward_time=0.055, loss_ctc=101.588, loss=101.588, backward_time=0.059, grad_norm=51.051, clip=98.701, loss_scale=3.436e+10, optim_step_time=0.006, optim0_lr0=3.077e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 19:48:36,432 (trainer:779) INFO: 26epoch:train:925-1001batch: iter_time=6.095e-05, forward_time=0.056, loss_ctc=108.552, loss=108.552, backward_time=0.060, grad_norm=80.648, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.006, optim0_lr0=3.074e-04, train_time=0.164
[lambda-Lambda-Vector] 2025-04-01 19:48:48,910 (trainer:779) INFO: 26epoch:train:1002-1078batch: iter_time=6.029e-05, forward_time=0.055, loss_ctc=113.492, loss=113.492, backward_time=0.059, grad_norm=101.675, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.006, optim0_lr0=3.071e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 19:49:01,424 (trainer:779) INFO: 26epoch:train:1079-1155batch: iter_time=6.022e-05, forward_time=0.056, loss_ctc=108.670, loss=108.670, backward_time=0.059, grad_norm=79.465, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.006, optim0_lr0=3.068e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 19:49:13,639 (trainer:779) INFO: 26epoch:train:1156-1232batch: iter_time=6.074e-05, forward_time=0.054, loss_ctc=101.958, loss=101.958, backward_time=0.058, grad_norm=76.374, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.006, optim0_lr0=3.065e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 19:49:26,411 (trainer:779) INFO: 26epoch:train:1233-1309batch: iter_time=5.950e-05, forward_time=0.057, loss_ctc=116.696, loss=116.696, backward_time=0.061, grad_norm=87.713, clip=100.000, loss_scale=4.953e+10, optim_step_time=0.006, optim0_lr0=3.062e-04, train_time=0.166
[lambda-Lambda-Vector] 2025-04-01 19:49:38,753 (trainer:779) INFO: 26epoch:train:1310-1386batch: iter_time=5.726e-05, forward_time=0.055, loss_ctc=101.695, loss=101.695, backward_time=0.059, grad_norm=103.861, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.005, optim0_lr0=3.059e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 19:49:51,470 (trainer:779) INFO: 26epoch:train:1387-1463batch: iter_time=6.156e-05, forward_time=0.057, loss_ctc=93.945, loss=93.945, backward_time=0.060, grad_norm=88.611, clip=98.701, loss_scale=6.872e+10, optim_step_time=0.006, optim0_lr0=3.056e-04, train_time=0.165
[lambda-Lambda-Vector] 2025-04-01 19:50:03,994 (trainer:779) INFO: 26epoch:train:1464-1540batch: iter_time=6.242e-05, forward_time=0.056, loss_ctc=97.424, loss=97.424, backward_time=0.059, grad_norm=82.495, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.006, optim0_lr0=3.053e-04, train_time=0.163
[lambda-Lambda-Vector] 2025-04-01 19:50:51,986 (trainer:365) INFO: 26epoch results: [train] iter_time=1.009e-04, forward_time=0.055, loss_ctc=103.337, loss=103.337, backward_time=0.059, grad_norm=81.317, clip=99.548, loss_scale=4.044e+10, optim_step_time=0.006, optim0_lr0=3.081e-04, train_time=0.162, time=4 minutes and 12.1 seconds, total_count=40274, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=122.074, cer_ctc=0.931, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=122.074, time=46.41 seconds, total_count=8294, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 19:50:53,640 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 19:50:53,657 (trainer:487) INFO: The model files were removed: exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/22epoch.pth
[lambda-Lambda-Vector] 2025-04-01 19:50:53,657 (trainer:299) INFO: 27/70epoch started. Estimated time to finish: 3 hours, 55 minutes and 56.59 seconds
[lambda-Lambda-Vector] 2025-04-01 19:51:06,688 (trainer:779) INFO: 27epoch:train:1-77batch: iter_time=7.663e-04, forward_time=0.055, loss_ctc=105.028, loss=105.028, backward_time=0.058, grad_norm=66.066, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.006, optim0_lr0=3.050e-04, train_time=0.169
[lambda-Lambda-Vector] 2025-04-01 19:51:19,377 (trainer:779) INFO: 27epoch:train:78-154batch: iter_time=6.637e-05, forward_time=0.057, loss_ctc=102.143, loss=102.143, backward_time=0.060, grad_norm=77.989, clip=98.701, loss_scale=6.872e+10, optim_step_time=0.006, optim0_lr0=3.047e-04, train_time=0.165
[lambda-Lambda-Vector] 2025-04-01 19:51:32,151 (trainer:779) INFO: 27epoch:train:155-231batch: iter_time=6.600e-05, forward_time=0.057, loss_ctc=114.221, loss=114.221, backward_time=0.061, grad_norm=92.065, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.006, optim0_lr0=3.044e-04, train_time=0.166
[lambda-Lambda-Vector] 2025-04-01 19:51:44,402 (trainer:779) INFO: 27epoch:train:232-308batch: iter_time=6.317e-05, forward_time=0.055, loss_ctc=103.825, loss=103.825, backward_time=0.058, grad_norm=106.594, clip=98.701, loss_scale=6.872e+10, optim_step_time=0.006, optim0_lr0=3.041e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 19:51:56,885 (trainer:779) INFO: 27epoch:train:309-385batch: iter_time=6.625e-05, forward_time=0.056, loss_ctc=101.050, loss=101.050, backward_time=0.059, grad_norm=94.757, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.006, optim0_lr0=3.038e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 19:52:09,541 (trainer:779) INFO: 27epoch:train:386-462batch: iter_time=6.122e-05, forward_time=0.057, loss_ctc=104.221, loss=104.221, backward_time=0.060, grad_norm=87.951, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.006, optim0_lr0=3.035e-04, train_time=0.164
[lambda-Lambda-Vector] 2025-04-01 19:52:21,990 (trainer:779) INFO: 27epoch:train:463-539batch: iter_time=6.253e-05, forward_time=0.056, loss_ctc=102.908, loss=102.908, backward_time=0.059, grad_norm=81.487, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.006, optim0_lr0=3.033e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 19:52:35,580 (trainer:779) INFO: 27epoch:train:540-616batch: iter_time=6.278e-05, forward_time=0.056, loss_ctc=97.527, loss=97.527, backward_time=0.060, grad_norm=91.281, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.006, optim0_lr0=3.030e-04, train_time=0.176
[lambda-Lambda-Vector] 2025-04-01 19:52:48,050 (trainer:779) INFO: 27epoch:train:617-693batch: iter_time=6.313e-05, forward_time=0.056, loss_ctc=111.927, loss=111.927, backward_time=0.059, grad_norm=83.516, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.006, optim0_lr0=3.027e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 19:53:00,778 (trainer:779) INFO: 27epoch:train:694-770batch: iter_time=6.842e-05, forward_time=0.057, loss_ctc=103.367, loss=103.367, backward_time=0.060, grad_norm=70.174, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.006, optim0_lr0=3.024e-04, train_time=0.165
[lambda-Lambda-Vector] 2025-04-01 19:53:13,309 (trainer:779) INFO: 27epoch:train:771-847batch: iter_time=6.439e-05, forward_time=0.056, loss_ctc=94.067, loss=94.067, backward_time=0.059, grad_norm=63.029, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.006, optim0_lr0=3.021e-04, train_time=0.163
[lambda-Lambda-Vector] 2025-04-01 19:53:25,692 (trainer:779) INFO: 27epoch:train:848-924batch: iter_time=6.598e-05, forward_time=0.055, loss_ctc=109.360, loss=109.360, backward_time=0.059, grad_norm=64.044, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.006, optim0_lr0=3.018e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 19:53:38,178 (trainer:779) INFO: 27epoch:train:925-1001batch: iter_time=6.586e-05, forward_time=0.056, loss_ctc=93.400, loss=93.400, backward_time=0.059, grad_norm=70.779, clip=98.701, loss_scale=6.872e+10, optim_step_time=0.006, optim0_lr0=3.016e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 19:53:50,303 (trainer:779) INFO: 27epoch:train:1002-1078batch: iter_time=6.189e-05, forward_time=0.055, loss_ctc=91.711, loss=91.711, backward_time=0.057, grad_norm=70.011, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.006, optim0_lr0=3.013e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 19:54:02,820 (trainer:779) INFO: 27epoch:train:1079-1155batch: iter_time=6.711e-05, forward_time=0.056, loss_ctc=104.724, loss=104.724, backward_time=0.059, grad_norm=65.990, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.006, optim0_lr0=3.010e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 19:54:15,498 (trainer:779) INFO: 27epoch:train:1156-1232batch: iter_time=6.347e-05, forward_time=0.057, loss_ctc=112.946, loss=112.946, backward_time=0.060, grad_norm=65.207, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.006, optim0_lr0=3.007e-04, train_time=0.165
[lambda-Lambda-Vector] 2025-04-01 19:54:27,683 (trainer:779) INFO: 27epoch:train:1233-1309batch: iter_time=6.348e-05, forward_time=0.054, loss_ctc=99.841, loss=99.841, backward_time=0.058, grad_norm=57.111, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.006, optim0_lr0=3.004e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 19:54:40,107 (trainer:779) INFO: 27epoch:train:1310-1386batch: iter_time=6.293e-05, forward_time=0.055, loss_ctc=108.621, loss=108.621, backward_time=0.059, grad_norm=64.977, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.006, optim0_lr0=3.002e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 19:54:52,901 (trainer:779) INFO: 27epoch:train:1387-1463batch: iter_time=6.169e-05, forward_time=0.057, loss_ctc=124.307, loss=124.307, backward_time=0.061, grad_norm=76.255, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.006, optim0_lr0=2.999e-04, train_time=0.166
[lambda-Lambda-Vector] 2025-04-01 19:55:04,706 (trainer:779) INFO: 27epoch:train:1464-1540batch: iter_time=5.770e-05, forward_time=0.052, loss_ctc=90.761, loss=90.761, backward_time=0.056, grad_norm=56.888, clip=97.403, loss_scale=6.872e+10, optim_step_time=0.005, optim0_lr0=2.996e-04, train_time=0.153
[lambda-Lambda-Vector] 2025-04-01 19:55:52,464 (trainer:365) INFO: 27epoch results: [train] iter_time=9.873e-05, forward_time=0.056, loss_ctc=103.271, loss=103.271, backward_time=0.059, grad_norm=75.249, clip=99.677, loss_scale=6.872e+10, optim_step_time=0.006, optim0_lr0=3.023e-04, train_time=0.163, time=4 minutes and 12.77 seconds, total_count=41823, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=129.555, cer_ctc=0.935, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=129.555, time=46.04 seconds, total_count=8613, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 19:55:55,052 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 19:55:55,052 (trainer:299) INFO: 28/70epoch started. Estimated time to finish: 3 hours, 50 minutes and 2.45 seconds
[lambda-Lambda-Vector] 2025-04-01 19:56:08,148 (trainer:779) INFO: 28epoch:train:1-77batch: iter_time=6.437e-04, forward_time=0.055, loss_ctc=103.272, loss=103.272, backward_time=0.059, grad_norm=69.859, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.005, optim0_lr0=2.993e-04, train_time=0.170
[lambda-Lambda-Vector] 2025-04-01 19:56:20,754 (trainer:779) INFO: 28epoch:train:78-154batch: iter_time=6.673e-05, forward_time=0.056, loss_ctc=111.659, loss=111.659, backward_time=0.060, grad_norm=67.204, clip=98.701, loss_scale=6.872e+10, optim_step_time=0.006, optim0_lr0=2.990e-04, train_time=0.164
[lambda-Lambda-Vector] 2025-04-01 19:56:33,146 (trainer:779) INFO: 28epoch:train:155-231batch: iter_time=6.460e-05, forward_time=0.055, loss_ctc=97.921, loss=97.921, backward_time=0.059, grad_norm=72.434, clip=98.701, loss_scale=1.169e+11, optim_step_time=0.006, optim0_lr0=2.987e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 19:56:45,598 (trainer:779) INFO: 28epoch:train:232-308batch: iter_time=6.180e-05, forward_time=0.056, loss_ctc=89.733, loss=89.733, backward_time=0.059, grad_norm=73.204, clip=94.805, loss_scale=1.374e+11, optim_step_time=0.005, optim0_lr0=2.985e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 19:56:57,776 (trainer:779) INFO: 28epoch:train:309-385batch: iter_time=6.138e-05, forward_time=0.055, loss_ctc=97.495, loss=97.495, backward_time=0.058, grad_norm=66.738, clip=98.701, loss_scale=1.374e+11, optim_step_time=0.005, optim0_lr0=2.982e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 19:57:09,814 (trainer:779) INFO: 28epoch:train:386-462batch: iter_time=6.135e-05, forward_time=0.053, loss_ctc=95.918, loss=95.918, backward_time=0.057, grad_norm=55.636, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.005, optim0_lr0=2.979e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 19:57:22,469 (trainer:779) INFO: 28epoch:train:463-539batch: iter_time=6.423e-05, forward_time=0.056, loss_ctc=107.932, loss=107.932, backward_time=0.060, grad_norm=60.485, clip=98.701, loss_scale=1.374e+11, optim_step_time=0.006, optim0_lr0=2.977e-04, train_time=0.164
[lambda-Lambda-Vector] 2025-04-01 19:57:35,042 (trainer:779) INFO: 28epoch:train:540-616batch: iter_time=6.582e-05, forward_time=0.056, loss_ctc=102.930, loss=102.930, backward_time=0.059, grad_norm=58.850, clip=98.701, loss_scale=1.374e+11, optim_step_time=0.006, optim0_lr0=2.974e-04, train_time=0.163
[lambda-Lambda-Vector] 2025-04-01 19:57:47,436 (trainer:779) INFO: 28epoch:train:617-693batch: iter_time=5.809e-05, forward_time=0.055, loss_ctc=113.575, loss=113.575, backward_time=0.059, grad_norm=76.143, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.005, optim0_lr0=2.971e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 19:57:59,670 (trainer:779) INFO: 28epoch:train:694-770batch: iter_time=5.452e-05, forward_time=0.054, loss_ctc=121.920, loss=121.920, backward_time=0.059, grad_norm=66.362, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.005, optim0_lr0=2.968e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 19:58:11,470 (trainer:779) INFO: 28epoch:train:771-847batch: iter_time=4.880e-05, forward_time=0.052, loss_ctc=100.393, loss=100.393, backward_time=0.056, grad_norm=60.572, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.005, optim0_lr0=2.966e-04, train_time=0.153
[lambda-Lambda-Vector] 2025-04-01 19:58:23,541 (trainer:779) INFO: 28epoch:train:848-924batch: iter_time=4.918e-05, forward_time=0.053, loss_ctc=109.494, loss=109.494, backward_time=0.058, grad_norm=55.908, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.005, optim0_lr0=2.963e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 19:58:35,900 (trainer:779) INFO: 28epoch:train:925-1001batch: iter_time=4.839e-05, forward_time=0.054, loss_ctc=116.158, loss=116.158, backward_time=0.059, grad_norm=70.637, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.004, optim0_lr0=2.960e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 19:58:48,058 (trainer:779) INFO: 28epoch:train:1002-1078batch: iter_time=4.912e-05, forward_time=0.054, loss_ctc=93.816, loss=93.816, backward_time=0.058, grad_norm=69.680, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.005, optim0_lr0=2.958e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 19:59:00,304 (trainer:779) INFO: 28epoch:train:1079-1155batch: iter_time=4.934e-05, forward_time=0.054, loss_ctc=104.234, loss=104.234, backward_time=0.059, grad_norm=63.905, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.005, optim0_lr0=2.955e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 19:59:12,374 (trainer:779) INFO: 28epoch:train:1156-1232batch: iter_time=4.904e-05, forward_time=0.053, loss_ctc=99.710, loss=99.710, backward_time=0.058, grad_norm=67.108, clip=97.403, loss_scale=1.374e+11, optim_step_time=0.005, optim0_lr0=2.953e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 19:59:25,536 (trainer:779) INFO: 28epoch:train:1233-1309batch: iter_time=4.838e-05, forward_time=0.054, loss_ctc=106.708, loss=106.708, backward_time=0.059, grad_norm=70.508, clip=98.701, loss_scale=1.374e+11, optim_step_time=0.005, optim0_lr0=2.950e-04, train_time=0.171
[lambda-Lambda-Vector] 2025-04-01 19:59:37,367 (trainer:779) INFO: 28epoch:train:1310-1386batch: iter_time=5.024e-05, forward_time=0.052, loss_ctc=97.902, loss=97.902, backward_time=0.057, grad_norm=60.665, clip=98.701, loss_scale=1.374e+11, optim_step_time=0.005, optim0_lr0=2.947e-04, train_time=0.154
[lambda-Lambda-Vector] 2025-04-01 19:59:49,675 (trainer:779) INFO: 28epoch:train:1387-1463batch: iter_time=5.023e-05, forward_time=0.054, loss_ctc=101.265, loss=101.265, backward_time=0.059, grad_norm=71.187, clip=98.701, loss_scale=1.374e+11, optim_step_time=0.005, optim0_lr0=2.945e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 20:00:01,980 (trainer:779) INFO: 28epoch:train:1464-1540batch: iter_time=4.871e-05, forward_time=0.054, loss_ctc=112.170, loss=112.170, backward_time=0.059, grad_norm=77.447, clip=98.701, loss_scale=1.374e+11, optim_step_time=0.005, optim0_lr0=2.942e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 20:00:48,964 (trainer:365) INFO: 28epoch results: [train] iter_time=8.439e-05, forward_time=0.054, loss_ctc=103.240, loss=103.240, backward_time=0.059, grad_norm=66.623, clip=99.032, loss_scale=1.296e+11, optim_step_time=0.005, optim0_lr0=2.967e-04, train_time=0.160, time=4 minutes and 8.63 seconds, total_count=43372, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=119.049, cer_ctc=0.933, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=119.049, time=45.28 seconds, total_count=8932, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 20:00:50,611 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 20:00:50,644 (trainer:487) INFO: The model files were removed: exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/25epoch.pth, exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/27epoch.pth
[lambda-Lambda-Vector] 2025-04-01 20:00:50,644 (trainer:299) INFO: 29/70epoch started. Estimated time to finish: 3 hours, 44 minutes and 3.37 seconds
[lambda-Lambda-Vector] 2025-04-01 20:01:03,556 (trainer:779) INFO: 29epoch:train:1-77batch: iter_time=7.444e-04, forward_time=0.054, loss_ctc=104.585, loss=104.585, backward_time=0.058, grad_norm=75.972, clip=98.701, loss_scale=1.374e+11, optim_step_time=0.005, optim0_lr0=2.939e-04, train_time=0.168
[lambda-Lambda-Vector] 2025-04-01 20:01:15,990 (trainer:779) INFO: 29epoch:train:78-154batch: iter_time=5.086e-05, forward_time=0.055, loss_ctc=122.504, loss=122.504, backward_time=0.060, grad_norm=77.302, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.005, optim0_lr0=2.936e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 20:01:27,723 (trainer:779) INFO: 29epoch:train:155-231batch: iter_time=5.105e-05, forward_time=0.052, loss_ctc=96.834, loss=96.834, backward_time=0.056, grad_norm=67.577, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.005, optim0_lr0=2.934e-04, train_time=0.152
[lambda-Lambda-Vector] 2025-04-01 20:01:39,788 (trainer:779) INFO: 29epoch:train:232-308batch: iter_time=5.015e-05, forward_time=0.053, loss_ctc=100.620, loss=100.620, backward_time=0.058, grad_norm=74.767, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.005, optim0_lr0=2.931e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 20:01:51,792 (trainer:779) INFO: 29epoch:train:309-385batch: iter_time=5.145e-05, forward_time=0.053, loss_ctc=107.294, loss=107.294, backward_time=0.058, grad_norm=80.971, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.005, optim0_lr0=2.929e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 20:02:04,847 (trainer:779) INFO: 29epoch:train:386-462batch: iter_time=4.919e-05, forward_time=0.053, loss_ctc=92.216, loss=92.216, backward_time=0.058, grad_norm=99.214, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.005, optim0_lr0=2.926e-04, train_time=0.169
[lambda-Lambda-Vector] 2025-04-01 20:02:17,140 (trainer:779) INFO: 29epoch:train:463-539batch: iter_time=4.926e-05, forward_time=0.054, loss_ctc=111.997, loss=111.997, backward_time=0.059, grad_norm=100.642, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.005, optim0_lr0=2.924e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 20:02:29,128 (trainer:779) INFO: 29epoch:train:540-616batch: iter_time=4.924e-05, forward_time=0.053, loss_ctc=96.204, loss=96.204, backward_time=0.057, grad_norm=85.503, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.005, optim0_lr0=2.921e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 20:02:41,273 (trainer:779) INFO: 29epoch:train:617-693batch: iter_time=4.812e-05, forward_time=0.054, loss_ctc=103.699, loss=103.699, backward_time=0.058, grad_norm=129.656, clip=100.000, loss_scale=2.535e+11, optim_step_time=0.005, optim0_lr0=2.918e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 20:02:53,377 (trainer:779) INFO: 29epoch:train:694-770batch: iter_time=4.896e-05, forward_time=0.053, loss_ctc=97.368, loss=97.368, backward_time=0.058, grad_norm=113.458, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.005, optim0_lr0=2.916e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 20:03:05,490 (trainer:779) INFO: 29epoch:train:771-847batch: iter_time=5.037e-05, forward_time=0.054, loss_ctc=101.492, loss=101.492, backward_time=0.058, grad_norm=102.672, clip=98.701, loss_scale=2.749e+11, optim_step_time=0.005, optim0_lr0=2.913e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 20:03:17,219 (trainer:779) INFO: 29epoch:train:848-924batch: iter_time=4.863e-05, forward_time=0.052, loss_ctc=79.656, loss=79.656, backward_time=0.056, grad_norm=68.489, clip=98.701, loss_scale=2.749e+11, optim_step_time=0.005, optim0_lr0=2.911e-04, train_time=0.152
[lambda-Lambda-Vector] 2025-04-01 20:03:29,364 (trainer:779) INFO: 29epoch:train:925-1001batch: iter_time=4.736e-05, forward_time=0.054, loss_ctc=104.207, loss=104.207, backward_time=0.058, grad_norm=93.275, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.005, optim0_lr0=2.908e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 20:03:41,769 (trainer:779) INFO: 29epoch:train:1002-1078batch: iter_time=4.812e-05, forward_time=0.055, loss_ctc=103.402, loss=103.402, backward_time=0.060, grad_norm=94.656, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.005, optim0_lr0=2.906e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 20:03:54,195 (trainer:779) INFO: 29epoch:train:1079-1155batch: iter_time=4.768e-05, forward_time=0.055, loss_ctc=119.999, loss=119.999, backward_time=0.060, grad_norm=75.909, clip=98.701, loss_scale=2.749e+11, optim_step_time=0.005, optim0_lr0=2.903e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 20:04:06,470 (trainer:779) INFO: 29epoch:train:1156-1232batch: iter_time=4.734e-05, forward_time=0.054, loss_ctc=102.583, loss=102.583, backward_time=0.059, grad_norm=70.667, clip=97.403, loss_scale=2.749e+11, optim_step_time=0.005, optim0_lr0=2.901e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 20:04:18,809 (trainer:779) INFO: 29epoch:train:1233-1309batch: iter_time=4.773e-05, forward_time=0.054, loss_ctc=107.109, loss=107.109, backward_time=0.059, grad_norm=109.359, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.005, optim0_lr0=2.898e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 20:04:31,098 (trainer:779) INFO: 29epoch:train:1310-1386batch: iter_time=4.848e-05, forward_time=0.054, loss_ctc=117.357, loss=117.357, backward_time=0.059, grad_norm=93.224, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.005, optim0_lr0=2.896e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 20:04:43,288 (trainer:779) INFO: 29epoch:train:1387-1463batch: iter_time=4.915e-05, forward_time=0.054, loss_ctc=105.522, loss=105.522, backward_time=0.058, grad_norm=75.656, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.005, optim0_lr0=2.893e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 20:04:55,550 (trainer:779) INFO: 29epoch:train:1464-1540batch: iter_time=4.733e-05, forward_time=0.054, loss_ctc=105.894, loss=105.894, backward_time=0.059, grad_norm=75.198, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.005, optim0_lr0=2.891e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 20:05:42,489 (trainer:365) INFO: 29epoch results: [train] iter_time=8.347e-05, forward_time=0.054, loss_ctc=103.137, loss=103.137, backward_time=0.058, grad_norm=87.996, clip=99.613, loss_scale=2.192e+11, optim_step_time=0.005, optim0_lr0=2.915e-04, train_time=0.159, time=4 minutes and 6.61 seconds, total_count=44921, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=132.005, cer_ctc=0.940, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=132.005, time=45.23 seconds, total_count=9251, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 20:05:45,042 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 20:05:45,043 (trainer:299) INFO: 30/70epoch started. Estimated time to finish: 3 hours, 38 minutes and 6.98 seconds
[lambda-Lambda-Vector] 2025-04-01 20:05:57,543 (trainer:779) INFO: 30epoch:train:1-77batch: iter_time=8.160e-04, forward_time=0.052, loss_ctc=93.666, loss=93.666, backward_time=0.056, grad_norm=64.774, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.005, optim0_lr0=2.888e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 20:06:09,899 (trainer:779) INFO: 30epoch:train:78-154batch: iter_time=4.766e-05, forward_time=0.054, loss_ctc=107.219, loss=107.219, backward_time=0.059, grad_norm=87.939, clip=98.701, loss_scale=2.749e+11, optim_step_time=0.004, optim0_lr0=2.886e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 20:06:21,966 (trainer:779) INFO: 30epoch:train:155-231batch: iter_time=4.806e-05, forward_time=0.053, loss_ctc=104.511, loss=104.511, backward_time=0.058, grad_norm=86.303, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.004, optim0_lr0=2.883e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 20:06:34,282 (trainer:779) INFO: 30epoch:train:232-308batch: iter_time=4.775e-05, forward_time=0.054, loss_ctc=101.104, loss=101.104, backward_time=0.059, grad_norm=90.292, clip=98.701, loss_scale=2.749e+11, optim_step_time=0.004, optim0_lr0=2.881e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 20:06:46,523 (trainer:779) INFO: 30epoch:train:309-385batch: iter_time=4.654e-05, forward_time=0.054, loss_ctc=111.525, loss=111.525, backward_time=0.059, grad_norm=105.257, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.004, optim0_lr0=2.878e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 20:06:58,537 (trainer:779) INFO: 30epoch:train:386-462batch: iter_time=4.840e-05, forward_time=0.053, loss_ctc=115.478, loss=115.478, backward_time=0.058, grad_norm=91.766, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.004, optim0_lr0=2.876e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 20:07:10,166 (trainer:779) INFO: 30epoch:train:463-539batch: iter_time=4.691e-05, forward_time=0.051, loss_ctc=92.170, loss=92.170, backward_time=0.056, grad_norm=64.962, clip=98.701, loss_scale=2.749e+11, optim_step_time=0.004, optim0_lr0=2.873e-04, train_time=0.151
[lambda-Lambda-Vector] 2025-04-01 20:07:22,471 (trainer:779) INFO: 30epoch:train:540-616batch: iter_time=4.622e-05, forward_time=0.054, loss_ctc=125.474, loss=125.474, backward_time=0.059, grad_norm=74.284, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.004, optim0_lr0=2.871e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 20:07:34,557 (trainer:779) INFO: 30epoch:train:617-693batch: iter_time=4.667e-05, forward_time=0.053, loss_ctc=102.528, loss=102.528, backward_time=0.058, grad_norm=63.656, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.005, optim0_lr0=2.868e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 20:07:46,718 (trainer:779) INFO: 30epoch:train:694-770batch: iter_time=4.639e-05, forward_time=0.053, loss_ctc=109.155, loss=109.155, backward_time=0.059, grad_norm=72.334, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.004, optim0_lr0=2.866e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 20:07:58,987 (trainer:779) INFO: 30epoch:train:771-847batch: iter_time=4.849e-05, forward_time=0.054, loss_ctc=106.532, loss=106.532, backward_time=0.059, grad_norm=68.064, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.005, optim0_lr0=2.864e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 20:08:11,165 (trainer:779) INFO: 30epoch:train:848-924batch: iter_time=4.943e-05, forward_time=0.054, loss_ctc=111.031, loss=111.031, backward_time=0.059, grad_norm=59.279, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.005, optim0_lr0=2.861e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 20:08:23,538 (trainer:779) INFO: 30epoch:train:925-1001batch: iter_time=4.962e-05, forward_time=0.055, loss_ctc=98.475, loss=98.475, backward_time=0.059, grad_norm=67.364, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.005, optim0_lr0=2.859e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 20:08:36,082 (trainer:779) INFO: 30epoch:train:1002-1078batch: iter_time=4.997e-05, forward_time=0.056, loss_ctc=109.983, loss=109.983, backward_time=0.060, grad_norm=66.950, clip=98.701, loss_scale=2.749e+11, optim_step_time=0.005, optim0_lr0=2.856e-04, train_time=0.163
[lambda-Lambda-Vector] 2025-04-01 20:08:49,359 (trainer:779) INFO: 30epoch:train:1079-1155batch: iter_time=5.063e-05, forward_time=0.055, loss_ctc=106.599, loss=106.599, backward_time=0.059, grad_norm=60.980, clip=98.701, loss_scale=5.462e+11, optim_step_time=0.005, optim0_lr0=2.854e-04, train_time=0.172
[lambda-Lambda-Vector] 2025-04-01 20:09:01,090 (trainer:779) INFO: 30epoch:train:1156-1232batch: iter_time=5.089e-05, forward_time=0.052, loss_ctc=81.400, loss=81.400, backward_time=0.056, grad_norm=51.870, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.005, optim0_lr0=2.852e-04, train_time=0.152
[lambda-Lambda-Vector] 2025-04-01 20:09:13,202 (trainer:779) INFO: 30epoch:train:1233-1309batch: iter_time=4.905e-05, forward_time=0.053, loss_ctc=99.400, loss=99.400, backward_time=0.058, grad_norm=62.067, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.005, optim0_lr0=2.849e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 20:09:25,609 (trainer:779) INFO: 30epoch:train:1310-1386batch: iter_time=5.002e-05, forward_time=0.055, loss_ctc=118.111, loss=118.111, backward_time=0.060, grad_norm=68.476, clip=98.701, loss_scale=5.498e+11, optim_step_time=0.005, optim0_lr0=2.847e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 20:09:37,917 (trainer:779) INFO: 30epoch:train:1387-1463batch: iter_time=5.045e-05, forward_time=0.054, loss_ctc=102.440, loss=102.440, backward_time=0.059, grad_norm=73.253, clip=96.104, loss_scale=5.498e+11, optim_step_time=0.005, optim0_lr0=2.844e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 20:09:49,790 (trainer:779) INFO: 30epoch:train:1464-1540batch: iter_time=5.105e-05, forward_time=0.053, loss_ctc=91.326, loss=91.326, backward_time=0.057, grad_norm=67.302, clip=98.701, loss_scale=5.498e+11, optim_step_time=0.005, optim0_lr0=2.842e-04, train_time=0.154
[lambda-Lambda-Vector] 2025-04-01 20:10:37,335 (trainer:365) INFO: 30epoch results: [train] iter_time=8.669e-05, forward_time=0.054, loss_ctc=103.354, loss=103.354, backward_time=0.058, grad_norm=72.272, clip=99.354, loss_scale=3.583e+11, optim_step_time=0.005, optim0_lr0=2.865e-04, train_time=0.159, time=4 minutes and 6.39 seconds, total_count=46470, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=116.132, cer_ctc=0.938, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=116.132, time=45.9 seconds, total_count=9570, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 20:10:38,957 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 20:10:38,972 (trainer:487) INFO: The model files were removed: exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/29epoch.pth
[lambda-Lambda-Vector] 2025-04-01 20:10:38,973 (trainer:299) INFO: 31/70epoch started. Estimated time to finish: 3 hours, 32 minutes and 14.1 seconds
[lambda-Lambda-Vector] 2025-04-01 20:10:51,830 (trainer:779) INFO: 31epoch:train:1-77batch: iter_time=8.325e-04, forward_time=0.054, loss_ctc=88.247, loss=88.247, backward_time=0.057, grad_norm=52.286, clip=94.805, loss_scale=5.498e+11, optim_step_time=0.006, optim0_lr0=2.840e-04, train_time=0.167
[lambda-Lambda-Vector] 2025-04-01 20:11:04,136 (trainer:779) INFO: 31epoch:train:78-154batch: iter_time=7.141e-05, forward_time=0.055, loss_ctc=86.412, loss=86.412, backward_time=0.058, grad_norm=46.462, clip=97.403, loss_scale=5.498e+11, optim_step_time=0.006, optim0_lr0=2.837e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 20:11:17,621 (trainer:779) INFO: 31epoch:train:155-231batch: iter_time=6.112e-05, forward_time=0.055, loss_ctc=123.995, loss=123.995, backward_time=0.060, grad_norm=56.325, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.005, optim0_lr0=2.835e-04, train_time=0.175
[lambda-Lambda-Vector] 2025-04-01 20:11:29,772 (trainer:779) INFO: 31epoch:train:232-308batch: iter_time=5.559e-05, forward_time=0.054, loss_ctc=101.943, loss=101.943, backward_time=0.058, grad_norm=51.741, clip=98.701, loss_scale=5.498e+11, optim_step_time=0.005, optim0_lr0=2.832e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 20:11:41,770 (trainer:779) INFO: 31epoch:train:309-385batch: iter_time=5.402e-05, forward_time=0.053, loss_ctc=101.607, loss=101.607, backward_time=0.057, grad_norm=56.900, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.005, optim0_lr0=2.830e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 20:11:53,891 (trainer:779) INFO: 31epoch:train:386-462batch: iter_time=5.447e-05, forward_time=0.054, loss_ctc=88.591, loss=88.591, backward_time=0.058, grad_norm=69.282, clip=96.104, loss_scale=5.498e+11, optim_step_time=0.005, optim0_lr0=2.828e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 20:12:06,151 (trainer:779) INFO: 31epoch:train:463-539batch: iter_time=5.490e-05, forward_time=0.054, loss_ctc=101.731, loss=101.731, backward_time=0.059, grad_norm=67.760, clip=98.701, loss_scale=5.498e+11, optim_step_time=0.005, optim0_lr0=2.826e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 20:12:18,309 (trainer:779) INFO: 31epoch:train:540-616batch: iter_time=5.374e-05, forward_time=0.053, loss_ctc=121.745, loss=121.745, backward_time=0.058, grad_norm=66.061, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.005, optim0_lr0=2.823e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 20:12:33,087 (trainer:779) INFO: 31epoch:train:617-693batch: iter_time=6.304e-05, forward_time=0.065, loss_ctc=105.071, loss=105.071, backward_time=0.070, grad_norm=102.538, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.006, optim0_lr0=2.821e-04, train_time=0.192
[lambda-Lambda-Vector] 2025-04-01 20:12:49,796 (trainer:779) INFO: 31epoch:train:694-770batch: iter_time=6.594e-05, forward_time=0.074, loss_ctc=100.474, loss=100.474, backward_time=0.081, grad_norm=76.091, clip=97.403, loss_scale=5.498e+11, optim_step_time=0.006, optim0_lr0=2.819e-04, train_time=0.217
[lambda-Lambda-Vector] 2025-04-01 20:13:07,669 (trainer:779) INFO: 31epoch:train:771-847batch: iter_time=6.505e-05, forward_time=0.080, loss_ctc=109.529, loss=109.529, backward_time=0.083, grad_norm=63.716, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.006, optim0_lr0=2.816e-04, train_time=0.232
[lambda-Lambda-Vector] 2025-04-01 20:13:24,571 (trainer:779) INFO: 31epoch:train:848-924batch: iter_time=6.466e-05, forward_time=0.078, loss_ctc=103.102, loss=103.102, backward_time=0.074, grad_norm=96.420, clip=98.701, loss_scale=5.498e+11, optim_step_time=0.006, optim0_lr0=2.814e-04, train_time=0.219
[lambda-Lambda-Vector] 2025-04-01 20:13:42,390 (trainer:779) INFO: 31epoch:train:925-1001batch: iter_time=6.410e-05, forward_time=0.081, loss_ctc=106.810, loss=106.810, backward_time=0.081, grad_norm=87.529, clip=97.403, loss_scale=5.498e+11, optim_step_time=0.006, optim0_lr0=2.812e-04, train_time=0.231
[lambda-Lambda-Vector] 2025-04-01 20:13:59,227 (trainer:779) INFO: 31epoch:train:1002-1078batch: iter_time=6.937e-05, forward_time=0.076, loss_ctc=94.338, loss=94.338, backward_time=0.080, grad_norm=72.276, clip=96.104, loss_scale=5.498e+11, optim_step_time=0.006, optim0_lr0=2.809e-04, train_time=0.219
[lambda-Lambda-Vector] 2025-04-01 20:14:15,255 (trainer:779) INFO: 31epoch:train:1079-1155batch: iter_time=6.711e-05, forward_time=0.074, loss_ctc=107.435, loss=107.435, backward_time=0.077, grad_norm=74.322, clip=97.403, loss_scale=5.498e+11, optim_step_time=0.006, optim0_lr0=2.807e-04, train_time=0.208
[lambda-Lambda-Vector] 2025-04-01 20:14:30,692 (trainer:779) INFO: 31epoch:train:1156-1232batch: iter_time=6.375e-05, forward_time=0.068, loss_ctc=120.442, loss=120.442, backward_time=0.071, grad_norm=97.142, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.006, optim0_lr0=2.805e-04, train_time=0.200
[lambda-Lambda-Vector] 2025-04-01 20:14:47,652 (trainer:779) INFO: 31epoch:train:1233-1309batch: iter_time=6.531e-05, forward_time=0.074, loss_ctc=127.748, loss=127.748, backward_time=0.081, grad_norm=74.400, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.006, optim0_lr0=2.803e-04, train_time=0.220
[lambda-Lambda-Vector] 2025-04-01 20:15:04,121 (trainer:779) INFO: 31epoch:train:1310-1386batch: iter_time=6.767e-05, forward_time=0.082, loss_ctc=102.980, loss=102.980, backward_time=0.073, grad_norm=52.635, clip=98.701, loss_scale=5.498e+11, optim_step_time=0.006, optim0_lr0=2.800e-04, train_time=0.214
[lambda-Lambda-Vector] 2025-04-01 20:15:20,513 (trainer:779) INFO: 31epoch:train:1387-1463batch: iter_time=6.599e-05, forward_time=0.072, loss_ctc=115.045, loss=115.045, backward_time=0.079, grad_norm=60.130, clip=98.701, loss_scale=5.498e+11, optim_step_time=0.006, optim0_lr0=2.798e-04, train_time=0.213
[lambda-Lambda-Vector] 2025-04-01 20:15:36,394 (trainer:779) INFO: 31epoch:train:1464-1540batch: iter_time=6.526e-05, forward_time=0.073, loss_ctc=85.577, loss=85.577, backward_time=0.075, grad_norm=65.955, clip=96.104, loss_scale=6.212e+11, optim_step_time=0.006, optim0_lr0=2.796e-04, train_time=0.206
[lambda-Lambda-Vector] 2025-04-01 20:16:38,126 (trainer:365) INFO: 31epoch results: [train] iter_time=1.009e-04, forward_time=0.066, loss_ctc=103.354, loss=103.354, backward_time=0.070, grad_norm=69.564, clip=98.321, loss_scale=5.565e+11, optim_step_time=0.006, optim0_lr0=2.817e-04, train_time=0.193, time=4 minutes and 59.61 seconds, total_count=48019, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=113.213, cer_ctc=0.937, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=113.213, time=59.54 seconds, total_count=9889, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 20:16:39,893 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 20:16:39,908 (trainer:487) INFO: The model files were removed: exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/30epoch.pth
[lambda-Lambda-Vector] 2025-04-01 20:16:39,909 (trainer:299) INFO: 32/70epoch started. Estimated time to finish: 3 hours, 27 minutes and 49.32 seconds
[lambda-Lambda-Vector] 2025-04-01 20:16:56,319 (trainer:779) INFO: 32epoch:train:1-77batch: iter_time=5.964e-04, forward_time=0.068, loss_ctc=96.098, loss=96.098, backward_time=0.076, grad_norm=56.759, clip=97.403, loss_scale=1.100e+12, optim_step_time=0.006, optim0_lr0=2.793e-04, train_time=0.213
[lambda-Lambda-Vector] 2025-04-01 20:17:12,409 (trainer:779) INFO: 32epoch:train:78-154batch: iter_time=7.022e-05, forward_time=0.071, loss_ctc=99.269, loss=99.269, backward_time=0.075, grad_norm=65.431, clip=98.701, loss_scale=1.100e+12, optim_step_time=0.006, optim0_lr0=2.791e-04, train_time=0.209
[lambda-Lambda-Vector] 2025-04-01 20:17:29,829 (trainer:779) INFO: 32epoch:train:155-231batch: iter_time=7.060e-05, forward_time=0.076, loss_ctc=109.289, loss=109.289, backward_time=0.083, grad_norm=70.477, clip=100.000, loss_scale=1.100e+12, optim_step_time=0.006, optim0_lr0=2.789e-04, train_time=0.226
[lambda-Lambda-Vector] 2025-04-01 20:17:47,526 (trainer:779) INFO: 32epoch:train:232-308batch: iter_time=7.076e-05, forward_time=0.079, loss_ctc=108.692, loss=108.692, backward_time=0.083, grad_norm=66.878, clip=98.701, loss_scale=1.100e+12, optim_step_time=0.006, optim0_lr0=2.787e-04, train_time=0.230
[lambda-Lambda-Vector] 2025-04-01 20:18:04,615 (trainer:779) INFO: 32epoch:train:309-385batch: iter_time=6.921e-05, forward_time=0.079, loss_ctc=103.074, loss=103.074, backward_time=0.076, grad_norm=74.620, clip=98.701, loss_scale=1.100e+12, optim_step_time=0.006, optim0_lr0=2.784e-04, train_time=0.222
[lambda-Lambda-Vector] 2025-04-01 20:18:22,320 (trainer:779) INFO: 32epoch:train:386-462batch: iter_time=6.874e-05, forward_time=0.083, loss_ctc=109.098, loss=109.098, backward_time=0.083, grad_norm=100.125, clip=97.403, loss_scale=1.100e+12, optim_step_time=0.006, optim0_lr0=2.782e-04, train_time=0.230
[lambda-Lambda-Vector] 2025-04-01 20:18:38,172 (trainer:779) INFO: 32epoch:train:463-539batch: iter_time=6.825e-05, forward_time=0.070, loss_ctc=118.983, loss=118.983, backward_time=0.075, grad_norm=87.857, clip=100.000, loss_scale=1.100e+12, optim_step_time=0.006, optim0_lr0=2.780e-04, train_time=0.206
[lambda-Lambda-Vector] 2025-04-01 20:18:53,734 (trainer:779) INFO: 32epoch:train:540-616batch: iter_time=6.916e-05, forward_time=0.070, loss_ctc=98.744, loss=98.744, backward_time=0.074, grad_norm=68.217, clip=97.403, loss_scale=1.100e+12, optim_step_time=0.006, optim0_lr0=2.778e-04, train_time=0.202
[lambda-Lambda-Vector] 2025-04-01 20:19:10,711 (trainer:779) INFO: 32epoch:train:617-693batch: iter_time=7.097e-05, forward_time=0.077, loss_ctc=105.371, loss=105.371, backward_time=0.081, grad_norm=78.595, clip=98.701, loss_scale=1.100e+12, optim_step_time=0.006, optim0_lr0=2.776e-04, train_time=0.220
[lambda-Lambda-Vector] 2025-04-01 20:19:27,309 (trainer:779) INFO: 32epoch:train:694-770batch: iter_time=6.969e-05, forward_time=0.075, loss_ctc=96.618, loss=96.618, backward_time=0.078, grad_norm=73.325, clip=96.104, loss_scale=1.100e+12, optim_step_time=0.006, optim0_lr0=2.773e-04, train_time=0.215
[lambda-Lambda-Vector] 2025-04-01 20:19:43,326 (trainer:779) INFO: 32epoch:train:771-847batch: iter_time=6.697e-05, forward_time=0.074, loss_ctc=91.758, loss=91.758, backward_time=0.073, grad_norm=84.632, clip=94.805, loss_scale=1.100e+12, optim_step_time=0.006, optim0_lr0=2.771e-04, train_time=0.208
[lambda-Lambda-Vector] 2025-04-01 20:20:00,893 (trainer:779) INFO: 32epoch:train:848-924batch: iter_time=6.798e-05, forward_time=0.071, loss_ctc=95.046, loss=95.046, backward_time=0.079, grad_norm=71.775, clip=97.403, loss_scale=1.100e+12, optim_step_time=0.006, optim0_lr0=2.769e-04, train_time=0.228
[lambda-Lambda-Vector] 2025-04-01 20:20:17,256 (trainer:779) INFO: 32epoch:train:925-1001batch: iter_time=7.620e-05, forward_time=0.077, loss_ctc=102.302, loss=102.302, backward_time=0.074, grad_norm=67.959, clip=96.104, loss_scale=1.100e+12, optim_step_time=0.006, optim0_lr0=2.767e-04, train_time=0.212
[lambda-Lambda-Vector] 2025-04-01 20:20:33,424 (trainer:779) INFO: 32epoch:train:1002-1078batch: iter_time=6.816e-05, forward_time=0.072, loss_ctc=85.760, loss=85.760, backward_time=0.073, grad_norm=59.320, clip=94.805, loss_scale=1.100e+12, optim_step_time=0.006, optim0_lr0=2.765e-04, train_time=0.210
[lambda-Lambda-Vector] 2025-04-01 20:20:50,372 (trainer:779) INFO: 32epoch:train:1079-1155batch: iter_time=6.836e-05, forward_time=0.074, loss_ctc=139.873, loss=139.873, backward_time=0.082, grad_norm=97.087, clip=100.000, loss_scale=1.100e+12, optim_step_time=0.006, optim0_lr0=2.763e-04, train_time=0.220
[lambda-Lambda-Vector] 2025-04-01 20:21:06,839 (trainer:779) INFO: 32epoch:train:1156-1232batch: iter_time=6.721e-05, forward_time=0.075, loss_ctc=97.128, loss=97.128, backward_time=0.076, grad_norm=84.852, clip=98.701, loss_scale=1.100e+12, optim_step_time=0.006, optim0_lr0=2.760e-04, train_time=0.214
[lambda-Lambda-Vector] 2025-04-01 20:21:22,779 (trainer:779) INFO: 32epoch:train:1233-1309batch: iter_time=7.228e-05, forward_time=0.070, loss_ctc=106.844, loss=106.844, backward_time=0.076, grad_norm=66.254, clip=97.403, loss_scale=1.100e+12, optim_step_time=0.006, optim0_lr0=2.758e-04, train_time=0.207
[lambda-Lambda-Vector] 2025-04-01 20:21:40,505 (trainer:779) INFO: 32epoch:train:1310-1386batch: iter_time=7.451e-05, forward_time=0.078, loss_ctc=95.784, loss=95.784, backward_time=0.082, grad_norm=51.838, clip=97.403, loss_scale=1.100e+12, optim_step_time=0.006, optim0_lr0=2.756e-04, train_time=0.230
[lambda-Lambda-Vector] 2025-04-01 20:22:00,001 (trainer:779) INFO: 32epoch:train:1387-1463batch: iter_time=7.528e-05, forward_time=0.085, loss_ctc=99.647, loss=99.647, backward_time=0.094, grad_norm=54.279, clip=98.701, loss_scale=1.100e+12, optim_step_time=0.007, optim0_lr0=2.754e-04, train_time=0.253
[lambda-Lambda-Vector] 2025-04-01 20:22:20,083 (trainer:779) INFO: 32epoch:train:1464-1540batch: iter_time=6.715e-05, forward_time=0.096, loss_ctc=129.890, loss=129.890, backward_time=0.090, grad_norm=81.226, clip=100.000, loss_scale=1.100e+12, optim_step_time=0.006, optim0_lr0=2.752e-04, train_time=0.261
[lambda-Lambda-Vector] 2025-04-01 20:23:24,657 (trainer:365) INFO: 32epoch results: [train] iter_time=9.618e-05, forward_time=0.076, loss_ctc=103.148, loss=103.148, backward_time=0.079, grad_norm=73.140, clip=97.934, loss_scale=1.100e+12, optim_step_time=0.006, optim0_lr0=2.772e-04, train_time=0.221, time=5 minutes and 43.03 seconds, total_count=49568, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=110.485, cer_ctc=0.943, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=110.485, time=1 minute and 1.71 seconds, total_count=10208, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 20:23:27,473 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 20:23:27,489 (trainer:487) INFO: The model files were removed: exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/31epoch.pth
[lambda-Lambda-Vector] 2025-04-01 20:23:27,490 (trainer:299) INFO: 33/70epoch started. Estimated time to finish: 3 hours, 24 minutes and 13.92 seconds
[lambda-Lambda-Vector] 2025-04-01 20:23:45,817 (trainer:779) INFO: 33epoch:train:1-77batch: iter_time=8.407e-04, forward_time=0.079, loss_ctc=118.273, loss=118.273, backward_time=0.080, grad_norm=74.830, clip=98.701, loss_scale=1.100e+12, optim_step_time=0.006, optim0_lr0=2.749e-04, train_time=0.238
[lambda-Lambda-Vector] 2025-04-01 20:24:02,658 (trainer:779) INFO: 33epoch:train:78-154batch: iter_time=7.506e-05, forward_time=0.075, loss_ctc=101.771, loss=101.771, backward_time=0.080, grad_norm=72.669, clip=98.701, loss_scale=1.100e+12, optim_step_time=0.006, optim0_lr0=2.747e-04, train_time=0.219
[lambda-Lambda-Vector] 2025-04-01 20:24:20,399 (trainer:779) INFO: 33epoch:train:155-231batch: iter_time=7.230e-05, forward_time=0.082, loss_ctc=95.194, loss=95.194, backward_time=0.081, grad_norm=52.192, clip=100.000, loss_scale=1.100e+12, optim_step_time=0.006, optim0_lr0=2.745e-04, train_time=0.230
[lambda-Lambda-Vector] 2025-04-01 20:24:38,357 (trainer:779) INFO: 33epoch:train:232-308batch: iter_time=6.872e-05, forward_time=0.079, loss_ctc=117.844, loss=117.844, backward_time=0.083, grad_norm=59.989, clip=100.000, loss_scale=1.100e+12, optim_step_time=0.006, optim0_lr0=2.743e-04, train_time=0.233
[lambda-Lambda-Vector] 2025-04-01 20:24:56,040 (trainer:779) INFO: 33epoch:train:309-385batch: iter_time=7.016e-05, forward_time=0.081, loss_ctc=95.005, loss=95.005, backward_time=0.082, grad_norm=46.567, clip=94.805, loss_scale=1.100e+12, optim_step_time=0.006, optim0_lr0=2.741e-04, train_time=0.230
[lambda-Lambda-Vector] 2025-04-01 20:25:13,604 (trainer:779) INFO: 33epoch:train:386-462batch: iter_time=7.071e-05, forward_time=0.086, loss_ctc=108.181, loss=108.181, backward_time=0.080, grad_norm=54.150, clip=98.701, loss_scale=1.528e+12, optim_step_time=0.006, optim0_lr0=2.739e-04, train_time=0.228
[lambda-Lambda-Vector] 2025-04-01 20:25:31,125 (trainer:779) INFO: 33epoch:train:463-539batch: iter_time=6.951e-05, forward_time=0.079, loss_ctc=83.888, loss=83.888, backward_time=0.082, grad_norm=47.897, clip=96.104, loss_scale=2.199e+12, optim_step_time=0.006, optim0_lr0=2.737e-04, train_time=0.227
[lambda-Lambda-Vector] 2025-04-01 20:25:49,768 (trainer:779) INFO: 33epoch:train:540-616batch: iter_time=6.903e-05, forward_time=0.082, loss_ctc=104.223, loss=104.223, backward_time=0.089, grad_norm=47.414, clip=98.701, loss_scale=2.199e+12, optim_step_time=0.006, optim0_lr0=2.735e-04, train_time=0.242
[lambda-Lambda-Vector] 2025-04-01 20:26:07,614 (trainer:779) INFO: 33epoch:train:617-693batch: iter_time=6.976e-05, forward_time=0.078, loss_ctc=104.247, loss=104.247, backward_time=0.085, grad_norm=59.689, clip=98.701, loss_scale=2.199e+12, optim_step_time=0.006, optim0_lr0=2.732e-04, train_time=0.232
[lambda-Lambda-Vector] 2025-04-01 20:26:23,696 (trainer:779) INFO: 33epoch:train:694-770batch: iter_time=7.171e-05, forward_time=0.075, loss_ctc=92.983, loss=92.983, backward_time=0.073, grad_norm=50.462, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.006, optim0_lr0=2.730e-04, train_time=0.209
[lambda-Lambda-Vector] 2025-04-01 20:26:40,341 (trainer:779) INFO: 33epoch:train:771-847batch: iter_time=7.017e-05, forward_time=0.075, loss_ctc=93.783, loss=93.783, backward_time=0.078, grad_norm=46.404, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.006, optim0_lr0=2.728e-04, train_time=0.216
[lambda-Lambda-Vector] 2025-04-01 20:26:57,403 (trainer:779) INFO: 33epoch:train:848-924batch: iter_time=6.932e-05, forward_time=0.075, loss_ctc=99.287, loss=99.287, backward_time=0.081, grad_norm=48.450, clip=98.701, loss_scale=2.199e+12, optim_step_time=0.006, optim0_lr0=2.726e-04, train_time=0.221
[lambda-Lambda-Vector] 2025-04-01 20:27:14,580 (trainer:779) INFO: 33epoch:train:925-1001batch: iter_time=6.411e-05, forward_time=0.073, loss_ctc=120.873, loss=120.873, backward_time=0.087, grad_norm=55.784, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.006, optim0_lr0=2.724e-04, train_time=0.223
[lambda-Lambda-Vector] 2025-04-01 20:27:31,321 (trainer:779) INFO: 33epoch:train:1002-1078batch: iter_time=6.758e-05, forward_time=0.071, loss_ctc=96.205, loss=96.205, backward_time=0.083, grad_norm=63.608, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.006, optim0_lr0=2.722e-04, train_time=0.217
[lambda-Lambda-Vector] 2025-04-01 20:27:47,304 (trainer:779) INFO: 33epoch:train:1079-1155batch: iter_time=6.696e-05, forward_time=0.068, loss_ctc=82.974, loss=82.974, backward_time=0.075, grad_norm=50.076, clip=96.104, loss_scale=2.199e+12, optim_step_time=0.006, optim0_lr0=2.720e-04, train_time=0.207
[lambda-Lambda-Vector] 2025-04-01 20:28:05,985 (trainer:779) INFO: 33epoch:train:1156-1232batch: iter_time=6.884e-05, forward_time=0.088, loss_ctc=100.116, loss=100.116, backward_time=0.084, grad_norm=53.103, clip=97.403, loss_scale=2.199e+12, optim_step_time=0.006, optim0_lr0=2.718e-04, train_time=0.243
[lambda-Lambda-Vector] 2025-04-01 20:28:24,270 (trainer:779) INFO: 33epoch:train:1233-1309batch: iter_time=6.615e-05, forward_time=0.088, loss_ctc=119.880, loss=119.880, backward_time=0.083, grad_norm=54.884, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.006, optim0_lr0=2.716e-04, train_time=0.237
[lambda-Lambda-Vector] 2025-04-01 20:28:41,535 (trainer:779) INFO: 33epoch:train:1310-1386batch: iter_time=6.657e-05, forward_time=0.074, loss_ctc=110.116, loss=110.116, backward_time=0.082, grad_norm=64.909, clip=98.701, loss_scale=2.199e+12, optim_step_time=0.006, optim0_lr0=2.714e-04, train_time=0.224
[lambda-Lambda-Vector] 2025-04-01 20:28:59,943 (trainer:779) INFO: 33epoch:train:1387-1463batch: iter_time=6.667e-05, forward_time=0.084, loss_ctc=131.244, loss=131.244, backward_time=0.085, grad_norm=68.351, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.006, optim0_lr0=2.712e-04, train_time=0.239
[lambda-Lambda-Vector] 2025-04-01 20:29:18,382 (trainer:779) INFO: 33epoch:train:1464-1540batch: iter_time=6.708e-05, forward_time=0.081, loss_ctc=118.921, loss=118.921, backward_time=0.087, grad_norm=54.809, clip=97.403, loss_scale=2.199e+12, optim_step_time=0.006, optim0_lr0=2.710e-04, train_time=0.239
[lambda-Lambda-Vector] 2025-04-01 20:30:24,312 (trainer:365) INFO: 33epoch results: [train] iter_time=1.072e-04, forward_time=0.079, loss_ctc=103.401, loss=103.401, backward_time=0.082, grad_norm=56.561, clip=98.644, loss_scale=1.892e+12, optim_step_time=0.006, optim0_lr0=2.729e-04, train_time=0.228, time=5 minutes and 53.42 seconds, total_count=51117, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=113.956, cer_ctc=0.942, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=113.956, time=1 minute and 3.4 seconds, total_count=10527, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 20:30:26,052 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 20:30:26,069 (trainer:487) INFO: The model files were removed: exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/32epoch.pth
[lambda-Lambda-Vector] 2025-04-01 20:30:26,069 (trainer:299) INFO: 34/70epoch started. Estimated time to finish: 3 hours, 20 minutes and 39.21 seconds
[lambda-Lambda-Vector] 2025-04-01 20:30:44,699 (trainer:779) INFO: 34epoch:train:1-77batch: iter_time=6.306e-04, forward_time=0.079, loss_ctc=115.295, loss=115.295, backward_time=0.085, grad_norm=44.990, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.006, optim0_lr0=2.707e-04, train_time=0.242
[lambda-Lambda-Vector] 2025-04-01 20:31:02,909 (trainer:779) INFO: 34epoch:train:78-154batch: iter_time=6.852e-05, forward_time=0.081, loss_ctc=110.458, loss=110.458, backward_time=0.085, grad_norm=55.979, clip=98.701, loss_scale=2.199e+12, optim_step_time=0.006, optim0_lr0=2.705e-04, train_time=0.236
[lambda-Lambda-Vector] 2025-04-01 20:31:20,571 (trainer:779) INFO: 34epoch:train:155-231batch: iter_time=6.766e-05, forward_time=0.071, loss_ctc=94.949, loss=94.949, backward_time=0.088, grad_norm=44.990, clip=98.701, loss_scale=2.199e+12, optim_step_time=0.006, optim0_lr0=2.703e-04, train_time=0.229
[lambda-Lambda-Vector] 2025-04-01 20:31:38,384 (trainer:779) INFO: 34epoch:train:232-308batch: iter_time=6.692e-05, forward_time=0.080, loss_ctc=114.560, loss=114.560, backward_time=0.084, grad_norm=56.039, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.006, optim0_lr0=2.701e-04, train_time=0.231
[lambda-Lambda-Vector] 2025-04-01 20:31:56,188 (trainer:779) INFO: 34epoch:train:309-385batch: iter_time=6.863e-05, forward_time=0.081, loss_ctc=100.456, loss=100.456, backward_time=0.082, grad_norm=69.250, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.006, optim0_lr0=2.699e-04, train_time=0.231
[lambda-Lambda-Vector] 2025-04-01 20:32:14,432 (trainer:779) INFO: 34epoch:train:386-462batch: iter_time=6.559e-05, forward_time=0.083, loss_ctc=121.329, loss=121.329, backward_time=0.085, grad_norm=78.179, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.006, optim0_lr0=2.697e-04, train_time=0.237
[lambda-Lambda-Vector] 2025-04-01 20:32:27,959 (trainer:779) INFO: 34epoch:train:463-539batch: iter_time=5.901e-05, forward_time=0.060, loss_ctc=123.546, loss=123.546, backward_time=0.064, grad_norm=72.236, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.005, optim0_lr0=2.695e-04, train_time=0.176
[lambda-Lambda-Vector] 2025-04-01 20:32:40,312 (trainer:779) INFO: 34epoch:train:540-616batch: iter_time=5.560e-05, forward_time=0.055, loss_ctc=98.207, loss=98.207, backward_time=0.059, grad_norm=66.326, clip=98.701, loss_scale=2.199e+12, optim_step_time=0.005, optim0_lr0=2.693e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 20:32:53,573 (trainer:779) INFO: 34epoch:train:617-693batch: iter_time=5.546e-05, forward_time=0.055, loss_ctc=94.764, loss=94.764, backward_time=0.059, grad_norm=71.203, clip=97.403, loss_scale=2.199e+12, optim_step_time=0.005, optim0_lr0=2.691e-04, train_time=0.172
[lambda-Lambda-Vector] 2025-04-01 20:33:05,321 (trainer:779) INFO: 34epoch:train:694-770batch: iter_time=5.639e-05, forward_time=0.052, loss_ctc=89.759, loss=89.759, backward_time=0.056, grad_norm=49.303, clip=98.701, loss_scale=2.199e+12, optim_step_time=0.005, optim0_lr0=2.689e-04, train_time=0.152
[lambda-Lambda-Vector] 2025-04-01 20:33:17,748 (trainer:779) INFO: 34epoch:train:771-847batch: iter_time=5.531e-05, forward_time=0.055, loss_ctc=112.720, loss=112.720, backward_time=0.060, grad_norm=61.950, clip=97.403, loss_scale=2.199e+12, optim_step_time=0.005, optim0_lr0=2.687e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 20:33:30,234 (trainer:779) INFO: 34epoch:train:848-924batch: iter_time=5.525e-05, forward_time=0.055, loss_ctc=101.614, loss=101.614, backward_time=0.060, grad_norm=66.884, clip=97.403, loss_scale=3.370e+12, optim_step_time=0.005, optim0_lr0=2.685e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 20:33:42,458 (trainer:779) INFO: 34epoch:train:925-1001batch: iter_time=5.477e-05, forward_time=0.054, loss_ctc=114.095, loss=114.095, backward_time=0.059, grad_norm=60.076, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.005, optim0_lr0=2.683e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 20:33:54,081 (trainer:779) INFO: 34epoch:train:1002-1078batch: iter_time=5.477e-05, forward_time=0.052, loss_ctc=81.831, loss=81.831, backward_time=0.056, grad_norm=50.176, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.005, optim0_lr0=2.681e-04, train_time=0.151
[lambda-Lambda-Vector] 2025-04-01 20:34:06,424 (trainer:779) INFO: 34epoch:train:1079-1155batch: iter_time=5.433e-05, forward_time=0.054, loss_ctc=113.977, loss=113.977, backward_time=0.060, grad_norm=57.141, clip=98.701, loss_scale=4.398e+12, optim_step_time=0.005, optim0_lr0=2.679e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 20:34:18,452 (trainer:779) INFO: 34epoch:train:1156-1232batch: iter_time=5.439e-05, forward_time=0.053, loss_ctc=87.035, loss=87.035, backward_time=0.058, grad_norm=47.463, clip=98.701, loss_scale=4.398e+12, optim_step_time=0.005, optim0_lr0=2.677e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 20:34:30,629 (trainer:779) INFO: 34epoch:train:1233-1309batch: iter_time=5.377e-05, forward_time=0.054, loss_ctc=96.082, loss=96.082, backward_time=0.059, grad_norm=59.876, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.005, optim0_lr0=2.675e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 20:34:42,835 (trainer:779) INFO: 34epoch:train:1310-1386batch: iter_time=5.481e-05, forward_time=0.054, loss_ctc=90.000, loss=90.000, backward_time=0.059, grad_norm=52.100, clip=97.403, loss_scale=4.398e+12, optim_step_time=0.005, optim0_lr0=2.673e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 20:34:55,096 (trainer:779) INFO: 34epoch:train:1387-1463batch: iter_time=5.499e-05, forward_time=0.054, loss_ctc=105.736, loss=105.736, backward_time=0.059, grad_norm=47.475, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.005, optim0_lr0=2.672e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 20:35:07,785 (trainer:779) INFO: 34epoch:train:1464-1540batch: iter_time=5.361e-05, forward_time=0.056, loss_ctc=136.897, loss=136.897, backward_time=0.061, grad_norm=59.804, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.005, optim0_lr0=2.670e-04, train_time=0.165
[lambda-Lambda-Vector] 2025-04-01 20:35:54,704 (trainer:365) INFO: 34epoch results: [train] iter_time=8.677e-05, forward_time=0.062, loss_ctc=103.188, loss=103.188, backward_time=0.067, grad_norm=58.457, clip=99.096, loss_scale=3.145e+12, optim_step_time=0.005, optim0_lr0=2.688e-04, train_time=0.183, time=4 minutes and 43.4 seconds, total_count=52666, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=116.646, cer_ctc=0.940, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=116.646, time=45.23 seconds, total_count=10846, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 20:35:57,158 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 20:35:57,174 (trainer:487) INFO: The model files were removed: exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/33epoch.pth
[lambda-Lambda-Vector] 2025-04-01 20:35:57,174 (trainer:299) INFO: 35/70epoch started. Estimated time to finish: 3 hours, 15 minutes and 19.88 seconds
[lambda-Lambda-Vector] 2025-04-01 20:36:09,679 (trainer:779) INFO: 35epoch:train:1-77batch: iter_time=5.809e-04, forward_time=0.052, loss_ctc=87.028, loss=87.028, backward_time=0.056, grad_norm=51.825, clip=96.104, loss_scale=4.398e+12, optim_step_time=0.005, optim0_lr0=2.667e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 20:36:22,262 (trainer:779) INFO: 35epoch:train:78-154batch: iter_time=5.746e-05, forward_time=0.056, loss_ctc=114.949, loss=114.949, backward_time=0.061, grad_norm=78.422, clip=98.701, loss_scale=4.398e+12, optim_step_time=0.005, optim0_lr0=2.665e-04, train_time=0.163
[lambda-Lambda-Vector] 2025-04-01 20:36:34,688 (trainer:779) INFO: 35epoch:train:155-231batch: iter_time=5.627e-05, forward_time=0.055, loss_ctc=111.505, loss=111.505, backward_time=0.060, grad_norm=58.906, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.005, optim0_lr0=2.663e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 20:36:46,932 (trainer:779) INFO: 35epoch:train:232-308batch: iter_time=5.561e-05, forward_time=0.054, loss_ctc=110.666, loss=110.666, backward_time=0.059, grad_norm=58.726, clip=98.701, loss_scale=4.398e+12, optim_step_time=0.005, optim0_lr0=2.662e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 20:36:59,031 (trainer:779) INFO: 35epoch:train:309-385batch: iter_time=5.662e-05, forward_time=0.054, loss_ctc=95.554, loss=95.554, backward_time=0.058, grad_norm=54.706, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.005, optim0_lr0=2.660e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 20:37:11,441 (trainer:779) INFO: 35epoch:train:386-462batch: iter_time=5.647e-05, forward_time=0.055, loss_ctc=109.191, loss=109.191, backward_time=0.060, grad_norm=52.509, clip=98.701, loss_scale=4.398e+12, optim_step_time=0.005, optim0_lr0=2.658e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 20:37:23,670 (trainer:779) INFO: 35epoch:train:463-539batch: iter_time=5.524e-05, forward_time=0.054, loss_ctc=102.287, loss=102.287, backward_time=0.059, grad_norm=52.988, clip=97.403, loss_scale=4.398e+12, optim_step_time=0.005, optim0_lr0=2.656e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 20:37:35,784 (trainer:779) INFO: 35epoch:train:540-616batch: iter_time=5.615e-05, forward_time=0.053, loss_ctc=106.505, loss=106.505, backward_time=0.059, grad_norm=51.049, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.005, optim0_lr0=2.654e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 20:37:48,423 (trainer:779) INFO: 35epoch:train:617-693batch: iter_time=5.565e-05, forward_time=0.056, loss_ctc=112.767, loss=112.767, backward_time=0.061, grad_norm=60.196, clip=98.701, loss_scale=4.398e+12, optim_step_time=0.005, optim0_lr0=2.652e-04, train_time=0.164
[lambda-Lambda-Vector] 2025-04-01 20:38:00,856 (trainer:779) INFO: 35epoch:train:694-770batch: iter_time=5.493e-05, forward_time=0.055, loss_ctc=104.885, loss=104.885, backward_time=0.060, grad_norm=56.033, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.005, optim0_lr0=2.650e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 20:38:13,238 (trainer:779) INFO: 35epoch:train:771-847batch: iter_time=5.472e-05, forward_time=0.055, loss_ctc=109.990, loss=109.990, backward_time=0.060, grad_norm=55.428, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.005, optim0_lr0=2.648e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 20:38:25,655 (trainer:779) INFO: 35epoch:train:848-924batch: iter_time=5.461e-05, forward_time=0.055, loss_ctc=101.730, loss=101.730, backward_time=0.060, grad_norm=52.098, clip=98.701, loss_scale=4.398e+12, optim_step_time=0.005, optim0_lr0=2.646e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 20:38:37,428 (trainer:779) INFO: 35epoch:train:925-1001batch: iter_time=5.521e-05, forward_time=0.052, loss_ctc=92.789, loss=92.789, backward_time=0.057, grad_norm=56.336, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.005, optim0_lr0=2.644e-04, train_time=0.153
[lambda-Lambda-Vector] 2025-04-01 20:38:49,843 (trainer:779) INFO: 35epoch:train:1002-1078batch: iter_time=5.526e-05, forward_time=0.055, loss_ctc=103.403, loss=103.403, backward_time=0.060, grad_norm=70.040, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.005, optim0_lr0=2.642e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 20:39:02,157 (trainer:779) INFO: 35epoch:train:1079-1155batch: iter_time=5.412e-05, forward_time=0.054, loss_ctc=116.083, loss=116.083, backward_time=0.060, grad_norm=72.749, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.005, optim0_lr0=2.641e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 20:39:14,604 (trainer:779) INFO: 35epoch:train:1156-1232batch: iter_time=5.423e-05, forward_time=0.055, loss_ctc=104.093, loss=104.093, backward_time=0.060, grad_norm=54.550, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.005, optim0_lr0=2.639e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 20:39:26,635 (trainer:779) INFO: 35epoch:train:1233-1309batch: iter_time=5.635e-05, forward_time=0.054, loss_ctc=93.364, loss=93.364, backward_time=0.058, grad_norm=52.923, clip=98.701, loss_scale=4.398e+12, optim_step_time=0.005, optim0_lr0=2.637e-04, train_time=0.156
[lambda-Lambda-Vector] 2025-04-01 20:39:38,726 (trainer:779) INFO: 35epoch:train:1310-1386batch: iter_time=5.567e-05, forward_time=0.054, loss_ctc=92.131, loss=92.131, backward_time=0.058, grad_norm=55.138, clip=98.701, loss_scale=7.368e+12, optim_step_time=0.005, optim0_lr0=2.635e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 20:39:51,838 (trainer:779) INFO: 35epoch:train:1387-1463batch: iter_time=5.410e-05, forward_time=0.054, loss_ctc=113.732, loss=113.732, backward_time=0.059, grad_norm=60.788, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.005, optim0_lr0=2.633e-04, train_time=0.170
[lambda-Lambda-Vector] 2025-04-01 20:40:03,631 (trainer:779) INFO: 35epoch:train:1464-1540batch: iter_time=5.517e-05, forward_time=0.052, loss_ctc=94.167, loss=94.167, backward_time=0.057, grad_norm=47.724, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.005, optim0_lr0=2.631e-04, train_time=0.153
[lambda-Lambda-Vector] 2025-04-01 20:40:51,033 (trainer:365) INFO: 35epoch results: [train] iter_time=8.152e-05, forward_time=0.054, loss_ctc=103.000, loss=103.000, backward_time=0.059, grad_norm=57.516, clip=99.225, loss_scale=5.008e+12, optim_step_time=0.005, optim0_lr0=2.649e-04, train_time=0.160, time=4 minutes and 8.11 seconds, total_count=54215, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=112.905, cer_ctc=0.937, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=112.905, time=45.75 seconds, total_count=11165, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 20:40:52,766 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 20:40:52,781 (trainer:487) INFO: The model files were removed: exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/34epoch.pth
[lambda-Lambda-Vector] 2025-04-01 20:40:52,781 (trainer:299) INFO: 36/70epoch started. Estimated time to finish: 3 hours, 9 minutes and 24.38 seconds
[lambda-Lambda-Vector] 2025-04-01 20:41:05,888 (trainer:779) INFO: 36epoch:train:1-77batch: iter_time=5.885e-04, forward_time=0.055, loss_ctc=116.622, loss=116.622, backward_time=0.058, grad_norm=56.310, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.006, optim0_lr0=2.629e-04, train_time=0.170
[lambda-Lambda-Vector] 2025-04-01 20:41:18,189 (trainer:779) INFO: 36epoch:train:78-154batch: iter_time=6.311e-05, forward_time=0.055, loss_ctc=83.244, loss=83.244, backward_time=0.058, grad_norm=55.095, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.005, optim0_lr0=2.627e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 20:41:30,359 (trainer:779) INFO: 36epoch:train:155-231batch: iter_time=6.490e-05, forward_time=0.054, loss_ctc=107.720, loss=107.720, backward_time=0.057, grad_norm=52.300, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.006, optim0_lr0=2.625e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 20:41:42,766 (trainer:779) INFO: 36epoch:train:232-308batch: iter_time=6.095e-05, forward_time=0.055, loss_ctc=102.926, loss=102.926, backward_time=0.059, grad_norm=56.951, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.005, optim0_lr0=2.623e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 20:41:55,125 (trainer:779) INFO: 36epoch:train:309-385batch: iter_time=5.515e-05, forward_time=0.055, loss_ctc=101.161, loss=101.161, backward_time=0.059, grad_norm=61.154, clip=98.701, loss_scale=8.796e+12, optim_step_time=0.005, optim0_lr0=2.622e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 20:42:07,059 (trainer:779) INFO: 36epoch:train:386-462batch: iter_time=5.780e-05, forward_time=0.053, loss_ctc=103.010, loss=103.010, backward_time=0.057, grad_norm=58.917, clip=98.701, loss_scale=8.796e+12, optim_step_time=0.005, optim0_lr0=2.620e-04, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 20:42:19,431 (trainer:779) INFO: 36epoch:train:463-539batch: iter_time=5.478e-05, forward_time=0.055, loss_ctc=117.400, loss=117.400, backward_time=0.059, grad_norm=63.614, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.005, optim0_lr0=2.618e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 20:42:32,875 (trainer:779) INFO: 36epoch:train:540-616batch: iter_time=5.607e-05, forward_time=0.055, loss_ctc=109.373, loss=109.373, backward_time=0.060, grad_norm=58.047, clip=98.701, loss_scale=8.796e+12, optim_step_time=0.005, optim0_lr0=2.616e-04, train_time=0.174
[lambda-Lambda-Vector] 2025-04-01 20:42:45,154 (trainer:779) INFO: 36epoch:train:617-693batch: iter_time=5.599e-05, forward_time=0.054, loss_ctc=113.736, loss=113.736, backward_time=0.059, grad_norm=64.231, clip=98.701, loss_scale=8.796e+12, optim_step_time=0.005, optim0_lr0=2.614e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 20:42:57,289 (trainer:779) INFO: 36epoch:train:694-770batch: iter_time=5.531e-05, forward_time=0.054, loss_ctc=104.300, loss=104.300, backward_time=0.059, grad_norm=54.449, clip=98.701, loss_scale=8.796e+12, optim_step_time=0.005, optim0_lr0=2.612e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 20:43:09,398 (trainer:779) INFO: 36epoch:train:771-847batch: iter_time=5.274e-05, forward_time=0.054, loss_ctc=95.959, loss=95.959, backward_time=0.058, grad_norm=49.142, clip=98.701, loss_scale=8.796e+12, optim_step_time=0.005, optim0_lr0=2.611e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 20:43:21,459 (trainer:779) INFO: 36epoch:train:848-924batch: iter_time=5.103e-05, forward_time=0.053, loss_ctc=92.687, loss=92.687, backward_time=0.058, grad_norm=54.399, clip=97.403, loss_scale=8.796e+12, optim_step_time=0.005, optim0_lr0=2.609e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 20:43:33,703 (trainer:779) INFO: 36epoch:train:925-1001batch: iter_time=5.526e-05, forward_time=0.054, loss_ctc=101.144, loss=101.144, backward_time=0.059, grad_norm=58.413, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.005, optim0_lr0=2.607e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 20:43:45,992 (trainer:779) INFO: 36epoch:train:1002-1078batch: iter_time=5.490e-05, forward_time=0.054, loss_ctc=102.998, loss=102.998, backward_time=0.059, grad_norm=59.351, clip=97.403, loss_scale=8.796e+12, optim_step_time=0.005, optim0_lr0=2.605e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 20:43:58,785 (trainer:779) INFO: 36epoch:train:1079-1155batch: iter_time=5.578e-05, forward_time=0.056, loss_ctc=123.236, loss=123.236, backward_time=0.062, grad_norm=70.617, clip=98.701, loss_scale=8.796e+12, optim_step_time=0.005, optim0_lr0=2.603e-04, train_time=0.166
[lambda-Lambda-Vector] 2025-04-01 20:44:11,115 (trainer:779) INFO: 36epoch:train:1156-1232batch: iter_time=5.433e-05, forward_time=0.055, loss_ctc=100.693, loss=100.693, backward_time=0.059, grad_norm=59.823, clip=98.701, loss_scale=8.796e+12, optim_step_time=0.005, optim0_lr0=2.601e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 20:44:23,024 (trainer:779) INFO: 36epoch:train:1233-1309batch: iter_time=5.579e-05, forward_time=0.053, loss_ctc=95.397, loss=95.397, backward_time=0.057, grad_norm=56.538, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.005, optim0_lr0=2.600e-04, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 20:44:35,263 (trainer:779) INFO: 36epoch:train:1310-1386batch: iter_time=5.574e-05, forward_time=0.054, loss_ctc=97.835, loss=97.835, backward_time=0.059, grad_norm=69.151, clip=98.701, loss_scale=8.796e+12, optim_step_time=0.005, optim0_lr0=2.598e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 20:44:47,357 (trainer:779) INFO: 36epoch:train:1387-1463batch: iter_time=5.523e-05, forward_time=0.053, loss_ctc=105.940, loss=105.940, backward_time=0.058, grad_norm=63.256, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.005, optim0_lr0=2.596e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 20:44:59,561 (trainer:779) INFO: 36epoch:train:1464-1540batch: iter_time=5.453e-05, forward_time=0.054, loss_ctc=99.124, loss=99.124, backward_time=0.059, grad_norm=71.240, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.005, optim0_lr0=2.594e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 20:45:46,644 (trainer:365) INFO: 36epoch results: [train] iter_time=8.266e-05, forward_time=0.054, loss_ctc=102.950, loss=102.950, backward_time=0.059, grad_norm=59.634, clip=99.161, loss_scale=8.796e+12, optim_step_time=0.005, optim0_lr0=2.611e-04, train_time=0.160, time=4 minutes and 8.48 seconds, total_count=55764, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=117.856, cer_ctc=0.943, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=117.856, time=45.38 seconds, total_count=11484, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 20:45:49,241 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 20:45:49,258 (trainer:487) INFO: The model files were removed: exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/35epoch.pth
[lambda-Lambda-Vector] 2025-04-01 20:45:49,258 (trainer:299) INFO: 37/70epoch started. Estimated time to finish: 3 hours, 3 minutes and 33.03 seconds
[lambda-Lambda-Vector] 2025-04-01 20:46:01,985 (trainer:779) INFO: 37epoch:train:1-77batch: iter_time=8.097e-04, forward_time=0.053, loss_ctc=90.525, loss=90.525, backward_time=0.057, grad_norm=52.697, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.005, optim0_lr0=2.592e-04, train_time=0.165
[lambda-Lambda-Vector] 2025-04-01 20:46:14,401 (trainer:779) INFO: 37epoch:train:78-154batch: iter_time=6.019e-05, forward_time=0.055, loss_ctc=114.469, loss=114.469, backward_time=0.059, grad_norm=72.845, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.005, optim0_lr0=2.590e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 20:46:26,768 (trainer:779) INFO: 37epoch:train:155-231batch: iter_time=5.867e-05, forward_time=0.055, loss_ctc=116.565, loss=116.565, backward_time=0.059, grad_norm=66.002, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.005, optim0_lr0=2.589e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 20:46:38,968 (trainer:779) INFO: 37epoch:train:232-308batch: iter_time=5.765e-05, forward_time=0.054, loss_ctc=112.234, loss=112.234, backward_time=0.058, grad_norm=63.576, clip=100.000, loss_scale=1.702e+13, optim_step_time=0.005, optim0_lr0=2.587e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 20:46:51,066 (trainer:779) INFO: 37epoch:train:309-385batch: iter_time=5.753e-05, forward_time=0.054, loss_ctc=108.829, loss=108.829, backward_time=0.058, grad_norm=56.637, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.005, optim0_lr0=2.585e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 20:47:02,910 (trainer:779) INFO: 37epoch:train:386-462batch: iter_time=5.633e-05, forward_time=0.052, loss_ctc=97.046, loss=97.046, backward_time=0.057, grad_norm=46.963, clip=98.701, loss_scale=1.759e+13, optim_step_time=0.005, optim0_lr0=2.583e-04, train_time=0.154
[lambda-Lambda-Vector] 2025-04-01 20:47:15,219 (trainer:779) INFO: 37epoch:train:463-539batch: iter_time=5.632e-05, forward_time=0.055, loss_ctc=104.131, loss=104.131, backward_time=0.059, grad_norm=51.501, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.005, optim0_lr0=2.582e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 20:47:27,390 (trainer:779) INFO: 37epoch:train:540-616batch: iter_time=5.668e-05, forward_time=0.054, loss_ctc=96.554, loss=96.554, backward_time=0.058, grad_norm=57.138, clip=98.701, loss_scale=1.759e+13, optim_step_time=0.005, optim0_lr0=2.580e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 20:47:39,791 (trainer:779) INFO: 37epoch:train:617-693batch: iter_time=5.512e-05, forward_time=0.055, loss_ctc=112.076, loss=112.076, backward_time=0.060, grad_norm=60.617, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.005, optim0_lr0=2.578e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 20:47:52,427 (trainer:779) INFO: 37epoch:train:694-770batch: iter_time=5.511e-05, forward_time=0.056, loss_ctc=107.788, loss=107.788, backward_time=0.061, grad_norm=65.368, clip=98.701, loss_scale=1.759e+13, optim_step_time=0.005, optim0_lr0=2.576e-04, train_time=0.164
[lambda-Lambda-Vector] 2025-04-01 20:48:04,665 (trainer:779) INFO: 37epoch:train:771-847batch: iter_time=5.458e-05, forward_time=0.055, loss_ctc=105.355, loss=105.355, backward_time=0.059, grad_norm=60.916, clip=98.701, loss_scale=1.759e+13, optim_step_time=0.005, optim0_lr0=2.575e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 20:48:17,055 (trainer:779) INFO: 37epoch:train:848-924batch: iter_time=5.603e-05, forward_time=0.055, loss_ctc=92.024, loss=92.024, backward_time=0.059, grad_norm=58.983, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.005, optim0_lr0=2.573e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 20:48:29,185 (trainer:779) INFO: 37epoch:train:925-1001batch: iter_time=5.447e-05, forward_time=0.054, loss_ctc=92.083, loss=92.083, backward_time=0.058, grad_norm=83.421, clip=98.701, loss_scale=1.759e+13, optim_step_time=0.005, optim0_lr0=2.571e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 20:48:41,632 (trainer:779) INFO: 37epoch:train:1002-1078batch: iter_time=5.612e-05, forward_time=0.055, loss_ctc=113.538, loss=113.538, backward_time=0.060, grad_norm=81.347, clip=98.701, loss_scale=1.759e+13, optim_step_time=0.005, optim0_lr0=2.569e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 20:48:53,761 (trainer:779) INFO: 37epoch:train:1079-1155batch: iter_time=5.564e-05, forward_time=0.054, loss_ctc=99.861, loss=99.861, backward_time=0.058, grad_norm=90.532, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.005, optim0_lr0=2.568e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 20:49:06,774 (trainer:779) INFO: 37epoch:train:1156-1232batch: iter_time=5.556e-05, forward_time=0.053, loss_ctc=97.738, loss=97.738, backward_time=0.058, grad_norm=91.552, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.005, optim0_lr0=2.566e-04, train_time=0.169
[lambda-Lambda-Vector] 2025-04-01 20:49:19,212 (trainer:779) INFO: 37epoch:train:1233-1309batch: iter_time=5.515e-05, forward_time=0.055, loss_ctc=101.344, loss=101.344, backward_time=0.060, grad_norm=142.358, clip=98.701, loss_scale=1.759e+13, optim_step_time=0.005, optim0_lr0=2.564e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 20:49:31,682 (trainer:779) INFO: 37epoch:train:1310-1386batch: iter_time=5.431e-05, forward_time=0.055, loss_ctc=111.944, loss=111.944, backward_time=0.060, grad_norm=264.776, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.005, optim0_lr0=2.562e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 20:49:44,132 (trainer:779) INFO: 37epoch:train:1387-1463batch: iter_time=5.397e-05, forward_time=0.055, loss_ctc=104.615, loss=104.615, backward_time=0.060, grad_norm=197.801, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.005, optim0_lr0=2.561e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 20:49:56,219 (trainer:779) INFO: 37epoch:train:1464-1540batch: iter_time=5.378e-05, forward_time=0.054, loss_ctc=90.899, loss=90.899, backward_time=0.058, grad_norm=178.421, clip=98.701, loss_scale=1.759e+13, optim_step_time=0.005, optim0_lr0=2.559e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 20:50:43,306 (trainer:365) INFO: 37epoch results: [train] iter_time=9.338e-05, forward_time=0.054, loss_ctc=103.020, loss=103.020, backward_time=0.059, grad_norm=93.066, clip=99.484, loss_scale=1.625e+13, optim_step_time=0.005, optim0_lr0=2.575e-04, train_time=0.160, time=4 minutes and 8.82 seconds, total_count=57313, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=112.589, cer_ctc=0.940, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=112.589, time=45.22 seconds, total_count=11803, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 20:50:44,992 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 20:50:45,008 (trainer:487) INFO: The model files were removed: exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/36epoch.pth
[lambda-Lambda-Vector] 2025-04-01 20:50:45,008 (trainer:299) INFO: 38/70epoch started. Estimated time to finish: 2 hours, 57 minutes and 44 seconds
[lambda-Lambda-Vector] 2025-04-01 20:50:58,234 (trainer:779) INFO: 38epoch:train:1-77batch: iter_time=7.832e-04, forward_time=0.056, loss_ctc=106.545, loss=106.545, backward_time=0.059, grad_norm=234.136, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.005, optim0_lr0=2.557e-04, train_time=0.172
[lambda-Lambda-Vector] 2025-04-01 20:51:10,890 (trainer:779) INFO: 38epoch:train:78-154batch: iter_time=7.016e-05, forward_time=0.057, loss_ctc=95.832, loss=95.832, backward_time=0.060, grad_norm=224.823, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.006, optim0_lr0=2.555e-04, train_time=0.164
[lambda-Lambda-Vector] 2025-04-01 20:51:23,599 (trainer:779) INFO: 38epoch:train:155-231batch: iter_time=7.074e-05, forward_time=0.057, loss_ctc=102.557, loss=102.557, backward_time=0.060, grad_norm=156.112, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.006, optim0_lr0=2.554e-04, train_time=0.165
[lambda-Lambda-Vector] 2025-04-01 20:51:36,203 (trainer:779) INFO: 38epoch:train:232-308batch: iter_time=7.316e-05, forward_time=0.057, loss_ctc=102.712, loss=102.712, backward_time=0.059, grad_norm=212.729, clip=98.701, loss_scale=1.759e+13, optim_step_time=0.006, optim0_lr0=2.552e-04, train_time=0.164
[lambda-Lambda-Vector] 2025-04-01 20:51:49,466 (trainer:779) INFO: 38epoch:train:309-385batch: iter_time=7.178e-05, forward_time=0.056, loss_ctc=97.627, loss=97.627, backward_time=0.058, grad_norm=143.376, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.006, optim0_lr0=2.550e-04, train_time=0.172
[lambda-Lambda-Vector] 2025-04-01 20:52:01,552 (trainer:779) INFO: 38epoch:train:386-462batch: iter_time=7.371e-05, forward_time=0.054, loss_ctc=101.176, loss=101.176, backward_time=0.057, grad_norm=135.801, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.006, optim0_lr0=2.549e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 20:52:14,019 (trainer:779) INFO: 38epoch:train:463-539batch: iter_time=7.097e-05, forward_time=0.056, loss_ctc=92.713, loss=92.713, backward_time=0.059, grad_norm=132.150, clip=98.701, loss_scale=1.759e+13, optim_step_time=0.006, optim0_lr0=2.547e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 20:52:26,455 (trainer:779) INFO: 38epoch:train:540-616batch: iter_time=6.911e-05, forward_time=0.056, loss_ctc=91.323, loss=91.323, backward_time=0.058, grad_norm=124.699, clip=98.701, loss_scale=1.759e+13, optim_step_time=0.006, optim0_lr0=2.545e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 20:52:38,776 (trainer:779) INFO: 38epoch:train:617-693batch: iter_time=6.007e-05, forward_time=0.055, loss_ctc=113.803, loss=113.803, backward_time=0.059, grad_norm=147.887, clip=100.000, loss_scale=1.896e+13, optim_step_time=0.005, optim0_lr0=2.543e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 20:52:51,270 (trainer:779) INFO: 38epoch:train:694-770batch: iter_time=6.130e-05, forward_time=0.056, loss_ctc=122.543, loss=122.543, backward_time=0.059, grad_norm=116.058, clip=98.701, loss_scale=3.518e+13, optim_step_time=0.005, optim0_lr0=2.542e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 20:53:04,102 (trainer:779) INFO: 38epoch:train:771-847batch: iter_time=5.713e-05, forward_time=0.057, loss_ctc=133.514, loss=133.514, backward_time=0.062, grad_norm=110.424, clip=100.000, loss_scale=3.518e+13, optim_step_time=0.005, optim0_lr0=2.540e-04, train_time=0.167
[lambda-Lambda-Vector] 2025-04-01 20:53:16,454 (trainer:779) INFO: 38epoch:train:848-924batch: iter_time=5.572e-05, forward_time=0.055, loss_ctc=113.080, loss=113.080, backward_time=0.059, grad_norm=88.900, clip=100.000, loss_scale=3.518e+13, optim_step_time=0.005, optim0_lr0=2.538e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 20:53:28,935 (trainer:779) INFO: 38epoch:train:925-1001batch: iter_time=5.541e-05, forward_time=0.055, loss_ctc=108.678, loss=108.678, backward_time=0.060, grad_norm=79.800, clip=100.000, loss_scale=3.518e+13, optim_step_time=0.005, optim0_lr0=2.537e-04, train_time=0.162
[lambda-Lambda-Vector] 2025-04-01 20:53:41,184 (trainer:779) INFO: 38epoch:train:1002-1078batch: iter_time=5.529e-05, forward_time=0.054, loss_ctc=101.979, loss=101.979, backward_time=0.059, grad_norm=66.574, clip=98.701, loss_scale=3.518e+13, optim_step_time=0.005, optim0_lr0=2.535e-04, train_time=0.159
[lambda-Lambda-Vector] 2025-04-01 20:53:53,371 (trainer:779) INFO: 38epoch:train:1079-1155batch: iter_time=5.519e-05, forward_time=0.054, loss_ctc=96.704, loss=96.704, backward_time=0.058, grad_norm=60.386, clip=97.403, loss_scale=3.518e+13, optim_step_time=0.005, optim0_lr0=2.533e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 20:54:05,578 (trainer:779) INFO: 38epoch:train:1156-1232batch: iter_time=5.624e-05, forward_time=0.055, loss_ctc=81.127, loss=81.127, backward_time=0.058, grad_norm=64.484, clip=100.000, loss_scale=3.518e+13, optim_step_time=0.005, optim0_lr0=2.532e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 20:54:17,998 (trainer:779) INFO: 38epoch:train:1233-1309batch: iter_time=5.590e-05, forward_time=0.055, loss_ctc=108.919, loss=108.919, backward_time=0.060, grad_norm=82.138, clip=98.701, loss_scale=3.518e+13, optim_step_time=0.005, optim0_lr0=2.530e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 20:54:30,169 (trainer:779) INFO: 38epoch:train:1310-1386batch: iter_time=5.472e-05, forward_time=0.054, loss_ctc=95.270, loss=95.270, backward_time=0.058, grad_norm=74.158, clip=100.000, loss_scale=3.518e+13, optim_step_time=0.005, optim0_lr0=2.528e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 20:54:42,561 (trainer:779) INFO: 38epoch:train:1387-1463batch: iter_time=5.635e-05, forward_time=0.055, loss_ctc=114.450, loss=114.450, backward_time=0.060, grad_norm=61.662, clip=97.403, loss_scale=3.518e+13, optim_step_time=0.005, optim0_lr0=2.527e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 20:54:55,090 (trainer:779) INFO: 38epoch:train:1464-1540batch: iter_time=5.405e-05, forward_time=0.056, loss_ctc=107.988, loss=107.988, backward_time=0.060, grad_norm=70.884, clip=97.403, loss_scale=3.518e+13, optim_step_time=0.005, optim0_lr0=2.525e-04, train_time=0.163
[lambda-Lambda-Vector] 2025-04-01 20:55:43,237 (trainer:365) INFO: 38epoch results: [train] iter_time=9.774e-05, forward_time=0.055, loss_ctc=103.081, loss=103.081, backward_time=0.059, grad_norm=118.927, clip=99.225, loss_scale=2.738e+13, optim_step_time=0.005, optim0_lr0=2.541e-04, train_time=0.162, time=4 minutes and 11.9 seconds, total_count=58862, gpu_max_cached_mem_GB=31.434, [valid] loss_ctc=115.058, cer_ctc=0.936, loss_att=nan, acc=nan, cer=nan, wer=nan, loss=115.058, time=46.32 seconds, total_count=12122, gpu_max_cached_mem_GB=31.434
[lambda-Lambda-Vector] 2025-04-01 20:55:44,847 (trainer:431) INFO: There are no improvements in this epoch
[lambda-Lambda-Vector] 2025-04-01 20:55:44,863 (trainer:487) INFO: The model files were removed: exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/37epoch.pth
[lambda-Lambda-Vector] 2025-04-01 20:55:44,863 (trainer:299) INFO: 39/70epoch started. Estimated time to finish: 2 hours, 52 minutes and 1.23 seconds
[lambda-Lambda-Vector] 2025-04-01 20:55:57,975 (trainer:779) INFO: 39epoch:train:1-77batch: iter_time=7.188e-04, forward_time=0.054, loss_ctc=114.049, loss=114.049, backward_time=0.059, grad_norm=64.722, clip=100.000, loss_scale=3.518e+13, optim_step_time=0.005, optim0_lr0=2.523e-04, train_time=0.170
[lambda-Lambda-Vector] 2025-04-01 20:56:10,333 (trainer:779) INFO: 39epoch:train:78-154batch: iter_time=5.822e-05, forward_time=0.055, loss_ctc=101.140, loss=101.140, backward_time=0.059, grad_norm=71.258, clip=97.403, loss_scale=3.518e+13, optim_step_time=0.005, optim0_lr0=2.522e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 20:56:22,636 (trainer:779) INFO: 39epoch:train:155-231batch: iter_time=5.694e-05, forward_time=0.054, loss_ctc=115.613, loss=115.613, backward_time=0.059, grad_norm=67.378, clip=100.000, loss_scale=3.518e+13, optim_step_time=0.005, optim0_lr0=2.520e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 20:56:34,698 (trainer:779) INFO: 39epoch:train:232-308batch: iter_time=5.498e-05, forward_time=0.053, loss_ctc=94.073, loss=94.073, backward_time=0.058, grad_norm=65.731, clip=97.403, loss_scale=3.518e+13, optim_step_time=0.005, optim0_lr0=2.518e-04, train_time=0.157
[lambda-Lambda-Vector] 2025-04-01 20:56:47,044 (trainer:779) INFO: 39epoch:train:309-385batch: iter_time=5.726e-05, forward_time=0.054, loss_ctc=109.719, loss=109.719, backward_time=0.059, grad_norm=67.924, clip=98.701, loss_scale=3.518e+13, optim_step_time=0.005, optim0_lr0=2.517e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 20:56:59,659 (trainer:779) INFO: 39epoch:train:386-462batch: iter_time=5.660e-05, forward_time=0.056, loss_ctc=114.490, loss=114.490, backward_time=0.060, grad_norm=72.947, clip=98.701, loss_scale=3.518e+13, optim_step_time=0.005, optim0_lr0=2.515e-04, train_time=0.164
[lambda-Lambda-Vector] 2025-04-01 20:57:11,804 (trainer:779) INFO: 39epoch:train:463-539batch: iter_time=5.477e-05, forward_time=0.054, loss_ctc=115.677, loss=115.677, backward_time=0.058, grad_norm=68.781, clip=100.000, loss_scale=3.518e+13, optim_step_time=0.005, optim0_lr0=2.513e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 20:57:23,771 (trainer:779) INFO: 39epoch:train:540-616batch: iter_time=5.485e-05, forward_time=0.053, loss_ctc=95.228, loss=95.228, backward_time=0.057, grad_norm=67.005, clip=98.701, loss_scale=3.518e+13, optim_step_time=0.005, optim0_lr0=2.512e-04, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 20:57:36,305 (trainer:779) INFO: 39epoch:train:617-693batch: iter_time=5.508e-05, forward_time=0.055, loss_ctc=116.848, loss=116.848, backward_time=0.060, grad_norm=70.645, clip=100.000, loss_scale=3.518e+13, optim_step_time=0.005, optim0_lr0=2.510e-04, train_time=0.163
[lambda-Lambda-Vector] 2025-04-01 20:57:48,256 (trainer:779) INFO: 39epoch:train:694-770batch: iter_time=5.828e-05, forward_time=0.053, loss_ctc=97.056, loss=97.056, backward_time=0.057, grad_norm=62.831, clip=97.403, loss_scale=3.518e+13, optim_step_time=0.005, optim0_lr0=2.508e-04, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 20:58:00,551 (trainer:779) INFO: 39epoch:train:771-847batch: iter_time=5.856e-05, forward_time=0.054, loss_ctc=101.822, loss=101.822, backward_time=0.059, grad_norm=69.655, clip=100.000, loss_scale=3.518e+13, optim_step_time=0.005, optim0_lr0=2.507e-04, train_time=0.160
[lambda-Lambda-Vector] 2025-04-01 20:58:12,738 (trainer:779) INFO: 39epoch:train:848-924batch: iter_time=5.548e-05, forward_time=0.054, loss_ctc=94.837, loss=94.837, backward_time=0.058, grad_norm=62.054, clip=98.701, loss_scale=3.518e+13, optim_step_time=0.005, optim0_lr0=2.505e-04, train_time=0.158
[lambda-Lambda-Vector] 2025-04-01 20:58:25,140 (trainer:779) INFO: 39epoch:train:925-1001batch: iter_time=5.519e-05, forward_time=0.055, loss_ctc=104.000, loss=104.000, backward_time=0.059, grad_norm=59.478, clip=98.701, loss_scale=3.518e+13, optim_step_time=0.005, optim0_lr0=2.504e-04, train_time=0.161
[lambda-Lambda-Vector] 2025-04-01 20:58:38,124 (trainer:779) INFO: 39epoch:train:1002-1078batch: iter_time=5.507e-05, forward_time=0.066, loss_ctc=93.613, loss=93.613, backward_time=0.057, grad_norm=50.907, clip=97.403, loss_scale=3.518e+13, optim_step_time=0.005, optim0_lr0=2.502e-04, train_time=0.169
[lambda-Lambda-Vector] 2025-04-01 20:58:50,070 (trainer:779) INFO: 39epoch:train:1079-1155batch: iter_time=5.436e-05, forward_time=0.053, loss_ctc=88.977, loss=88.977, backward_time=0.057, grad_norm=49.762, clip=94.805, loss_scale=4.295e+13, optim_step_time=0.005, optim0_lr0=2.500e-04, train_time=0.155
[lambda-Lambda-Vector] 2025-04-01 20:59:02,398 (trainer:779) INFO: 39epoch:train:1156-1232batch: iter_time=5.527e-05, forward_time=0.054, loss_ctc=107.757, loss=107.757, backward_time=0.059, grad_norm=63.723, clip=98.701, loss_scale=7.037e+13, optim_step_time=0.005, optim0_lr0=2.499e-04, train_time=0.160
# Accounting: time=12488 threads=1
# Ended (code 137) at Tue Apr  1 20:59:10 PDT 2025, elapsed time 12488 seconds

2025-04-02T17:08:49 (asr2_codec.sh:295:main) ./asr2_codec.sh --stage 13 --stop_stage 13 --src_token_size 15360 --src_codebook_size 1 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_15360/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_15360/dev/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --ngpu 1 --nj 4 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_fsq_15360 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.xcodec_fsq_15360 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-02T17:08:49 (asr2_codec.sh:632:main) Skipped stages:  8 9 10 11 16 17 
2025-04-02T17:08:49 (asr2_codec.sh:1430:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-04-02T17:08:49 (asr2_codec.sh:1473:main) Generate 'exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_15360_char_ts_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-04-02T17:08:49 (asr2_codec.sh:1477:main) ASR training started... log: 'exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_15360_char_ts_bpe_ts5000/train.log'
2025-04-02 17:08:49,708 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_15360_char_ts_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_15360_char_ts_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_15360_char_ts_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_int_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 15360 --src_codebook_size 1 --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_15360/dev/speech_token.scp,src_text,text_int --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_15360_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_15360_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_15360_char_ts_bpe_ts5000 --config conf/train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_15360/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_15360_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_15360_char_bpe5000/train/text_shape.bpe
2025-04-02 17:08:49,719 (launch:348) INFO: log file: exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_15360_char_ts_bpe_ts5000/train.log
2025-04-02T18:43:21 (asr2_codec.sh:295:main) ./asr2_codec.sh --stage 13 --stop_stage 13 --src_token_size 15360 --src_codebook_size 1 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_15360/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_15360/dev/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --ngpu 1 --nj 4 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_fsq_15360 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.xcodec_fsq_15360 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-02T18:43:21 (asr2_codec.sh:632:main) Skipped stages:  8 9 10 11 16 17 
2025-04-02T18:43:21 (asr2_codec.sh:1430:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-04-02T18:43:21 (asr2_codec.sh:1473:main) Generate 'exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_15360_char_ts_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-04-02T18:43:21 (asr2_codec.sh:1477:main) ASR training started... log: 'exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_15360_char_ts_bpe_ts5000/train.log'
2025-04-02 18:43:21,482 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_15360_char_ts_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_15360_char_ts_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_15360_char_ts_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_int_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 15360 --src_codebook_size 1 --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_15360/dev/speech_token.scp,src_text,text_int --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_15360_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_15360_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_15360_char_ts_bpe_ts5000 --config conf/train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_15360/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_15360_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_15360_char_bpe5000/train/text_shape.bpe
2025-04-02 18:43:21,495 (launch:348) INFO: log file: exp/asr_train_discrete_asr_int_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_15360_char_ts_bpe_ts5000/train.log
2025-04-02T19:01:55 (asr2_codec.sh:295:main) ./asr2_codec.sh --stage 13 --stop_stage 13 --src_token_size 15360 --src_codebook_size 1 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_15360/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_15360/dev/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --ngpu 1 --nj 4 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_fsq_15360 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_int_e_branchformer1_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.xcodec_fsq_15360 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-02T19:01:55 (asr2_codec.sh:632:main) Skipped stages:  8 9 10 11 16 17 
2025-04-02T19:01:55 (asr2_codec.sh:1430:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-04-02T19:01:55 (asr2_codec.sh:1473:main) Generate 'exp/asr_train_discrete_asr_int_e_branchformer1_1gpu_lr5e-4_raw_xcodec_fsq_15360_char_ts_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-04-02T19:01:55 (asr2_codec.sh:1477:main) ASR training started... log: 'exp/asr_train_discrete_asr_int_e_branchformer1_1gpu_lr5e-4_raw_xcodec_fsq_15360_char_ts_bpe_ts5000/train.log'
2025-04-02 19:01:56,016 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_int_e_branchformer1_1gpu_lr5e-4_raw_xcodec_fsq_15360_char_ts_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_int_e_branchformer1_1gpu_lr5e-4_raw_xcodec_fsq_15360_char_ts_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_int_e_branchformer1_1gpu_lr5e-4_raw_xcodec_fsq_15360_char_ts_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_int_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 15360 --src_codebook_size 1 --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_15360/dev/speech_token.scp,src_text,text_int --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_15360_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_15360_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_int_e_branchformer1_1gpu_lr5e-4_raw_xcodec_fsq_15360_char_ts_bpe_ts5000 --config conf/train_discrete_asr_int_e_branchformer1_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_15360/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_15360_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_15360_char_bpe5000/train/text_shape.bpe
2025-04-02 19:01:56,029 (launch:348) INFO: log file: exp/asr_train_discrete_asr_int_e_branchformer1_1gpu_lr5e-4_raw_xcodec_fsq_15360_char_ts_bpe_ts5000/train.log
2025-04-02T21:31:56 (asr2_codec.sh:295:main) ./asr2_codec.sh --stage 13 --stop_stage 13 --src_token_size 15360 --src_codebook_size 1 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_15360/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_15360/dev/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --ngpu 1 --nj 4 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_fsq_15360 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_int_e_branchformer1_1gpu_lr2e-3.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.xcodec_fsq_15360 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-02T21:31:56 (asr2_codec.sh:632:main) Skipped stages:  8 9 10 11 16 17 
2025-04-02T21:31:56 (asr2_codec.sh:1430:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-04-02T21:31:56 (asr2_codec.sh:1473:main) Generate 'exp/asr_train_discrete_asr_int_e_branchformer1_1gpu_lr2e-3_raw_xcodec_fsq_15360_char_ts_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-04-02T21:31:56 (asr2_codec.sh:1477:main) ASR training started... log: 'exp/asr_train_discrete_asr_int_e_branchformer1_1gpu_lr2e-3_raw_xcodec_fsq_15360_char_ts_bpe_ts5000/train.log'
2025-04-02 21:31:56,893 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_int_e_branchformer1_1gpu_lr2e-3_raw_xcodec_fsq_15360_char_ts_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_int_e_branchformer1_1gpu_lr2e-3_raw_xcodec_fsq_15360_char_ts_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_int_e_branchformer1_1gpu_lr2e-3_raw_xcodec_fsq_15360_char_ts_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_int_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 15360 --src_codebook_size 1 --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_15360/dev/speech_token.scp,src_text,text_int --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_15360_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_15360_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_int_e_branchformer1_1gpu_lr2e-3_raw_xcodec_fsq_15360_char_ts_bpe_ts5000 --config conf/train_discrete_asr_int_e_branchformer1_1gpu_lr2e-3.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_15360/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_15360_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_15360_char_bpe5000/train/text_shape.bpe
2025-04-02 21:31:56,906 (launch:348) INFO: log file: exp/asr_train_discrete_asr_int_e_branchformer1_1gpu_lr2e-3_raw_xcodec_fsq_15360_char_ts_bpe_ts5000/train.log
2025-04-03T03:54:18 (asr2_codec.sh:1795:main) Successfully finished. [elapsed=22942s]
2025-04-03T21:18:00 (asr2_codec.sh:296:main) ./asr2_codec.sh --stage 13 --stop_stage 13 --src_token_size 1024 --src_codebook_size 8 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/dev/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --src_codebook_paths codec_infer_data/speechtokenizer/codebook_0.npy codec_infer_data/speechtokenizer/codebook_1.npy codec_infer_data/speechtokenizer/codebook_2.npy codec_infer_data/speechtokenizer/codebook_3.npy codec_infer_data/speechtokenizer/codebook_4.npy codec_infer_data/speechtokenizer/codebook_5.npy codec_infer_data/speechtokenizer/codebook_6.npy codec_infer_data/speechtokenizer/codebook_7.npy --ngpu 1 --nj 4 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang speechtokenizer --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.speechtokenizer --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-03T21:18:00 (asr2_codec.sh:633:main) Skipped stages:  8 9 10 11 16 17 
2025-04-03T21:18:00 (asr2_codec.sh:1431:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-04-03T21:18:00 (asr2_codec.sh:1474:main) Generate 'exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-04-03T21:18:00 (asr2_codec.sh:1478:main) ASR training started... log: 'exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log'
2025-04-03 21:18:00,708 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_codec_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1024 --src_codebook_size 8 --src_codebook_paths codec_infer_data/speechtokenizer/codebook_0.npy codec_infer_data/speechtokenizer/codebook_1.npy codec_infer_data/speechtokenizer/codebook_2.npy codec_infer_data/speechtokenizer/codebook_3.npy codec_infer_data/speechtokenizer/codebook_4.npy codec_infer_data/speechtokenizer/codebook_5.npy codec_infer_data/speechtokenizer/codebook_6.npy codec_infer_data/speechtokenizer/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/dev/speech_token.scp,src_text,text_int --valid_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/train/text_shape.bpe
2025-04-03 21:18:00,719 (launch:348) INFO: log file: exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log
2025-04-05T14:11:45 (asr2_codec.sh:296:main) ./asr2_codec.sh --stage 13 --stop_stage 13 --src_token_size 1024 --src_codebook_size 8 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/dev/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --src_codebook_paths codec_infer_data/speechtokenizer/codebook_0.npy codec_infer_data/speechtokenizer/codebook_1.npy codec_infer_data/speechtokenizer/codebook_2.npy codec_infer_data/speechtokenizer/codebook_3.npy codec_infer_data/speechtokenizer/codebook_4.npy codec_infer_data/speechtokenizer/codebook_5.npy codec_infer_data/speechtokenizer/codebook_6.npy codec_infer_data/speechtokenizer/codebook_7.npy --ngpu 1 --nj 4 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang speechtokenizer --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_init_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.speechtokenizer --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-05T14:11:46 (asr2_codec.sh:633:main) Skipped stages:  8 9 10 11 16 17 
2025-04-05T14:11:46 (asr2_codec.sh:1431:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-04-05T14:11:46 (asr2_codec.sh:1474:main) Generate 'exp/asr_train_discrete_asr_codec_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-04-05T14:11:46 (asr2_codec.sh:1478:main) ASR training started... log: 'exp/asr_train_discrete_asr_codec_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log'
2025-04-05 14:11:46,168 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_codec_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_codec_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_codec_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_codec_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1024 --src_codebook_size 8 --src_codebook_paths codec_infer_data/speechtokenizer/codebook_0.npy codec_infer_data/speechtokenizer/codebook_1.npy codec_infer_data/speechtokenizer/codebook_2.npy codec_infer_data/speechtokenizer/codebook_3.npy codec_infer_data/speechtokenizer/codebook_4.npy codec_infer_data/speechtokenizer/codebook_5.npy codec_infer_data/speechtokenizer/codebook_6.npy codec_infer_data/speechtokenizer/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/dev/speech_token.scp,src_text,text_int --valid_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_init_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/train/text_shape.bpe
2025-04-05 14:11:46,183 (launch:348) INFO: log file: exp/asr_train_discrete_asr_codec_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log
2025-04-05T22:30:33 (asr2_codec.sh:296:main) ./asr2_codec.sh --stage 13 --stop_stage 13 --src_token_size 1024 --src_codebook_size 8 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/dev/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --src_codebook_paths codec_infer_data/speechtokenizer/codebook_0.npy codec_infer_data/speechtokenizer/codebook_1.npy codec_infer_data/speechtokenizer/codebook_2.npy codec_infer_data/speechtokenizer/codebook_3.npy codec_infer_data/speechtokenizer/codebook_4.npy codec_infer_data/speechtokenizer/codebook_5.npy codec_infer_data/speechtokenizer/codebook_6.npy codec_infer_data/speechtokenizer/codebook_7.npy --ngpu 1 --nj 4 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang speechtokenizer --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.speechtokenizer --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-05T22:30:34 (asr2_codec.sh:633:main) Skipped stages:  8 9 10 11 16 17 
2025-04-05T22:30:34 (asr2_codec.sh:1431:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-04-05T22:30:34 (asr2_codec.sh:1474:main) Generate 'exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-04-05T22:30:34 (asr2_codec.sh:1478:main) ASR training started... log: 'exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log'
2025-04-05 22:30:34,118 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_codec_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1024 --src_codebook_size 8 --src_codebook_paths codec_infer_data/speechtokenizer/codebook_0.npy codec_infer_data/speechtokenizer/codebook_1.npy codec_infer_data/speechtokenizer/codebook_2.npy codec_infer_data/speechtokenizer/codebook_3.npy codec_infer_data/speechtokenizer/codebook_4.npy codec_infer_data/speechtokenizer/codebook_5.npy codec_infer_data/speechtokenizer/codebook_6.npy codec_infer_data/speechtokenizer/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/dev/speech_token.scp,src_text,text_int --valid_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/train/text_shape.bpe
2025-04-05 22:30:34,131 (launch:348) INFO: log file: exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log
run.pl: job failed, log is in exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log
Command '['run.pl', '--name', 'exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log', '--gpu', '1', 'exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log', 'python3', '-m', 'espnet2.bin.mt_codec_train', '--use_preprocessor', 'true', '--bpemodel', 'data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model', '--token_type', 'bpe', '--token_list', 'data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt', '--src_token_size', '1024', '--src_codebook_size', '8', '--src_codebook_paths', 'codec_infer_data/speechtokenizer/codebook_0.npy', 'codec_infer_data/speechtokenizer/codebook_1.npy', 'codec_infer_data/speechtokenizer/codebook_2.npy', 'codec_infer_data/speechtokenizer/codebook_3.npy', 'codec_infer_data/speechtokenizer/codebook_4.npy', 'codec_infer_data/speechtokenizer/codebook_5.npy', 'codec_infer_data/speechtokenizer/codebook_6.npy', 'codec_infer_data/speechtokenizer/codebook_7.npy', '--non_linguistic_symbols', 'none', '--cleaner', 'none', '--g2p', 'none', '--valid_data_path_and_name_and_type', '/data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text', '--valid_data_path_and_name_and_type', '/data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/dev/speech_token.scp,src_text,text_int', '--valid_shape_file', 'exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/valid/text_shape.bpe', '--valid_shape_file', 'exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/valid/src_text_shape.char', '--resume', 'true', '--ignore_init_mismatch', 'false', '--fold_length', '150', '--fold_length', '150', '--output_dir', 'exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000', '--config', 'conf/train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml', '--train_data_path_and_name_and_type', '/data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/train/speech_token.scp,src_text,text_int', '--train_data_path_and_name_and_type', '/data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text', '--train_shape_file', 'exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/train/src_text_shape.char', '--train_shape_file', 'exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/train/text_shape.bpe', '--ngpu', '1', '--multiprocessing_distributed', 'True']' returned non-zero exit status 1.
Traceback (most recent call last):
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/data/mohan/workdir/espnet/espnet2/bin/launch.py", line 384, in <module>
    main()
  File "/data/mohan/workdir/espnet/espnet2/bin/launch.py", line 375, in main
    raise RuntimeError(
RuntimeError: 
################### The last 1000 lines of exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log ###################
# python3 -m espnet2.bin.mt_codec_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1024 --src_codebook_size 8 --src_codebook_paths codec_infer_data/speechtokenizer/codebook_0.npy codec_infer_data/speechtokenizer/codebook_1.npy codec_infer_data/speechtokenizer/codebook_2.npy codec_infer_data/speechtokenizer/codebook_3.npy codec_infer_data/speechtokenizer/codebook_4.npy codec_infer_data/speechtokenizer/codebook_5.npy codec_infer_data/speechtokenizer/codebook_6.npy codec_infer_data/speechtokenizer/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/dev/speech_token.scp,src_text,text_int --valid_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/train/text_shape.bpe --ngpu 1 --multiprocessing_distributed True 
# Started at Sat Apr  5 22:30:34 PDT 2025
#
/data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/mt_codec_train.py --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1024 --src_codebook_size 8 --src_codebook_paths codec_infer_data/speechtokenizer/codebook_0.npy codec_infer_data/speechtokenizer/codebook_1.npy codec_infer_data/speechtokenizer/codebook_2.npy codec_infer_data/speechtokenizer/codebook_3.npy codec_infer_data/speechtokenizer/codebook_4.npy codec_infer_data/speechtokenizer/codebook_5.npy codec_infer_data/speechtokenizer/codebook_6.npy codec_infer_data/speechtokenizer/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/dev/speech_token.scp,src_text,text_int --valid_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/train/text_shape.bpe --ngpu 1 --multiprocessing_distributed True
[lambda-Lambda-Vector] 2025-04-05 22:30:39,576 (mt_codec:333) INFO: Vocabulary size: 5000
Traceback (most recent call last):
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_codec_train.py", line 23, in <module>
    main()
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_codec_train.py", line 19, in main
    MTTask.main(cmd=cmd)
  File "/data/mohan/workdir/espnet/espnet2/tasks/abs_task.py", line 1210, in main
    cls.main_worker(args)
  File "/data/mohan/workdir/espnet/espnet2/tasks/abs_task.py", line 1346, in main_worker
    model = cls.build_model(args=args)
  File "/data/mohan/workdir/espnet/espnet2/tasks/mt_codec.py", line 340, in build_model
    frontend = frontend_class(npy_paths=args.src_codebook_paths, **args.frontend_conf)
  File "/data/mohan/workdir/espnet/espnet2/mt/frontend/codebook_embedding.py", line 61, in __init__
    self.codebooks.append(embed)
UnboundLocalError: local variable 'embed' referenced before assignment
# Accounting: time=6 threads=1
# Ended (code 1) at Sat Apr  5 22:30:40 PDT 2025, elapsed time 6 seconds

2025-04-05T22:32:19 (asr2_codec.sh:296:main) ./asr2_codec.sh --stage 13 --stop_stage 13 --src_token_size 1024 --src_codebook_size 8 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/dev/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --src_codebook_paths codec_infer_data/speechtokenizer/codebook_0.npy codec_infer_data/speechtokenizer/codebook_1.npy codec_infer_data/speechtokenizer/codebook_2.npy codec_infer_data/speechtokenizer/codebook_3.npy codec_infer_data/speechtokenizer/codebook_4.npy codec_infer_data/speechtokenizer/codebook_5.npy codec_infer_data/speechtokenizer/codebook_6.npy codec_infer_data/speechtokenizer/codebook_7.npy --ngpu 1 --nj 4 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang speechtokenizer --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.speechtokenizer --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-05T22:32:19 (asr2_codec.sh:633:main) Skipped stages:  8 9 10 11 16 17 
2025-04-05T22:32:19 (asr2_codec.sh:1431:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-04-05T22:32:19 (asr2_codec.sh:1474:main) Generate 'exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-04-05T22:32:19 (asr2_codec.sh:1478:main) ASR training started... log: 'exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log'
2025-04-05 22:32:19,663 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_codec_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1024 --src_codebook_size 8 --src_codebook_paths codec_infer_data/speechtokenizer/codebook_0.npy codec_infer_data/speechtokenizer/codebook_1.npy codec_infer_data/speechtokenizer/codebook_2.npy codec_infer_data/speechtokenizer/codebook_3.npy codec_infer_data/speechtokenizer/codebook_4.npy codec_infer_data/speechtokenizer/codebook_5.npy codec_infer_data/speechtokenizer/codebook_6.npy codec_infer_data/speechtokenizer/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/dev/speech_token.scp,src_text,text_int --valid_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/train/text_shape.bpe
2025-04-05 22:32:19,674 (launch:348) INFO: log file: exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log
2025-04-06T04:02:59 (asr2_codec.sh:1797:main) Successfully finished. [elapsed=49874s]
2025-04-06T07:21:47 (asr2_codec.sh:1797:main) Successfully finished. [elapsed=31768s]
2025-04-07T21:48:52 (asr2_codec.sh:296:main) ./asr2_codec.sh --stage 13 --stop_stage 13 --src_token_size 1000 --src_codebook_size 8 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --src_codebook_paths codec_infer_data/speechtokenizer/codebook_0.npy codec_infer_data/speechtokenizer/codebook_1.npy codec_infer_data/speechtokenizer/codebook_2.npy codec_infer_data/speechtokenizer/codebook_3.npy codec_infer_data/speechtokenizer/codebook_4.npy codec_infer_data/speechtokenizer/codebook_5.npy codec_infer_data/speechtokenizer/codebook_6.npy codec_infer_data/speechtokenizer/codebook_7.npy --ngpu 1 --nj 8 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_fsq_g8r1 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.xcodec_fsq_g8r1 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-07T21:48:52 (asr2_codec.sh:633:main) Skipped stages:  8 9 10 11 16 17 
2025-04-07T21:48:52 (asr2_codec.sh:1432:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-04-07T21:48:52 (asr2_codec.sh:1475:main) Generate 'exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-04-07T21:48:52 (asr2_codec.sh:1479:main) ASR training started... log: 'exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log'
2025-04-07 21:48:52,838 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_codec_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1000 --src_codebook_size 8 --src_codebook_paths codec_infer_data/speechtokenizer/codebook_0.npy codec_infer_data/speechtokenizer/codebook_1.npy codec_infer_data/speechtokenizer/codebook_2.npy codec_infer_data/speechtokenizer/codebook_3.npy codec_infer_data/speechtokenizer/codebook_4.npy codec_infer_data/speechtokenizer/codebook_5.npy codec_infer_data/speechtokenizer/codebook_6.npy codec_infer_data/speechtokenizer/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp,src_text,text_int --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/text_shape.bpe
2025-04-07 21:48:52,850 (launch:348) INFO: log file: exp/asr_train_discrete_asr_codec_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log
2025-04-08T00:17:48 (asr2_codec.sh:296:main) ./asr2_codec.sh --stage 13 --stop_stage 13 --src_token_size 1000 --src_codebook_size 8 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --src_codebook_paths codec_infer_data/speechtokenizer/codebook_0.npy codec_infer_data/speechtokenizer/codebook_1.npy codec_infer_data/speechtokenizer/codebook_2.npy codec_infer_data/speechtokenizer/codebook_3.npy codec_infer_data/speechtokenizer/codebook_4.npy codec_infer_data/speechtokenizer/codebook_5.npy codec_infer_data/speechtokenizer/codebook_6.npy codec_infer_data/speechtokenizer/codebook_7.npy --ngpu 1 --nj 8 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_fsq_g8r1 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.xcodec_fsq_g8r1 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-08T00:17:48 (asr2_codec.sh:633:main) Skipped stages:  8 9 10 11 16 17 
2025-04-08T00:17:48 (asr2_codec.sh:1432:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-04-08T00:17:48 (asr2_codec.sh:1475:main) Generate 'exp/asr_train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-04-08T00:17:48 (asr2_codec.sh:1479:main) ASR training started... log: 'exp/asr_train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log'
2025-04-08 00:17:48,205 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_codec_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1000 --src_codebook_size 8 --src_codebook_paths codec_infer_data/speechtokenizer/codebook_0.npy codec_infer_data/speechtokenizer/codebook_1.npy codec_infer_data/speechtokenizer/codebook_2.npy codec_infer_data/speechtokenizer/codebook_3.npy codec_infer_data/speechtokenizer/codebook_4.npy codec_infer_data/speechtokenizer/codebook_5.npy codec_infer_data/speechtokenizer/codebook_6.npy codec_infer_data/speechtokenizer/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp,src_text,text_int --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/text_shape.bpe
2025-04-08 00:17:48,218 (launch:348) INFO: log file: exp/asr_train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log
run.pl: job failed, log is in exp/asr_train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log
Command '['run.pl', '--name', 'exp/asr_train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log', '--gpu', '1', 'exp/asr_train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log', 'python3', '-m', 'espnet2.bin.mt_codec_train', '--use_preprocessor', 'true', '--bpemodel', 'data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model', '--token_type', 'bpe', '--token_list', 'data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt', '--src_token_size', '1000', '--src_codebook_size', '8', '--src_codebook_paths', 'codec_infer_data/speechtokenizer/codebook_0.npy', 'codec_infer_data/speechtokenizer/codebook_1.npy', 'codec_infer_data/speechtokenizer/codebook_2.npy', 'codec_infer_data/speechtokenizer/codebook_3.npy', 'codec_infer_data/speechtokenizer/codebook_4.npy', 'codec_infer_data/speechtokenizer/codebook_5.npy', 'codec_infer_data/speechtokenizer/codebook_6.npy', 'codec_infer_data/speechtokenizer/codebook_7.npy', '--non_linguistic_symbols', 'none', '--cleaner', 'none', '--g2p', 'none', '--valid_data_path_and_name_and_type', '/data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text', '--valid_data_path_and_name_and_type', '/data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp,src_text,text_int', '--valid_shape_file', 'exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/text_shape.bpe', '--valid_shape_file', 'exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/src_text_shape.char', '--resume', 'true', '--ignore_init_mismatch', 'false', '--fold_length', '150', '--fold_length', '150', '--output_dir', 'exp/asr_train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000', '--config', 'conf/train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml', '--train_data_path_and_name_and_type', '/data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp,src_text,text_int', '--train_data_path_and_name_and_type', '/data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text', '--train_shape_file', 'exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/src_text_shape.char', '--train_shape_file', 'exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/text_shape.bpe', '--ngpu', '1', '--multiprocessing_distributed', 'True']' returned non-zero exit status 1.
Traceback (most recent call last):
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/data/mohan/workdir/espnet/espnet2/bin/launch.py", line 384, in <module>
    main()
  File "/data/mohan/workdir/espnet/espnet2/bin/launch.py", line 375, in main
    raise RuntimeError(
RuntimeError: 
################### The last 1000 lines of exp/asr_train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log ###################
# python3 -m espnet2.bin.mt_codec_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1000 --src_codebook_size 8 --src_codebook_paths codec_infer_data/speechtokenizer/codebook_0.npy codec_infer_data/speechtokenizer/codebook_1.npy codec_infer_data/speechtokenizer/codebook_2.npy codec_infer_data/speechtokenizer/codebook_3.npy codec_infer_data/speechtokenizer/codebook_4.npy codec_infer_data/speechtokenizer/codebook_5.npy codec_infer_data/speechtokenizer/codebook_6.npy codec_infer_data/speechtokenizer/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp,src_text,text_int --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/text_shape.bpe --ngpu 1 --multiprocessing_distributed True 
# Started at Tue Apr  8 00:17:48 PDT 2025
#
/data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/mt_codec_train.py --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1000 --src_codebook_size 8 --src_codebook_paths codec_infer_data/speechtokenizer/codebook_0.npy codec_infer_data/speechtokenizer/codebook_1.npy codec_infer_data/speechtokenizer/codebook_2.npy codec_infer_data/speechtokenizer/codebook_3.npy codec_infer_data/speechtokenizer/codebook_4.npy codec_infer_data/speechtokenizer/codebook_5.npy codec_infer_data/speechtokenizer/codebook_6.npy codec_infer_data/speechtokenizer/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp,src_text,text_int --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/text_shape.bpe --ngpu 1 --multiprocessing_distributed True
[lambda-Lambda-Vector] 2025-04-08 00:17:53,591 (mt_codec:333) INFO: Vocabulary size: 5000
[lambda-Lambda-Vector] 2025-04-08 00:17:53,762 (discrete_asr_codec_espnet_model:98) WARNING: Set decoder to none as ctc_weight==1.0
[lambda-Lambda-Vector] 2025-04-08 00:17:54,941 (abs_task:1387) INFO: pytorch.version=2.3.0+cu121, cuda.available=True, cudnn.version=8902, cudnn.benchmark=False, cudnn.deterministic=True
[lambda-Lambda-Vector] 2025-04-08 00:17:54,945 (abs_task:1388) INFO: Model structure:
ESPnetDiscreteASRModel(
  (frontend): CodebookEmbedding(
    (codebooks): ModuleList(
      (0-7): 8 x Sequential(
        (0): Embedding(1000, 128)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (encoder): EBranchformerEncoder(
    (embed): Conv1dSubsampling2(
      (conv): Sequential(
        (0): Conv1d(128, 256, kernel_size=(3,), stride=(1,))
        (1): ReLU()
        (2): Conv1d(256, 256, kernel_size=(3,), stride=(2,))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): RelPositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (encoders): MultiSequential(
      (0): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (1): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (2): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (3): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (4): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (5): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (6): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (7): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (8): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (9): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (10): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (11): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
  )
  (criterion_mt): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
  (specaug): SpecAug(
    (time_mask): MaskAlongAxisVariableMaxWidth(mask_width_ratio_range=[0.0, 0.05], num_mask=10, axis=time)
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5000, bias=True)
    (ctc_loss): CTCLoss()
  )
)

Model summary:
    Class Name: ESPnetDiscreteASRModel
    Total Number of model parameters: 25.98 M
    Number of trainable parameters: 25.98 M (100.0%)
    Size: 103.92 MB
    Type: torch.float32
[lambda-Lambda-Vector] 2025-04-08 00:17:54,945 (abs_task:1391) INFO: Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 3.333333333333334e-08
    maximize: False
    weight_decay: 1e-06
)
[lambda-Lambda-Vector] 2025-04-08 00:17:54,945 (abs_task:1392) INFO: Scheduler: WarmupLR(warmup_steps=15000)
[lambda-Lambda-Vector] 2025-04-08 00:17:54,945 (abs_task:1401) INFO: Saving the configuration in exp/asr_train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/config.yaml
[lambda-Lambda-Vector] 2025-04-08 00:18:13,125 (abs_task:1810) INFO: [train] dataset:
ESPnetDataset(
  src_text: {"path": "/data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp", "type": "text_int"}
  text: {"path": "/data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en", "type": "text"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x718323c20340>)
[lambda-Lambda-Vector] 2025-04-08 00:18:13,125 (abs_task:1811) INFO: [train] Batch sampler: NumElementsBatchSampler(N-batch=1515, batch_bins=128000000, sort_in_batch=descending, sort_batch=descending)
[lambda-Lambda-Vector] 2025-04-08 00:18:13,125 (abs_task:1812) INFO: [train] mini-batch sizes summary: N-batch=1515, mean=36.8, min=5, max=322
[lambda-Lambda-Vector] 2025-04-08 00:18:15,659 (abs_task:1810) INFO: [valid] dataset:
ESPnetDataset(
  text: {"path": "/data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en", "type": "text"}
  src_text: {"path": "/data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp", "type": "text_int"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x71832530dae0>)
[lambda-Lambda-Vector] 2025-04-08 00:18:15,659 (abs_task:1811) INFO: [valid] Batch sampler: NumElementsBatchSampler(N-batch=313, batch_bins=128000000, sort_in_batch=descending, sort_batch=descending)
[lambda-Lambda-Vector] 2025-04-08 00:18:15,659 (abs_task:1812) INFO: [valid] mini-batch sizes summary: N-batch=313, mean=28.9, min=8, max=112
[lambda-Lambda-Vector] 2025-04-08 00:18:15,661 (trainer:311) INFO: 1/70epoch started
Traceback (most recent call last):
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_codec_train.py", line 23, in <module>
    main()
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_codec_train.py", line 19, in main
    MTTask.main(cmd=cmd)
  File "/data/mohan/workdir/espnet/espnet2/tasks/abs_task.py", line 1210, in main
    cls.main_worker(args)
  File "/data/mohan/workdir/espnet/espnet2/tasks/abs_task.py", line 1571, in main_worker
    cls.trainer.run(
  File "/data/mohan/workdir/espnet/espnet2/train/trainer.py", line 317, in run
    all_steps_are_invalid = cls.train_one_epoch(
  File "/data/mohan/workdir/espnet/espnet2/train/trainer.py", line 614, in train_one_epoch
    retval = model(**batch)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/mohan/workdir/espnet/espnet2/asr/discrete_asr_codec_espnet_model.py", line 153, in forward
    encoder_out, encoder_out_lens = self.encode(src_text, src_text_lengths)
  File "/data/mohan/workdir/espnet/espnet2/asr/discrete_asr_codec_espnet_model.py", line 254, in encode
    encoder_out, encoder_out_lens, _ = self.encoder(feats, feats_lengths)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/mohan/workdir/espnet/espnet2/asr/encoder/e_branchformer_encoder.py", line 483, in forward
    xs_pad, masks = self.embed(xs_pad, masks)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/mohan/workdir/espnet/espnet/nets/pytorch_backend/transformer/subsampling.py", line 151, in forward
    x = self.conv(x)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
RuntimeError: Given groups=1, weight of size [256, 128, 3], expected input[19, 1024, 832] to have 128 channels, but got 1024 channels instead
# Accounting: time=32 threads=1
# Ended (code 1) at Tue Apr  8 00:18:20 PDT 2025, elapsed time 32 seconds

2025-04-08T00:20:29 (asr2_codec.sh:296:main) ./asr2_codec.sh --stage 13 --stop_stage 13 --src_token_size 1000 --src_codebook_size 8 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --src_codebook_paths codec_infer_data/speechtokenizer/codebook_0.npy codec_infer_data/speechtokenizer/codebook_1.npy codec_infer_data/speechtokenizer/codebook_2.npy codec_infer_data/speechtokenizer/codebook_3.npy codec_infer_data/speechtokenizer/codebook_4.npy codec_infer_data/speechtokenizer/codebook_5.npy codec_infer_data/speechtokenizer/codebook_6.npy codec_infer_data/speechtokenizer/codebook_7.npy --ngpu 1 --nj 8 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_fsq_g8r1 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.xcodec_fsq_g8r1 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-08T00:20:29 (asr2_codec.sh:633:main) Skipped stages:  8 9 10 11 16 17 
2025-04-08T00:20:29 (asr2_codec.sh:1432:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-04-08T00:20:29 (asr2_codec.sh:1475:main) Generate 'exp/asr_train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-04-08T00:20:29 (asr2_codec.sh:1479:main) ASR training started... log: 'exp/asr_train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log'
2025-04-08 00:20:29,820 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_codec_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1000 --src_codebook_size 8 --src_codebook_paths codec_infer_data/speechtokenizer/codebook_0.npy codec_infer_data/speechtokenizer/codebook_1.npy codec_infer_data/speechtokenizer/codebook_2.npy codec_infer_data/speechtokenizer/codebook_3.npy codec_infer_data/speechtokenizer/codebook_4.npy codec_infer_data/speechtokenizer/codebook_5.npy codec_infer_data/speechtokenizer/codebook_6.npy codec_infer_data/speechtokenizer/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp,src_text,text_int --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/text_shape.bpe
2025-04-08 00:20:29,832 (launch:348) INFO: log file: exp/asr_train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log
2025-04-08T16:26:10 (asr2_codec.sh:296:main) ./asr2_codec.sh --stage 13 --stop_stage 13 --src_token_size 1000 --src_codebook_size 8 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --src_codebook_paths codec_infer_data/xcodec_fsq_g8r1/codebook_0.npy codec_infer_data/xcodec_fsq_g8r1/codebook_1.npy codec_infer_data/xcodec_fsq_g8r1/codebook_2.npy codec_infer_data/xcodec_fsq_g8r1/codebook_3.npy codec_infer_data/xcodec_fsq_g8r1/codebook_4.npy codec_infer_data/xcodec_fsq_g8r1/codebook_5.npy codec_infer_data/xcodec_fsq_g8r1/codebook_6.npy codec_infer_data/xcodec_fsq_g8r1/codebook_7.npy --ngpu 1 --nj 8 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_fsq_g8r1 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.xcodec_fsq_g8r1 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-08T16:26:10 (asr2_codec.sh:633:main) Skipped stages:  8 9 10 11 16 17 
2025-04-08T16:26:10 (asr2_codec.sh:1432:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-04-08T16:26:10 (asr2_codec.sh:1475:main) Generate 'exp/asr_train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-04-08T16:26:10 (asr2_codec.sh:1479:main) ASR training started... log: 'exp/asr_train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log'
2025-04-08 16:26:10,454 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_codec_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1000 --src_codebook_size 8 --src_codebook_paths codec_infer_data/xcodec_fsq_g8r1/codebook_0.npy codec_infer_data/xcodec_fsq_g8r1/codebook_1.npy codec_infer_data/xcodec_fsq_g8r1/codebook_2.npy codec_infer_data/xcodec_fsq_g8r1/codebook_3.npy codec_infer_data/xcodec_fsq_g8r1/codebook_4.npy codec_infer_data/xcodec_fsq_g8r1/codebook_5.npy codec_infer_data/xcodec_fsq_g8r1/codebook_6.npy codec_infer_data/xcodec_fsq_g8r1/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp,src_text,text_int --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/text_shape.bpe
2025-04-08 16:26:10,467 (launch:348) INFO: log file: exp/asr_train_discrete_asr_codec_concat_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log
2025-04-08T16:26:36 (asr2_codec.sh:296:main) ./asr2_codec.sh --stage 13 --stop_stage 13 --src_token_size 1000 --src_codebook_size 8 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --src_codebook_paths codec_infer_data/xcodec_fsq_g8r1/codebook_0.npy codec_infer_data/xcodec_fsq_g8r1/codebook_1.npy codec_infer_data/xcodec_fsq_g8r1/codebook_2.npy codec_infer_data/xcodec_fsq_g8r1/codebook_3.npy codec_infer_data/xcodec_fsq_g8r1/codebook_4.npy codec_infer_data/xcodec_fsq_g8r1/codebook_5.npy codec_infer_data/xcodec_fsq_g8r1/codebook_6.npy codec_infer_data/xcodec_fsq_g8r1/codebook_7.npy --ngpu 1 --nj 8 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_fsq_g8r1 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.xcodec_fsq_g8r1 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-08T16:26:37 (asr2_codec.sh:633:main) Skipped stages:  8 9 10 11 16 17 
2025-04-08T16:26:37 (asr2_codec.sh:1432:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-04-08T16:26:37 (asr2_codec.sh:1475:main) Generate 'exp/asr_train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-04-08T16:26:37 (asr2_codec.sh:1479:main) ASR training started... log: 'exp/asr_train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log'
2025-04-08 16:26:37,171 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_codec_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1000 --src_codebook_size 8 --src_codebook_paths codec_infer_data/xcodec_fsq_g8r1/codebook_0.npy codec_infer_data/xcodec_fsq_g8r1/codebook_1.npy codec_infer_data/xcodec_fsq_g8r1/codebook_2.npy codec_infer_data/xcodec_fsq_g8r1/codebook_3.npy codec_infer_data/xcodec_fsq_g8r1/codebook_4.npy codec_infer_data/xcodec_fsq_g8r1/codebook_5.npy codec_infer_data/xcodec_fsq_g8r1/codebook_6.npy codec_infer_data/xcodec_fsq_g8r1/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp,src_text,text_int --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/text_shape.bpe
2025-04-08 16:26:37,184 (launch:348) INFO: log file: exp/asr_train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log
run.pl: job failed, log is in exp/asr_train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log
Command '['run.pl', '--name', 'exp/asr_train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log', '--gpu', '1', 'exp/asr_train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log', 'python3', '-m', 'espnet2.bin.mt_codec_train', '--use_preprocessor', 'true', '--bpemodel', 'data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model', '--token_type', 'bpe', '--token_list', 'data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt', '--src_token_size', '1000', '--src_codebook_size', '8', '--src_codebook_paths', 'codec_infer_data/xcodec_fsq_g8r1/codebook_0.npy', 'codec_infer_data/xcodec_fsq_g8r1/codebook_1.npy', 'codec_infer_data/xcodec_fsq_g8r1/codebook_2.npy', 'codec_infer_data/xcodec_fsq_g8r1/codebook_3.npy', 'codec_infer_data/xcodec_fsq_g8r1/codebook_4.npy', 'codec_infer_data/xcodec_fsq_g8r1/codebook_5.npy', 'codec_infer_data/xcodec_fsq_g8r1/codebook_6.npy', 'codec_infer_data/xcodec_fsq_g8r1/codebook_7.npy', '--non_linguistic_symbols', 'none', '--cleaner', 'none', '--g2p', 'none', '--valid_data_path_and_name_and_type', '/data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text', '--valid_data_path_and_name_and_type', '/data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp,src_text,text_int', '--valid_shape_file', 'exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/text_shape.bpe', '--valid_shape_file', 'exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/src_text_shape.char', '--resume', 'true', '--ignore_init_mismatch', 'false', '--fold_length', '150', '--fold_length', '150', '--output_dir', 'exp/asr_train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000', '--config', 'conf/train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml', '--train_data_path_and_name_and_type', '/data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp,src_text,text_int', '--train_data_path_and_name_and_type', '/data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text', '--train_shape_file', 'exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/src_text_shape.char', '--train_shape_file', 'exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/text_shape.bpe', '--ngpu', '1', '--multiprocessing_distributed', 'True']' returned non-zero exit status 1.
Traceback (most recent call last):
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/data/mohan/workdir/espnet/espnet2/bin/launch.py", line 384, in <module>
    main()
  File "/data/mohan/workdir/espnet/espnet2/bin/launch.py", line 375, in main
    raise RuntimeError(
RuntimeError: 
################### The last 1000 lines of exp/asr_train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log ###################
# python3 -m espnet2.bin.mt_codec_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1000 --src_codebook_size 8 --src_codebook_paths codec_infer_data/xcodec_fsq_g8r1/codebook_0.npy codec_infer_data/xcodec_fsq_g8r1/codebook_1.npy codec_infer_data/xcodec_fsq_g8r1/codebook_2.npy codec_infer_data/xcodec_fsq_g8r1/codebook_3.npy codec_infer_data/xcodec_fsq_g8r1/codebook_4.npy codec_infer_data/xcodec_fsq_g8r1/codebook_5.npy codec_infer_data/xcodec_fsq_g8r1/codebook_6.npy codec_infer_data/xcodec_fsq_g8r1/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp,src_text,text_int --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/text_shape.bpe --ngpu 1 --multiprocessing_distributed True 
# Started at Tue Apr  8 16:26:37 PDT 2025
#
/data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/mt_codec_train.py --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1000 --src_codebook_size 8 --src_codebook_paths codec_infer_data/xcodec_fsq_g8r1/codebook_0.npy codec_infer_data/xcodec_fsq_g8r1/codebook_1.npy codec_infer_data/xcodec_fsq_g8r1/codebook_2.npy codec_infer_data/xcodec_fsq_g8r1/codebook_3.npy codec_infer_data/xcodec_fsq_g8r1/codebook_4.npy codec_infer_data/xcodec_fsq_g8r1/codebook_5.npy codec_infer_data/xcodec_fsq_g8r1/codebook_6.npy codec_infer_data/xcodec_fsq_g8r1/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp,src_text,text_int --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/text_shape.bpe --ngpu 1 --multiprocessing_distributed True
[lambda-Lambda-Vector] 2025-04-08 16:26:42,520 (mt_codec:333) INFO: Vocabulary size: 5000
Traceback (most recent call last):
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_codec_train.py", line 23, in <module>
    main()
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_codec_train.py", line 19, in main
    MTTask.main(cmd=cmd)
  File "/data/mohan/workdir/espnet/espnet2/tasks/abs_task.py", line 1210, in main
    cls.main_worker(args)
  File "/data/mohan/workdir/espnet/espnet2/tasks/abs_task.py", line 1346, in main_worker
    model = cls.build_model(args=args)
  File "/data/mohan/workdir/espnet/espnet2/tasks/mt_codec.py", line 340, in build_model
    frontend = frontend_class(input_size=args.src_token_size, num_codebooks=args.src_codebook_size, npy_paths=args.src_codebook_paths, **args.frontend_conf)
  File "/data/mohan/workdir/espnet/espnet2/mt/frontend/codebook_embedding.py", line 45, in __init__
    self.input_size, embed_dim = codebook_tensor.shape
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/typeguard/_functions.py", line 251, in check_variable_assignment
    check_type_internal(value, annotation, memo)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/typeguard/_checkers.py", line 866, in check_type_internal
    raise TypeCheckError(f"is not an instance of {qualified_name(origin_type)}")
typeguard.TypeCheckError: value assigned to embed_dim (torch.Size) is not an instance of int
# Accounting: time=6 threads=1
# Ended (code 1) at Tue Apr  8 16:26:43 PDT 2025, elapsed time 6 seconds

2025-04-08T16:33:17 (asr2_codec.sh:296:main) ./asr2_codec.sh --stage 13 --stop_stage 13 --src_token_size 1000 --src_codebook_size 8 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --src_codebook_paths codec_infer_data/xcodec_fsq_g8r1/codebook_0.npy codec_infer_data/xcodec_fsq_g8r1/codebook_1.npy codec_infer_data/xcodec_fsq_g8r1/codebook_2.npy codec_infer_data/xcodec_fsq_g8r1/codebook_3.npy codec_infer_data/xcodec_fsq_g8r1/codebook_4.npy codec_infer_data/xcodec_fsq_g8r1/codebook_5.npy codec_infer_data/xcodec_fsq_g8r1/codebook_6.npy codec_infer_data/xcodec_fsq_g8r1/codebook_7.npy --ngpu 1 --nj 8 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_fsq_g8r1 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.xcodec_fsq_g8r1 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-08T16:33:17 (asr2_codec.sh:633:main) Skipped stages:  8 9 10 11 16 17 
2025-04-08T16:33:17 (asr2_codec.sh:1432:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-04-08T16:33:17 (asr2_codec.sh:1475:main) Generate 'exp/asr_train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-04-08T16:33:17 (asr2_codec.sh:1479:main) ASR training started... log: 'exp/asr_train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log'
2025-04-08 16:33:17,672 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_codec_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1000 --src_codebook_size 8 --src_codebook_paths codec_infer_data/xcodec_fsq_g8r1/codebook_0.npy codec_infer_data/xcodec_fsq_g8r1/codebook_1.npy codec_infer_data/xcodec_fsq_g8r1/codebook_2.npy codec_infer_data/xcodec_fsq_g8r1/codebook_3.npy codec_infer_data/xcodec_fsq_g8r1/codebook_4.npy codec_infer_data/xcodec_fsq_g8r1/codebook_5.npy codec_infer_data/xcodec_fsq_g8r1/codebook_6.npy codec_infer_data/xcodec_fsq_g8r1/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp,src_text,text_int --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/text_shape.bpe
2025-04-08 16:33:17,684 (launch:348) INFO: log file: exp/asr_train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log
2025-04-08T16:57:57 (asr2_codec.sh:296:main) ./asr2_codec.sh --stage 13 --stop_stage 13 --src_token_size 1000 --src_codebook_size 8 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --src_codebook_paths codec_infer_data/xcodec_fsq_g8r1/codebook_0.npy codec_infer_data/xcodec_fsq_g8r1/codebook_1.npy codec_infer_data/xcodec_fsq_g8r1/codebook_2.npy codec_infer_data/xcodec_fsq_g8r1/codebook_3.npy codec_infer_data/xcodec_fsq_g8r1/codebook_4.npy codec_infer_data/xcodec_fsq_g8r1/codebook_5.npy codec_infer_data/xcodec_fsq_g8r1/codebook_6.npy codec_infer_data/xcodec_fsq_g8r1/codebook_7.npy --ngpu 1 --nj 8 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_fsq_g8r1 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.xcodec_fsq_g8r1 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-08T16:57:57 (asr2_codec.sh:633:main) Skipped stages:  8 9 10 11 16 17 
2025-04-08T16:57:57 (asr2_codec.sh:1432:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-04-08T16:57:57 (asr2_codec.sh:1475:main) Generate 'exp/asr_train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-04-08T16:57:57 (asr2_codec.sh:1479:main) ASR training started... log: 'exp/asr_train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log'
2025-04-08 16:57:58,078 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_codec_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1000 --src_codebook_size 8 --src_codebook_paths codec_infer_data/xcodec_fsq_g8r1/codebook_0.npy codec_infer_data/xcodec_fsq_g8r1/codebook_1.npy codec_infer_data/xcodec_fsq_g8r1/codebook_2.npy codec_infer_data/xcodec_fsq_g8r1/codebook_3.npy codec_infer_data/xcodec_fsq_g8r1/codebook_4.npy codec_infer_data/xcodec_fsq_g8r1/codebook_5.npy codec_infer_data/xcodec_fsq_g8r1/codebook_6.npy codec_infer_data/xcodec_fsq_g8r1/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp,src_text,text_int --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/text_shape.bpe
2025-04-08 16:57:58,091 (launch:348) INFO: log file: exp/asr_train_discrete_asr_codec_concat_init_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log
2025-04-08T17:29:05 (asr2_codec.sh:296:main) ./asr2_codec.sh --stage 13 --stop_stage 13 --src_token_size 1000 --src_codebook_size 8 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --src_codebook_paths codec_infer_data/xcodec_fsq_g8r1/codebook_0.npy codec_infer_data/xcodec_fsq_g8r1/codebook_1.npy codec_infer_data/xcodec_fsq_g8r1/codebook_2.npy codec_infer_data/xcodec_fsq_g8r1/codebook_3.npy codec_infer_data/xcodec_fsq_g8r1/codebook_4.npy codec_infer_data/xcodec_fsq_g8r1/codebook_5.npy codec_infer_data/xcodec_fsq_g8r1/codebook_6.npy codec_infer_data/xcodec_fsq_g8r1/codebook_7.npy --ngpu 1 --nj 8 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_fsq_g8r1 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.xcodec_fsq_g8r1 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-08T17:29:05 (asr2_codec.sh:633:main) Skipped stages:  8 9 10 11 16 17 
2025-04-08T17:29:05 (asr2_codec.sh:1432:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-04-08T17:29:05 (asr2_codec.sh:1475:main) Generate 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-04-08T17:29:05 (asr2_codec.sh:1479:main) ASR training started... log: 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log'
2025-04-08 17:29:05,337 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_codec_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1000 --src_codebook_size 8 --src_codebook_paths codec_infer_data/xcodec_fsq_g8r1/codebook_0.npy codec_infer_data/xcodec_fsq_g8r1/codebook_1.npy codec_infer_data/xcodec_fsq_g8r1/codebook_2.npy codec_infer_data/xcodec_fsq_g8r1/codebook_3.npy codec_infer_data/xcodec_fsq_g8r1/codebook_4.npy codec_infer_data/xcodec_fsq_g8r1/codebook_5.npy codec_infer_data/xcodec_fsq_g8r1/codebook_6.npy codec_infer_data/xcodec_fsq_g8r1/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp,src_text,text_int --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/text_shape.bpe
2025-04-08 17:29:05,350 (launch:348) INFO: log file: exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log
run.pl: job failed, log is in exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log
Command '['run.pl', '--name', 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log', '--gpu', '1', 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log', 'python3', '-m', 'espnet2.bin.mt_codec_train', '--use_preprocessor', 'true', '--bpemodel', 'data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model', '--token_type', 'bpe', '--token_list', 'data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt', '--src_token_size', '1000', '--src_codebook_size', '8', '--src_codebook_paths', 'codec_infer_data/xcodec_fsq_g8r1/codebook_0.npy', 'codec_infer_data/xcodec_fsq_g8r1/codebook_1.npy', 'codec_infer_data/xcodec_fsq_g8r1/codebook_2.npy', 'codec_infer_data/xcodec_fsq_g8r1/codebook_3.npy', 'codec_infer_data/xcodec_fsq_g8r1/codebook_4.npy', 'codec_infer_data/xcodec_fsq_g8r1/codebook_5.npy', 'codec_infer_data/xcodec_fsq_g8r1/codebook_6.npy', 'codec_infer_data/xcodec_fsq_g8r1/codebook_7.npy', '--non_linguistic_symbols', 'none', '--cleaner', 'none', '--g2p', 'none', '--valid_data_path_and_name_and_type', '/data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text', '--valid_data_path_and_name_and_type', '/data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp,src_text,text_int', '--valid_shape_file', 'exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/text_shape.bpe', '--valid_shape_file', 'exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/src_text_shape.char', '--resume', 'true', '--ignore_init_mismatch', 'false', '--fold_length', '150', '--fold_length', '150', '--output_dir', 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000', '--config', 'conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml', '--train_data_path_and_name_and_type', '/data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp,src_text,text_int', '--train_data_path_and_name_and_type', '/data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text', '--train_shape_file', 'exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/src_text_shape.char', '--train_shape_file', 'exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/text_shape.bpe', '--ngpu', '1', '--multiprocessing_distributed', 'True']' returned non-zero exit status 1.
Traceback (most recent call last):
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/data/mohan/workdir/espnet/espnet2/bin/launch.py", line 384, in <module>
    main()
  File "/data/mohan/workdir/espnet/espnet2/bin/launch.py", line 375, in main
    raise RuntimeError(
RuntimeError: 
################### The last 1000 lines of exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log ###################
# python3 -m espnet2.bin.mt_codec_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1000 --src_codebook_size 8 --src_codebook_paths codec_infer_data/xcodec_fsq_g8r1/codebook_0.npy codec_infer_data/xcodec_fsq_g8r1/codebook_1.npy codec_infer_data/xcodec_fsq_g8r1/codebook_2.npy codec_infer_data/xcodec_fsq_g8r1/codebook_3.npy codec_infer_data/xcodec_fsq_g8r1/codebook_4.npy codec_infer_data/xcodec_fsq_g8r1/codebook_5.npy codec_infer_data/xcodec_fsq_g8r1/codebook_6.npy codec_infer_data/xcodec_fsq_g8r1/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp,src_text,text_int --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/text_shape.bpe --ngpu 1 --multiprocessing_distributed True 
# Started at Tue Apr  8 17:29:05 PDT 2025
#
/data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/mt_codec_train.py --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1000 --src_codebook_size 8 --src_codebook_paths codec_infer_data/xcodec_fsq_g8r1/codebook_0.npy codec_infer_data/xcodec_fsq_g8r1/codebook_1.npy codec_infer_data/xcodec_fsq_g8r1/codebook_2.npy codec_infer_data/xcodec_fsq_g8r1/codebook_3.npy codec_infer_data/xcodec_fsq_g8r1/codebook_4.npy codec_infer_data/xcodec_fsq_g8r1/codebook_5.npy codec_infer_data/xcodec_fsq_g8r1/codebook_6.npy codec_infer_data/xcodec_fsq_g8r1/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp,src_text,text_int --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/text_shape.bpe --ngpu 1 --multiprocessing_distributed True
[lambda-Lambda-Vector] 2025-04-08 17:29:10,765 (mt_codec:333) INFO: Vocabulary size: 5000
Traceback (most recent call last):
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_codec_train.py", line 23, in <module>
    main()
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_codec_train.py", line 19, in main
    MTTask.main(cmd=cmd)
  File "/data/mohan/workdir/espnet/espnet2/tasks/abs_task.py", line 1210, in main
    cls.main_worker(args)
  File "/data/mohan/workdir/espnet/espnet2/tasks/abs_task.py", line 1346, in main_worker
    model = cls.build_model(args=args)
  File "/data/mohan/workdir/espnet/espnet2/tasks/mt_codec.py", line 340, in build_model
    frontend = frontend_class(input_size=args.src_token_size, num_codebooks=args.src_codebook_size, npy_paths=args.src_codebook_paths, **args.frontend_conf)
  File "/data/mohan/workdir/espnet/espnet2/mt/frontend/codebook_embedding.py", line 15, in __init__
    def __init__(
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/typeguard/_functions.py", line 136, in check_argument_types
    check_type_internal(value, annotation, memo)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/typeguard/_checkers.py", line 866, in check_type_internal
    raise TypeCheckError(f"is not an instance of {qualified_name(origin_type)}")
typeguard.TypeCheckError: argument "concat" (str) is not an instance of bool
# Accounting: time=6 threads=1
# Ended (code 1) at Tue Apr  8 17:29:11 PDT 2025, elapsed time 6 seconds

2025-04-08T17:31:00 (asr2_codec.sh:296:main) ./asr2_codec.sh --stage 13 --stop_stage 13 --src_token_size 1000 --src_codebook_size 8 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --src_codebook_paths codec_infer_data/xcodec_fsq_g8r1/codebook_0.npy codec_infer_data/xcodec_fsq_g8r1/codebook_1.npy codec_infer_data/xcodec_fsq_g8r1/codebook_2.npy codec_infer_data/xcodec_fsq_g8r1/codebook_3.npy codec_infer_data/xcodec_fsq_g8r1/codebook_4.npy codec_infer_data/xcodec_fsq_g8r1/codebook_5.npy codec_infer_data/xcodec_fsq_g8r1/codebook_6.npy codec_infer_data/xcodec_fsq_g8r1/codebook_7.npy --ngpu 1 --nj 8 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_fsq_g8r1 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.xcodec_fsq_g8r1 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-08T17:31:00 (asr2_codec.sh:633:main) Skipped stages:  8 9 10 11 16 17 
2025-04-08T17:31:00 (asr2_codec.sh:1432:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-04-08T17:31:00 (asr2_codec.sh:1475:main) Generate 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-04-08T17:31:00 (asr2_codec.sh:1479:main) ASR training started... log: 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log'
2025-04-08 17:31:01,109 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_codec_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1000 --src_codebook_size 8 --src_codebook_paths codec_infer_data/xcodec_fsq_g8r1/codebook_0.npy codec_infer_data/xcodec_fsq_g8r1/codebook_1.npy codec_infer_data/xcodec_fsq_g8r1/codebook_2.npy codec_infer_data/xcodec_fsq_g8r1/codebook_3.npy codec_infer_data/xcodec_fsq_g8r1/codebook_4.npy codec_infer_data/xcodec_fsq_g8r1/codebook_5.npy codec_infer_data/xcodec_fsq_g8r1/codebook_6.npy codec_infer_data/xcodec_fsq_g8r1/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp,src_text,text_int --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/text_shape.bpe
2025-04-08 17:31:01,122 (launch:348) INFO: log file: exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/train.log
2025-04-09T09:41:51 (asr2_codec.sh:1798:main) Successfully finished. [elapsed=58251s]
2025-04-09T11:16:03 (asr2_codec.sh:296:main) ./asr2_codec.sh --stage 13 --stop_stage 13 --src_token_size 1024 --src_codebook_size 8 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/dev/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --src_codebook_paths codec_infer_data/speechtokenizer/codebook_0.npy codec_infer_data/speechtokenizer/codebook_1.npy codec_infer_data/speechtokenizer/codebook_2.npy codec_infer_data/speechtokenizer/codebook_3.npy codec_infer_data/speechtokenizer/codebook_4.npy codec_infer_data/speechtokenizer/codebook_5.npy codec_infer_data/speechtokenizer/codebook_6.npy codec_infer_data/speechtokenizer/codebook_7.npy --ngpu 1 --nj 4 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang speechtokenizer --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.speechtokenizer --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-09T11:16:03 (asr2_codec.sh:633:main) Skipped stages:  8 9 10 11 16 17 
2025-04-09T11:16:03 (asr2_codec.sh:1432:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-04-09T11:16:03 (asr2_codec.sh:1475:main) Generate 'exp/asr_train_discrete_asr_codec_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-04-09T11:16:03 (asr2_codec.sh:1479:main) ASR training started... log: 'exp/asr_train_discrete_asr_codec_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log'
2025-04-09 11:16:03,692 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_codec_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_codec_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_codec_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_codec_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1024 --src_codebook_size 8 --src_codebook_paths codec_infer_data/speechtokenizer/codebook_0.npy codec_infer_data/speechtokenizer/codebook_1.npy codec_infer_data/speechtokenizer/codebook_2.npy codec_infer_data/speechtokenizer/codebook_3.npy codec_infer_data/speechtokenizer/codebook_4.npy codec_infer_data/speechtokenizer/codebook_5.npy codec_infer_data/speechtokenizer/codebook_6.npy codec_infer_data/speechtokenizer/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/dev/speech_token.scp,src_text,text_int --valid_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/valid/text_shape.bpe --valid_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/train/src_text_shape.char --train_shape_file exp/asr_stats_raw_ts_speechtokenizer_char_bpe5000/train/text_shape.bpe
2025-04-09 11:16:03,705 (launch:348) INFO: log file: exp/asr_train_discrete_asr_codec_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/train.log
2025-04-10T03:44:55 (asr2_codec.sh:1798:main) Successfully finished. [elapsed=59332s]
2025-04-10T23:03:52 (asr2_codec.sh:298:main) ./asr2_codec.sh --stage 14 --stop_stage 14 --src_token_size 1000 --src_codebook_size 8 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp --test_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/test/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --test_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/test/text.ts.en --src_codebook_paths codec_infer_data/xcodec_fsq_g8r1/codebook_0.npy codec_infer_data/xcodec_fsq_g8r1/codebook_1.npy codec_infer_data/xcodec_fsq_g8r1/codebook_2.npy codec_infer_data/xcodec_fsq_g8r1/codebook_3.npy codec_infer_data/xcodec_fsq_g8r1/codebook_4.npy codec_infer_data/xcodec_fsq_g8r1/codebook_5.npy codec_infer_data/xcodec_fsq_g8r1/codebook_6.npy codec_infer_data/xcodec_fsq_g8r1/codebook_7.npy --ngpu 1 --nj 8 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_fsq_g8r1 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.xcodec_fsq_g8r1 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-10T23:03:52 (asr2_codec.sh:635:main) Skipped stages:  8 9 10 11 16 17 
2025-04-10T23:03:52 (asr2_codec.sh:1556:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000
2025-04-10T23:03:52 (asr2_codec.sh:1584:main) Generate 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/run.sh'. You can resume the process from stage 14 using this script
2025-04-10T23:03:53 (asr2_codec.sh:1615:main) Decoding started... log: 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/test/logdir/asr_inference.*.log'
2025-04-10T23:04:22 (asr2_codec.sh:298:main) ./asr2_codec.sh --stage 14 --stop_stage 14 --src_token_size 1000 --src_codebook_size 8 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp --test_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_fsq_g8r1/dev/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --test_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --src_codebook_paths codec_infer_data/xcodec_fsq_g8r1/codebook_0.npy codec_infer_data/xcodec_fsq_g8r1/codebook_1.npy codec_infer_data/xcodec_fsq_g8r1/codebook_2.npy codec_infer_data/xcodec_fsq_g8r1/codebook_3.npy codec_infer_data/xcodec_fsq_g8r1/codebook_4.npy codec_infer_data/xcodec_fsq_g8r1/codebook_5.npy codec_infer_data/xcodec_fsq_g8r1/codebook_6.npy codec_infer_data/xcodec_fsq_g8r1/codebook_7.npy --ngpu 1 --nj 8 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_fsq_g8r1 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets dev --src_bpe_train_text dump/raw/train/text.ts.xcodec_fsq_g8r1 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-10T23:04:22 (asr2_codec.sh:635:main) Skipped stages:  8 9 10 11 16 17 
2025-04-10T23:04:22 (asr2_codec.sh:1556:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000
2025-04-10T23:04:22 (asr2_codec.sh:1584:main) Generate 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/run.sh'. You can resume the process from stage 14 using this script
2025-04-10T23:04:22 (asr2_codec.sh:1615:main) Decoding started... log: 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/asr_inference.*.log'
2025-04-11T00:40:48 (asr2_codec.sh:1800:main) Successfully finished. [elapsed=5786s]
2025-04-11T01:30:01 (asr2_codec.sh:1800:main) Successfully finished. [elapsed=8769s]
2025-04-11T13:33:09 (asr2_codec.sh:298:main) ./asr2_codec.sh --stage 14 --stop_stage 14 --src_token_size 1024 --src_codebook_size 8 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/dev/speech_token.scp --test_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/test/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --test_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/test/text.ts.en --src_codebook_paths codec_infer_data/speechtokenizer/codebook_0.npy codec_infer_data/speechtokenizer/codebook_1.npy codec_infer_data/speechtokenizer/codebook_2.npy codec_infer_data/speechtokenizer/codebook_3.npy codec_infer_data/speechtokenizer/codebook_4.npy codec_infer_data/speechtokenizer/codebook_5.npy codec_infer_data/speechtokenizer/codebook_6.npy codec_infer_data/speechtokenizer/codebook_7.npy --ngpu 1 --nj 4 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang speechtokenizer --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.speechtokenizer --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-11T13:33:10 (asr2_codec.sh:635:main) Skipped stages:  8 9 10 11 16 17 
2025-04-11T13:33:10 (asr2_codec.sh:1556:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_codec_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000
2025-04-11T13:33:10 (asr2_codec.sh:1584:main) Generate 'exp/asr_train_discrete_asr_codec_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/run.sh'. You can resume the process from stage 14 using this script
2025-04-11T13:33:10 (asr2_codec.sh:1615:main) Decoding started... log: 'exp/asr_train_discrete_asr_codec_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/test/logdir/asr_inference.*.log'
2025-04-11T13:34:03 (asr2_codec.sh:298:main) ./asr2_codec.sh --stage 14 --stop_stage 14 --src_token_size 1024 --src_codebook_size 8 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/dev/speech_token.scp --test_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/speechtokenizer/dev/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --test_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --src_codebook_paths codec_infer_data/speechtokenizer/codebook_0.npy codec_infer_data/speechtokenizer/codebook_1.npy codec_infer_data/speechtokenizer/codebook_2.npy codec_infer_data/speechtokenizer/codebook_3.npy codec_infer_data/speechtokenizer/codebook_4.npy codec_infer_data/speechtokenizer/codebook_5.npy codec_infer_data/speechtokenizer/codebook_6.npy codec_infer_data/speechtokenizer/codebook_7.npy --ngpu 1 --nj 4 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang speechtokenizer --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets dev --src_bpe_train_text dump/raw/train/text.ts.speechtokenizer --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-11T13:34:03 (asr2_codec.sh:635:main) Skipped stages:  8 9 10 11 16 17 
2025-04-11T13:34:03 (asr2_codec.sh:1556:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_codec_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000
2025-04-11T13:34:03 (asr2_codec.sh:1584:main) Generate 'exp/asr_train_discrete_asr_codec_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/run.sh'. You can resume the process from stage 14 using this script
2025-04-11T13:34:04 (asr2_codec.sh:1615:main) Decoding started... log: 'exp/asr_train_discrete_asr_codec_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_speechtokenizer_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/asr_inference.*.log'
2025-04-11T16:30:46 (asr2_codec.sh:1800:main) Successfully finished. [elapsed=10603s]
2025-04-11T17:13:42 (asr2_codec.sh:1800:main) Successfully finished. [elapsed=13233s]
2025-04-12T22:38:02 (asr2_codec.sh:298:main) ./asr2_codec.sh --stage 13 --stop_stage 13 --src_token_size 1000 --src_codebook_size 8 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/dev/speech_token.scp --test_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/test/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --test_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/test/text.ts.en --src_codebook_paths codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_0.npy codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_1.npy codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_2.npy codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_3.npy codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_4.npy codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_5.npy codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_6.npy codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_7.npy --asr_stats_dir /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000 --ngpu 1 --nj 8 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_wavlm_base_plus_fsq_g8r1 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets dev --src_bpe_train_text dump/raw/train/text.ts.xcodec_wavlm_base_plus_fsq_g8r1 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-12T22:38:02 (asr2_codec.sh:635:main) Skipped stages:  8 9 10 11 16 17 
2025-04-12T22:38:02 (asr2_codec.sh:1434:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-04-12T22:38:02 (asr2_codec.sh:1477:main) Generate 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-04-12T22:38:02 (asr2_codec.sh:1481:main) ASR training started... log: 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/train.log'
2025-04-12 22:38:02,957 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_codec_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1000 --src_codebook_size 8 --src_codebook_paths codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_0.npy codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_1.npy codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_2.npy codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_3.npy codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_4.npy codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_5.npy codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_6.npy codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/dev/speech_token.scp,src_text,text_int --valid_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/text_shape.bpe --valid_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/src_text_shape.char --train_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/text_shape.bpe
2025-04-12 22:38:02,974 (launch:348) INFO: log file: exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/train.log
2025-04-13T01:07:30 (asr2_codec.sh:298:main) ./asr2_codec.sh --stage 13 --stop_stage 13 --src_token_size 1000 --src_codebook_size 8 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/dev/speech_token.scp --test_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/test/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --test_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/test/text.ts.en --src_codebook_paths codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_0.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_1.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_2.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_3.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_4.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_5.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_6.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_7.npy --asr_stats_dir /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000 --ngpu 1 --nj 8 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets dev --src_bpe_train_text dump/raw/train/text.ts.xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-13T01:07:30 (asr2_codec.sh:635:main) Skipped stages:  8 9 10 11 16 17 
2025-04-13T01:07:30 (asr2_codec.sh:1434:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-04-13T01:07:30 (asr2_codec.sh:1477:main) Generate 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-04-13T01:07:30 (asr2_codec.sh:1481:main) ASR training started... log: 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/train.log'
2025-04-13 01:07:30,937 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_codec_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1000 --src_codebook_size 8 --src_codebook_paths codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_0.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_1.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_2.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_3.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_4.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_5.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_6.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/dev/speech_token.scp,src_text,text_int --valid_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/text_shape.bpe --valid_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/src_text_shape.char --train_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/text_shape.bpe
2025-04-13 01:07:30,953 (launch:348) INFO: log file: exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/train.log
2025-04-13T09:10:16 (asr2_codec.sh:1800:main) Successfully finished. [elapsed=37934s]
2025-04-13T10:50:08 (asr2_codec.sh:1800:main) Successfully finished. [elapsed=34958s]
2025-04-13T11:10:56 (asr2_codec.sh:298:main) ./asr2_codec.sh --stage 14 --stop_stage 14 --src_token_size 1000 --src_codebook_size 8 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/dev/speech_token.scp --test_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/test/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --test_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/test/text.ts.en --src_codebook_paths codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_0.npy codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_1.npy codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_2.npy codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_3.npy codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_4.npy codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_5.npy codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_6.npy codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_7.npy --asr_stats_dir /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000 --ngpu 1 --nj 8 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_wavlm_base_plus_fsq_g8r1 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.xcodec_wavlm_base_plus_fsq_g8r1 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-13T11:10:56 (asr2_codec.sh:635:main) Skipped stages:  8 9 10 11 16 17 
2025-04-13T11:10:56 (asr2_codec.sh:1556:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000
2025-04-13T11:10:56 (asr2_codec.sh:1584:main) Generate 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/run.sh'. You can resume the process from stage 14 using this script
2025-04-13T11:10:56 (asr2_codec.sh:1615:main) Decoding started... log: 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/test/logdir/asr_inference.*.log'
2025-04-13T11:11:08 (asr2_codec.sh:298:main) ./asr2_codec.sh --stage 14 --stop_stage 14 --src_token_size 1000 --src_codebook_size 8 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/dev/speech_token.scp --test_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/test/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --test_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/test/text.ts.en --src_codebook_paths codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_0.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_1.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_2.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_3.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_4.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_5.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_6.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_7.npy --asr_stats_dir /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000 --ngpu 1 --nj 8 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-13T11:11:08 (asr2_codec.sh:635:main) Skipped stages:  8 9 10 11 16 17 
2025-04-13T11:11:08 (asr2_codec.sh:1556:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000
2025-04-13T11:11:08 (asr2_codec.sh:1584:main) Generate 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/run.sh'. You can resume the process from stage 14 using this script
2025-04-13T11:11:08 (asr2_codec.sh:1615:main) Decoding started... log: 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/test/logdir/asr_inference.*.log'
2025-04-13T12:41:09 (asr2_codec.sh:1800:main) Successfully finished. [elapsed=5413s]
2025-04-13T12:41:17 (asr2_codec.sh:1800:main) Successfully finished. [elapsed=5409s]
2025-04-13T12:50:17 (asr2_codec.sh:298:main) ./asr2_codec.sh --stage 14 --stop_stage 14 --src_token_size 1000 --src_codebook_size 8 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/dev/speech_token.scp --test_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/dev/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --test_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --src_codebook_paths codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_0.npy codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_1.npy codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_2.npy codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_3.npy codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_4.npy codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_5.npy codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_6.npy codec_infer_data/xcodec_wavlm_base_plus_fsq_g8r1/codebook_7.npy --asr_stats_dir /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000 --ngpu 1 --nj 8 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_wavlm_base_plus_fsq_g8r1 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets dev --src_bpe_train_text dump/raw/train/text.ts.xcodec_wavlm_base_plus_fsq_g8r1 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-13T12:50:17 (asr2_codec.sh:635:main) Skipped stages:  8 9 10 11 16 17 
2025-04-13T12:50:17 (asr2_codec.sh:1556:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000
2025-04-13T12:50:17 (asr2_codec.sh:1584:main) Generate 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/run.sh'. You can resume the process from stage 14 using this script
2025-04-13T12:50:18 (asr2_codec.sh:1615:main) Decoding started... log: 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/asr_inference.*.log'
2025-04-13T12:50:22 (asr2_codec.sh:298:main) ./asr2_codec.sh --stage 15 --stop_stage 15 --src_token_size 1000 --src_codebook_size 8 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/dev/speech_token.scp --test_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/dev/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --test_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --src_codebook_paths codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_0.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_1.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_2.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_3.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_4.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_5.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_6.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_7.npy --asr_stats_dir /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000 --ngpu 1 --nj 8 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets dev --src_bpe_train_text dump/raw/train/text.ts.xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-13T12:50:22 (asr2_codec.sh:635:main) Skipped stages:  8 9 10 11 16 17 
2025-04-13T12:50:22 (asr2_codec.sh:1638:main) Stage 15: Scoring
/data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/tokenize_text.py -f 2- --input - --output - --token_type char --cleaner none --token_type char --non_linguistic_symbols none --remove_non_linguistic_symbols true
Can't open exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/text: No such file or directory.
/data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/tokenize_text.py -f 2- --input - --output - --token_type char --token_type char --non_linguistic_symbols none --remove_non_linguistic_symbols true
2025-04-13T12:50:31 (asr2_codec.sh:1700:main) Write cer result in exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/score_cer/result.txt
|          SPKR                 |          # Snt                    # Wrd           |          Corr                      Sub                      Del                      Ins                       Err                    S.Err          |
|          Sum/Avg              |          9037                    763728           |           0.0                      0.0                    100.0                      0.0                     100.0                    100.0          |
/data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/tokenize_text.py -f 2- --input - --output - --token_type word --cleaner none --token_type word --non_linguistic_symbols none --remove_non_linguistic_symbols true
Can't open exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/text: No such file or directory.
/data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/tokenize_text.py -f 2- --input - --output - --token_type word --token_type word --non_linguistic_symbols none --remove_non_linguistic_symbols true
2025-04-13T12:50:37 (asr2_codec.sh:1700:main) Write wer result in exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/score_wer/result.txt
|          SPKR                 |          # Snt                    # Wrd           |          Corr                      Sub                      Del                      Ins                       Err                    S.Err          |
|          Sum/Avg              |          9037                    153273           |           0.0                      0.0                    100.0                      0.0                     100.0                    100.0          |
/data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/tokenize_text.py -f 2- --input - --output - --token_type bpe --cleaner none --token_type bpe --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model
Can't open exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/text: No such file or directory.
/data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/tokenize_text.py -f 2- --input - --output - --token_type bpe --token_type bpe --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model
2025-04-13T12:50:45 (asr2_codec.sh:1700:main) Write ter result in exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/score_ter/result.txt
|          SPKR                 |          # Snt                    # Wrd           |          Corr                      Sub                      Del                      Ins                       Err                    S.Err          |
|          Sum/Avg              |          9037                    168467           |           0.0                      0.0                    100.0                      0.0                     100.0                    100.0          |
<!-- Generated by scripts/utils/show_asr_result.sh -->
# RESULTS
## Environments
- date: `Sun Apr 13 12:50:45 PDT 2025`
- python version: `3.10.15 (main, Oct  3 2024, 07:27:34) [GCC 11.2.0]`
- espnet version: `espnet 202409`
- pytorch version: `pytorch 2.3.0+cu121`
- Git hash: `cea7138339774c302f4af2804631d62c75bb4b2f`
  - Commit date: `Wed Mar 5 17:46:50 2025 -0800`

## exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000
### WER

|dataset|Snt|Wrd|Corr|Sub|Del|Ins|Err|S.Err|
|---|---|---|---|---|---|---|---|---|
|decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev|9037|153273|0.0|0.0|100.0|0.0|100.0|100.0|
|decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/test|10311|182712|89.9|7.6|2.5|2.7|12.8|66.7|

### CER

|dataset|Snt|Wrd|Corr|Sub|Del|Ins|Err|S.Err|
|---|---|---|---|---|---|---|---|---|
|decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev|9037|763728|0.0|0.0|100.0|0.0|100.0|100.0|
|decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/test|10311|911898|95.6|1.6|2.8|2.8|7.2|66.7|

### TER

|dataset|Snt|Wrd|Corr|Sub|Del|Ins|Err|S.Err|
|---|---|---|---|---|---|---|---|---|
|decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev|9037|168467|0.0|0.0|100.0|0.0|100.0|100.0|
|decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/test|10311|201118|90.0|6.4|3.6|3.4|13.4|66.7|

2025-04-13T12:50:46 (asr2_codec.sh:1800:main) Successfully finished. [elapsed=24s]
2025-04-13T13:39:49 (asr2_codec.sh:1800:main) Successfully finished. [elapsed=2972s]
2025-04-13T13:42:47 (asr2_codec.sh:298:main) ./asr2_codec.sh --stage 14 --stop_stage 14 --src_token_size 1000 --src_codebook_size 8 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/dev/speech_token.scp --test_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/dev/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --test_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --src_codebook_paths codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_0.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_1.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_2.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_3.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_4.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_5.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_6.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_7.npy --asr_stats_dir /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000 --ngpu 1 --nj 8 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets dev --src_bpe_train_text dump/raw/train/text.ts.xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-13T13:42:47 (asr2_codec.sh:635:main) Skipped stages:  8 9 10 11 16 17 
2025-04-13T13:42:47 (asr2_codec.sh:1556:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000
2025-04-13T13:42:47 (asr2_codec.sh:1584:main) Generate 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/run.sh'. You can resume the process from stage 14 using this script
2025-04-13T13:42:47 (asr2_codec.sh:1615:main) Decoding started... log: 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/asr_inference.*.log'
2025-04-13T14:32:18 (asr2_codec.sh:1800:main) Successfully finished. [elapsed=2971s]
2025-04-21T17:38:52 (asr2_codec.sh:298:main) ./asr2_codec.sh --stage 15 --stop_stage 15 --src_token_size 1000 --src_codebook_size 8 --train_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/train/speech_token.scp --valid_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/dev/speech_token.scp --test_speech_token_scp /data/mohan/workdir/espnet/egs2/myst/asr2/codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/dev/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --test_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --src_codebook_paths codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_0.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_1.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_2.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_3.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_4.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_5.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_6.npy codec_infer_data/xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_7.npy --asr_stats_dir /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000 --ngpu 1 --nj 8 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets dev --src_bpe_train_text dump/raw/train/text.ts.xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-21T17:38:52 (asr2_codec.sh:635:main) Skipped stages:  8 9 10 11 16 17 
2025-04-21T17:38:52 (asr2_codec.sh:1638:main) Stage 15: Scoring
/data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/tokenize_text.py -f 2- --input - --output - --token_type char --cleaner none --token_type char --non_linguistic_symbols none --remove_non_linguistic_symbols true
/data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/tokenize_text.py -f 2- --input - --output - --token_type char --token_type char --non_linguistic_symbols none --remove_non_linguistic_symbols true
2025-04-21T17:39:14 (asr2_codec.sh:1700:main) Write cer result in exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/score_cer/result.txt
|          SPKR                 |          # Snt                    # Wrd           |          Corr                      Sub                      Del                      Ins                       Err                    S.Err          |
|          Sum/Avg              |          9037                    763728           |          95.7                      1.6                      2.7                      2.7                       6.9                     67.9          |
/data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/tokenize_text.py -f 2- --input - --output - --token_type word --cleaner none --token_type word --non_linguistic_symbols none --remove_non_linguistic_symbols true
/data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/tokenize_text.py -f 2- --input - --output - --token_type word --token_type word --non_linguistic_symbols none --remove_non_linguistic_symbols true
2025-04-21T17:39:22 (asr2_codec.sh:1700:main) Write wer result in exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/score_wer/result.txt
|          SPKR                 |          # Snt                    # Wrd           |          Corr                      Sub                      Del                      Ins                       Err                    S.Err          |
|          Sum/Avg              |          9037                    153273           |          90.3                      7.3                      2.4                      2.5                      12.2                     67.9          |
/data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/tokenize_text.py -f 2- --input - --output - --token_type bpe --cleaner none --token_type bpe --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model
/data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/tokenize_text.py -f 2- --input - --output - --token_type bpe --token_type bpe --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model
2025-04-21T17:39:31 (asr2_codec.sh:1700:main) Write ter result in exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/score_ter/result.txt
|          SPKR                 |          # Snt                    # Wrd           |          Corr                      Sub                      Del                      Ins                       Err                    S.Err          |
|          Sum/Avg              |          9037                    168467           |          90.3                      6.1                      3.6                      3.1                      12.8                     67.9          |
<!-- Generated by scripts/utils/show_asr_result.sh -->
# RESULTS
## Environments
- date: `Mon Apr 21 17:39:31 PDT 2025`
- python version: `3.10.15 (main, Oct  3 2024, 07:27:34) [GCC 11.2.0]`
- espnet version: `espnet 202409`
- pytorch version: `pytorch 2.3.0+cu121`
- Git hash: `cea7138339774c302f4af2804631d62c75bb4b2f`
  - Commit date: `Wed Mar 5 17:46:50 2025 -0800`

## exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000
### WER

|dataset|Snt|Wrd|Corr|Sub|Del|Ins|Err|S.Err|
|---|---|---|---|---|---|---|---|---|
|decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev|9037|153273|90.3|7.3|2.4|2.5|12.2|67.9|
|decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/test|10311|182712|89.9|7.6|2.5|2.7|12.8|66.7|

### CER

|dataset|Snt|Wrd|Corr|Sub|Del|Ins|Err|S.Err|
|---|---|---|---|---|---|---|---|---|
|decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev|9037|763728|95.7|1.6|2.7|2.7|6.9|67.9|
|decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/test|10311|911898|95.6|1.6|2.8|2.8|7.2|66.7|

### TER

|dataset|Snt|Wrd|Corr|Sub|Del|Ins|Err|S.Err|
|---|---|---|---|---|---|---|---|---|
|decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev|9037|168467|90.3|6.1|3.6|3.1|12.8|67.9|
|decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/test|10311|201118|90.0|6.4|3.6|3.4|13.4|66.7|

2025-04-21T17:39:32 (asr2_codec.sh:1800:main) Successfully finished. [elapsed=40s]
2025-04-21T17:40:45 (asr2_codec.sh:298:main) ./asr2_codec.sh --stage 13 --stop_stage 13 --src_token_size 1000 --src_codebook_size 8 --train_speech_token_scp dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/train/speech_token.scp --valid_speech_token_scp dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/dev/speech_token.scp --test_speech_token_scp dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/test/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --test_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/test/text.ts.en --src_codebook_paths dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_0.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_1.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_2.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_3.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_4.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_5.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_6.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_7.npy --asr_stats_dir /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000 --ngpu 1 --nj 8 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets dev --src_bpe_train_text dump/raw/train/text.ts.xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-21T17:40:45 (asr2_codec.sh:635:main) Skipped stages:  8 9 10 11 16 17 
2025-04-21T17:40:45 (asr2_codec.sh:1434:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-04-21T17:40:45 (asr2_codec.sh:1477:main) Generate 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-04-21T17:40:45 (asr2_codec.sh:1481:main) ASR training started... log: 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/train.log'
2025-04-21 17:40:45,346 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_codec_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1000 --src_codebook_size 8 --src_codebook_paths dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_0.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_1.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_2.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_3.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_4.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_5.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_6.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/dev/speech_token.scp,src_text,text_int --valid_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/text_shape.bpe --valid_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/src_text_shape.char --train_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/text_shape.bpe
2025-04-21 17:40:45,360 (launch:348) INFO: log file: exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/train.log
2025-04-22T09:44:50 (asr2_codec.sh:1800:main) Successfully finished. [elapsed=57845s]
2025-04-22T10:25:35 (asr2_codec.sh:298:main) ./asr2_codec.sh --stage 14 --stop_stage 14 --src_token_size 1000 --src_codebook_size 8 --train_speech_token_scp dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/train/speech_token.scp --valid_speech_token_scp dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/dev/speech_token.scp --test_speech_token_scp dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/test/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --test_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/test/text.ts.en --src_codebook_paths dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_0.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_1.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_2.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_3.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_4.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_5.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_6.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_7.npy --asr_stats_dir /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000 --ngpu 1 --nj 8 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-22T10:25:35 (asr2_codec.sh:635:main) Skipped stages:  8 9 10 11 16 17 
2025-04-22T10:25:35 (asr2_codec.sh:1556:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000
2025-04-22T10:25:35 (asr2_codec.sh:1584:main) Generate 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/run.sh'. You can resume the process from stage 14 using this script
2025-04-22T10:25:35 (asr2_codec.sh:1615:main) Decoding started... log: 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/test/logdir/asr_inference.*.log'
2025-04-22T10:29:39 (asr2_codec.sh:298:main) ./asr2_codec.sh --stage 14 --stop_stage 14 --src_token_size 1000 --src_codebook_size 8 --train_speech_token_scp dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/train/speech_token.scp --valid_speech_token_scp dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/dev/speech_token.scp --test_speech_token_scp dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/dev/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --test_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --src_codebook_paths dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_0.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_1.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_2.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_3.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_4.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_5.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_6.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1/codebook_7.npy --asr_stats_dir /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000 --ngpu 1 --nj 8 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets dev --src_bpe_train_text dump/raw/train/text.ts.xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-04-22T10:29:39 (asr2_codec.sh:635:main) Skipped stages:  8 9 10 11 16 17 
2025-04-22T10:29:39 (asr2_codec.sh:1556:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000
2025-04-22T10:29:39 (asr2_codec.sh:1584:main) Generate 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/run.sh'. You can resume the process from stage 14 using this script
2025-04-22T10:29:39 (asr2_codec.sh:1615:main) Decoding started... log: 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_cosy_s3_use_ssl_wavlm_base_plus_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/asr_inference.*.log'
2025-04-22T13:26:50 (asr2_codec.sh:1800:main) Successfully finished. [elapsed=10631s]
2025-04-22T14:05:20 (asr2_codec.sh:1800:main) Successfully finished. [elapsed=13185s]
2025-05-05T17:56:40 (asr2_codec.sh:298:main) ./asr2_codec.sh --stage 13 --stop_stage 13 --src_token_size 1000 --src_codebook_size 8 --train_speech_token_scp dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/train/speech_token.scp --valid_speech_token_scp dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/dev/speech_token.scp --test_speech_token_scp dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/test/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --test_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/test/text.ts.en --src_codebook_paths dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_0.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_1.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_2.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_3.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_4.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_5.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_6.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_7.npy --asr_stats_dir /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000 --ngpu 1 --nj 8 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_hubert_base_fsq_g8r1 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.xcodec_hubert_base_fsq_g8r1 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-05-05T17:56:40 (asr2_codec.sh:635:main) Skipped stages:  8 9 10 11 16 17 
2025-05-05T17:56:40 (asr2_codec.sh:1434:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-05-05T17:56:40 (asr2_codec.sh:1477:main) Generate 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-05-05T17:56:40 (asr2_codec.sh:1481:main) ASR training started... log: 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/train.log'
2025-05-05 17:56:40,666 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_codec_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1000 --src_codebook_size 8 --src_codebook_paths dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_0.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_1.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_2.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_3.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_4.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_5.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_6.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/dev/speech_token.scp,src_text,text_int --valid_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/text_shape.bpe --valid_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_hubert_base_fsq_g8r1_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/src_text_shape.char --train_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/text_shape.bpe
2025-05-05 17:56:40,683 (launch:348) INFO: log file: exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/train.log
run.pl: job failed, log is in exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/train.log
Command '['run.pl', '--name', 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/train.log', '--gpu', '1', 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/train.log', 'python3', '-m', 'espnet2.bin.mt_codec_train', '--use_preprocessor', 'true', '--bpemodel', 'data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model', '--token_type', 'bpe', '--token_list', 'data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt', '--src_token_size', '1000', '--src_codebook_size', '8', '--src_codebook_paths', 'dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_0.npy', 'dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_1.npy', 'dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_2.npy', 'dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_3.npy', 'dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_4.npy', 'dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_5.npy', 'dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_6.npy', 'dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_7.npy', '--non_linguistic_symbols', 'none', '--cleaner', 'none', '--g2p', 'none', '--valid_data_path_and_name_and_type', '/data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text', '--valid_data_path_and_name_and_type', 'dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/dev/speech_token.scp,src_text,text_int', '--valid_shape_file', '/data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/text_shape.bpe', '--valid_shape_file', '/data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/src_text_shape.char', '--resume', 'true', '--ignore_init_mismatch', 'false', '--fold_length', '150', '--fold_length', '150', '--output_dir', 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_hubert_base_fsq_g8r1_char_ts_bpe_ts5000', '--config', 'conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml', '--train_data_path_and_name_and_type', 'dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/train/speech_token.scp,src_text,text_int', '--train_data_path_and_name_and_type', '/data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text', '--train_shape_file', '/data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/src_text_shape.char', '--train_shape_file', '/data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/text_shape.bpe', '--ngpu', '1', '--multiprocessing_distributed', 'True']' returned non-zero exit status 1.
Traceback (most recent call last):
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/data/mohan/workdir/espnet/espnet2/bin/launch.py", line 384, in <module>
    main()
  File "/data/mohan/workdir/espnet/espnet2/bin/launch.py", line 375, in main
    raise RuntimeError(
RuntimeError: 
################### The last 1000 lines of exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/train.log ###################
# python3 -m espnet2.bin.mt_codec_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1000 --src_codebook_size 8 --src_codebook_paths dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_0.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_1.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_2.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_3.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_4.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_5.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_6.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/dev/speech_token.scp,src_text,text_int --valid_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/text_shape.bpe --valid_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_hubert_base_fsq_g8r1_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/src_text_shape.char --train_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/text_shape.bpe --ngpu 1 --multiprocessing_distributed True 
# Started at Mon May  5 17:56:40 PDT 2025
#
/data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/mt_codec_train.py --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1000 --src_codebook_size 8 --src_codebook_paths dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_0.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_1.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_2.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_3.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_4.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_5.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_6.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/dev/speech_token.scp,src_text,text_int --valid_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/text_shape.bpe --valid_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_hubert_base_fsq_g8r1_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/src_text_shape.char --train_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/text_shape.bpe --ngpu 1 --multiprocessing_distributed True
[lambda-Lambda-Vector] 2025-05-05 17:56:46,874 (mt_codec:333) INFO: Vocabulary size: 5000
Traceback (most recent call last):
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_codec_train.py", line 23, in <module>
    main()
  File "/data/mohan/workdir/espnet/espnet2/bin/mt_codec_train.py", line 19, in main
    MTTask.main(cmd=cmd)
  File "/data/mohan/workdir/espnet/espnet2/tasks/abs_task.py", line 1210, in main
    cls.main_worker(args)
  File "/data/mohan/workdir/espnet/espnet2/tasks/abs_task.py", line 1346, in main_worker
    model = cls.build_model(args=args)
  File "/data/mohan/workdir/espnet/espnet2/tasks/mt_codec.py", line 340, in build_model
    frontend = frontend_class(input_size=args.src_token_size, num_codebooks=args.src_codebook_size, npy_paths=args.src_codebook_paths, **args.frontend_conf)
  File "/data/mohan/workdir/espnet/espnet2/mt/frontend/codebook_embedding.py", line 41, in __init__
    codebook_array = np.load(npy_path)
  File "/data/mohan/anaconda3/envs/espnet/lib/python3.10/site-packages/numpy/lib/npyio.py", line 405, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
FileNotFoundError: [Errno 2] No such file or directory: 'dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_0.npy'
# Accounting: time=7 threads=1
# Ended (code 1) at Mon May  5 17:56:47 PDT 2025, elapsed time 7 seconds

2025-05-05T17:59:33 (asr2_codec.sh:298:main) ./asr2_codec.sh --stage 13 --stop_stage 13 --src_token_size 1000 --src_codebook_size 8 --train_speech_token_scp dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/train/speech_token.scp --valid_speech_token_scp dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/dev/speech_token.scp --test_speech_token_scp dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/test/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --test_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/test/text.ts.en --src_codebook_paths dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_0.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_1.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_2.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_3.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_4.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_5.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_6.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_7.npy --asr_stats_dir /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000 --ngpu 1 --nj 8 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_hubert_base_fsq_g8r1 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.xcodec_hubert_base_fsq_g8r1 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-05-05T17:59:33 (asr2_codec.sh:635:main) Skipped stages:  8 9 10 11 16 17 
2025-05-05T17:59:33 (asr2_codec.sh:1434:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-05-05T17:59:33 (asr2_codec.sh:1477:main) Generate 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-05-05T17:59:33 (asr2_codec.sh:1481:main) ASR training started... log: 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/train.log'
2025-05-05 17:59:33,996 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_codec_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1000 --src_codebook_size 8 --src_codebook_paths dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_0.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_1.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_2.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_3.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_4.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_5.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_6.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/dev/speech_token.scp,src_text,text_int --valid_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/text_shape.bpe --valid_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_hubert_base_fsq_g8r1_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/src_text_shape.char --train_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/text_shape.bpe
2025-05-05 17:59:34,008 (launch:348) INFO: log file: exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/train.log
2025-05-05T23:57:57 (asr2_codec.sh:298:main) ./asr2_codec.sh --stage 13 --stop_stage 13 --src_token_size 1000 --src_codebook_size 8 --train_speech_token_scp dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/train/speech_token.scp --valid_speech_token_scp dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/dev/speech_token.scp --test_speech_token_scp dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/test/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --test_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/test/text.ts.en --src_codebook_paths dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_0.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_1.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_2.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_3.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_4.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_5.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_6.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_7.npy --asr_stats_dir /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000 --ngpu 1 --nj 8 --inference_nj 1 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-05-05T23:57:57 (asr2_codec.sh:635:main) Skipped stages:  8 9 10 11 16 17 
2025-05-05T23:57:57 (asr2_codec.sh:1434:main) Stage 13: ASR Training: train_set=dump/raw/train, valid_set=dump/raw/dev
2025-05-05T23:57:57 (asr2_codec.sh:1477:main) Generate 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/run.sh'. You can resume the process from stage 13 using this script
2025-05-05T23:57:57 (asr2_codec.sh:1481:main) ASR training started... log: 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/train.log'
2025-05-05 23:57:57,360 (launch:94) INFO: /data/mohan/anaconda3/envs/espnet/bin/python3 /data/mohan/workdir/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/train.log' --log exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/.dimt_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.mt_codec_train --use_preprocessor true --bpemodel data/token_list/tgt_bpe_unigram5000_ts_en/bpe.model --token_type bpe --token_list data/token_list/tgt_bpe_unigram5000_ts_en/tokens.txt --src_token_size 1000 --src_codebook_size 8 --src_codebook_paths dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_0.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_1.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_2.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_3.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_4.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_5.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_6.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_7.npy --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en,text,text --valid_data_path_and_name_and_type dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/dev/speech_token.scp,src_text,text_int --valid_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/text_shape.bpe --valid_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/valid/src_text_shape.char --resume true --ignore_init_mismatch false --fold_length 150 --fold_length 150 --output_dir exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1_char_ts_bpe_ts5000 --config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --train_data_path_and_name_and_type dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/train/speech_token.scp,src_text,text_int --train_data_path_and_name_and_type /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en,text,text --train_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/src_text_shape.char --train_shape_file /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000/train/text_shape.bpe
2025-05-05 23:57:57,374 (launch:348) INFO: log file: exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/train.log
2025-05-06T09:47:58 (asr2_codec.sh:1800:main) Successfully finished. [elapsed=56905s]
2025-05-06T15:52:40 (asr2_codec.sh:1800:main) Successfully finished. [elapsed=57283s]
2025-05-06T20:01:14 (asr2_codec.sh:298:main) ./asr2_codec.sh --stage 14 --stop_stage 14 --src_token_size 1000 --src_codebook_size 8 --train_speech_token_scp dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/train/speech_token.scp --valid_speech_token_scp dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/dev/speech_token.scp --test_speech_token_scp dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/test/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --test_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/test/text.ts.en --src_codebook_paths dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_0.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_1.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_2.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_3.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_4.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_5.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_6.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_7.npy --asr_stats_dir /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000 --ngpu 1 --nj 8 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_hubert_base_fsq_g8r1 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.xcodec_hubert_base_fsq_g8r1 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-05-06T20:01:14 (asr2_codec.sh:635:main) Skipped stages:  8 9 10 11 16 17 
2025-05-06T20:01:14 (asr2_codec.sh:1556:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_hubert_base_fsq_g8r1_char_ts_bpe_ts5000
2025-05-06T20:01:14 (asr2_codec.sh:1584:main) Generate 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/run.sh'. You can resume the process from stage 14 using this script
2025-05-06T20:01:14 (asr2_codec.sh:1615:main) Decoding started... log: 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/test/logdir/asr_inference.*.log'
2025-05-06T20:07:25 (asr2_codec.sh:298:main) ./asr2_codec.sh --stage 14 --stop_stage 14 --src_token_size 1000 --src_codebook_size 8 --train_speech_token_scp dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/train/speech_token.scp --valid_speech_token_scp dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/dev/speech_token.scp --test_speech_token_scp dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/test/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --test_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/test/text.ts.en --src_codebook_paths dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_0.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_1.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_2.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_3.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_4.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_5.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_6.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_7.npy --asr_stats_dir /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000 --ngpu 1 --nj 8 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets test --src_bpe_train_text dump/raw/train/text.ts.xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-05-06T20:07:25 (asr2_codec.sh:635:main) Skipped stages:  8 9 10 11 16 17 
2025-05-06T20:07:25 (asr2_codec.sh:1556:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1_char_ts_bpe_ts5000
2025-05-06T20:07:25 (asr2_codec.sh:1584:main) Generate 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/run.sh'. You can resume the process from stage 14 using this script
2025-05-06T20:07:25 (asr2_codec.sh:1615:main) Decoding started... log: 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/test/logdir/asr_inference.*.log'
2025-05-06T21:38:37 (asr2_codec.sh:1800:main) Successfully finished. [elapsed=5843s]
2025-05-06T21:45:08 (asr2_codec.sh:1800:main) Successfully finished. [elapsed=5863s]
2025-05-07T12:31:46 (asr2_codec.sh:298:main) ./asr2_codec.sh --stage 14 --stop_stage 14 --src_token_size 1000 --src_codebook_size 8 --train_speech_token_scp dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/train/speech_token.scp --valid_speech_token_scp dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/dev/speech_token.scp --test_speech_token_scp dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/dev/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --test_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --src_codebook_paths dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_0.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_1.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_2.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_3.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_4.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_5.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_6.npy dump/codec_infer_data/xcodec_hubert_base_fsq_g8r1/codebook_7.npy --asr_stats_dir /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000 --ngpu 1 --nj 8 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_hubert_base_fsq_g8r1 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets dev --src_bpe_train_text dump/raw/train/text.ts.xcodec_hubert_base_fsq_g8r1 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-05-07T12:31:46 (asr2_codec.sh:635:main) Skipped stages:  8 9 10 11 16 17 
2025-05-07T12:31:46 (asr2_codec.sh:1556:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_hubert_base_fsq_g8r1_char_ts_bpe_ts5000
2025-05-07T12:31:46 (asr2_codec.sh:1584:main) Generate 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/run.sh'. You can resume the process from stage 14 using this script
2025-05-07T12:31:46 (asr2_codec.sh:1615:main) Decoding started... log: 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/asr_inference.*.log'
2025-05-07T12:31:50 (asr2_codec.sh:298:main) ./asr2_codec.sh --stage 14 --stop_stage 14 --src_token_size 1000 --src_codebook_size 8 --train_speech_token_scp dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/train/speech_token.scp --valid_speech_token_scp dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/dev/speech_token.scp --test_speech_token_scp dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/dev/speech_token.scp --train_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/train/text.ts.en --valid_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --test_text_scp /data/mohan/workdir/espnet/egs2/myst/asr2/dump/raw/dev/text.ts.en --src_codebook_paths dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_0.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_1.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_2.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_3.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_4.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_5.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_6.npy dump/codec_infer_data/xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1/codebook_7.npy --asr_stats_dir /data/mohan/workdir/espnet/egs2/myst/asr2/exp/asr_stats_raw_ts_xcodec_fsq_g8r1_char_bpe5000 --ngpu 1 --nj 8 --inference_nj 4 --inference_asr_model valid.cer_ctc.best.pth --gpu_inference true --src_lang xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1 --tgt_lang en --src_token_type char --src_nbpe 6000 --tgt_token_type bpe --tgt_nbpe 5000 --src_case ts --tgt_case ts --use_lm false --asr_config conf/train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4.yaml --inference_config conf/decode_ctc1.0_greedy.yaml --train_set train --valid_set dev --test_sets dev --src_bpe_train_text dump/raw/train/text.ts.xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1 --tgt_bpe_train_text dump/raw/train/text.ts.en --lm_train_text dump/raw/train/text.ts.en
2025-05-07T12:31:50 (asr2_codec.sh:635:main) Skipped stages:  8 9 10 11 16 17 
2025-05-07T12:31:50 (asr2_codec.sh:1556:main) Stage 14: Decoding: training_dir=exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1_char_ts_bpe_ts5000
2025-05-07T12:31:50 (asr2_codec.sh:1584:main) Generate 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/run.sh'. You can resume the process from stage 14 using this script
2025-05-07T12:31:50 (asr2_codec.sh:1615:main) Decoding started... log: 'exp/asr_train_discrete_asr_codec_concat_init_freeze_e_branchformer1_onlyctc_1gpu_lr5e-4_raw_xcodec_semantic_cosy_s3_hidden_use_ssl_hubert_base_fsq_g8r1_char_ts_bpe_ts5000/decode_ctc1.0_greedy_asr_model_valid.cer_ctc.best/dev/logdir/asr_inference.*.log'
2025-05-07T14:02:21 (asr2_codec.sh:1800:main) Successfully finished. [elapsed=5431s]
2025-05-07T14:03:03 (asr2_codec.sh:1800:main) Successfully finished. [elapsed=5477s]
